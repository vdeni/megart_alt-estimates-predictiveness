
@article{10.1371/journal.pcbi.1005399,
  title = {Ten Simple Rules for Responsible Big Data Research},
  author = {Zook, Matthew and Barocas, Solon and {boyd}, danah and Crawford, Kate and Keller, Emily and Gangadharan, Seeta Pe{\~n}a and Goodman, Alyssa and Hollander, Rachelle and Koenig, Barbara A. and Metcalf, Jacob and Narayanan, Arvind and Nelson, Alondra and Pasquale, Frank},
  year = {2017},
  month = mar,
  journal = {PLOS Computational Biology},
  volume = {13},
  number = {3},
  pages = {1--10},
  publisher = {{Public Library of Science}},
  doi = {10.1371/journal.pcbi.1005399},
  keywords = {ethics-privacy}
}

@book{409997,
  title = {Causality: {{Models}}, {{Reasoning}}, and {{Inference}}},
  author = {Pearl, Judea},
  year = {2013},
  edition = {2nd ed.},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge [etc.] :}}
}

@article{adelmanVisualWordRecognition,
  title = {Visual {{Word Recognition}}},
  author = {Adelman, James S},
  pages = {26},
  language = {en}
}

@article{aguasvivasSPALEXSpanishLexical2018,
  title = {{{SPALEX}}: {{A Spanish Lexical Decision Database From}} a {{Massive Online Data Collection}}},
  shorttitle = {{{SPALEX}}},
  author = {Aguasvivas, Jose Armando and Carreiras, Manuel and Brysbaert, Marc and Mandera, Pawe{\l} and Keuleers, Emmanuel and Du{\~n}abeitia, Jon Andoni},
  year = {2018},
  month = nov,
  journal = {Frontiers in Psychology},
  volume = {9},
  pages = {2156},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2018.02156},
  language = {en}
}

@book{allaireRmarkdownDynamicDocuments2019,
  title = {Rmarkdown: {{Dynamic Documents}} for {{R}}},
  author = {Allaire, J. J. and Xie, Yihui and McPherson, Jonathan and Luraschi, Javier and Ushey, Kevin and Atkins, Aron and Wickham, Hadley and Cheng, Joe and Chang, Winston and Iannone, Richard},
  year = {2019}
}

@article{althouseAdjustMultipleComparisons2016,
  title = {Adjust for {{Multiple Comparisons}}? {{It}}'s {{Not That Simple}}},
  shorttitle = {Adjust for {{Multiple Comparisons}}?},
  author = {Althouse, Andrew D.},
  year = {2016},
  month = may,
  journal = {The Annals of Thoracic Surgery},
  volume = {101},
  number = {5},
  pages = {1644--1645},
  issn = {00034975},
  doi = {10.1016/j.athoracsur.2015.11.024},
  language = {en},
  keywords = {statistika}
}

@book{alvinc.rencherMethodsMultivariateAnalysis2012,
  title = {Methods of {{Multivariate Analysis}}, {{Third Edition}}},
  author = {Alvin C. Rencher, William F. Christensen},
  year = {2012},
  series = {Wiley {{Series}} in {{Probability}} and {{Statistics}}},
  keywords = {multivariate,statistika}
}

@article{andersonPathwayMultivariateAnalysis2019,
  title = {A Pathway for Multivariate Analysis of Ecological Communities Using Copulas},
  author = {Anderson, Marti J. and de Valpine, Perry and Punnett, Andrew and Miller, Arden E.},
  year = {2019},
  journal = {Ecology and Evolution},
  volume = {9},
  number = {6},
  pages = {3276--3294},
  issn = {2045-7758},
  doi = {10.1002/ece3.4948},
  abstract = {We describe a new pathway for multivariate analysis of data consisting of counts of species abundances that includes two key components: copulas, to provide a flexible joint model of individual species, and dissimilarity-based methods, to integrate information across species and provide a holistic view of the community. Individual species are characterized using suitable (marginal) statistical distributions, with the mean, the degree of over-dispersion, and/or zero-inflation being allowed to vary among a priori groups of sampling units. Associations among species are then modeled using copulas, which allow any pair of disparate types of variables to be coupled through their cumulative distribution function, while maintaining entirely the separate individual marginal distributions appropriate for each species. A Gaussian copula smoothly captures changes in an index of association that excludes joint absences in the space of the original species variables. A permutation-based filter with exact family-wise error can optionally be used a priori to reduce the dimensionality of the copula estimation problem. We describe in detail a Monte Carlo expectation maximization algorithm for efficient estimation of the copula correlation matrix with discrete marginal distributions (counts). The resulting fully parameterized copula models can be used to simulate realistic ecological community data under fully specified null or alternative hypotheses. Distributions of community centroids derived from simulated data can then be visualized in ordinations of ecologically meaningful dissimilarity spaces. Multinomial mixtures of data drawn from copula models also yield smooth power curves in dissimilarity-based settings. Our proposed analysis pathway provides new opportunities to combine model-based approaches with dissimilarity-based methods to enhance understanding of ecological systems. We demonstrate implementation of the pathway through an ecological example, where associations among fish species were found to increase after the establishment of a marine reserve.},
  copyright = {\textcopyright{} 2019 The Authors. Ecology and Evolution published by John Wiley \& Sons Ltd.},
  language = {en},
  keywords = {copula,statistika},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/ece3.4948}
}

@book{anderssonEditorsExplainingInteraction2014,
  title = {From the Editors: {{Explaining}} Interaction Effects within and across Levels of Analysis},
  author = {Andersson, Ulf and {Cuervo-Cazurra}, Alvaro and Nielsen, Bo Bernhard},
  year = {2014},
  publisher = {{Springer}},
  isbn = {0047-2506},
  keywords = {statistika}
}

@article{andrewsEffectOrthographicSimilarity1997,
  title = {The Effect of Orthographic Similarity on Lexical Retrieval: {{Resolving}} Neighborhood Conflicts},
  shorttitle = {The Effect of Orthographic Similarity on Lexical Retrieval},
  author = {Andrews, Sally},
  year = {1997},
  month = dec,
  journal = {Psychonomic Bulletin \& Review},
  volume = {4},
  number = {4},
  pages = {439--461},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03214334},
  language = {en},
  keywords = {psihologija-jezika}
}

@article{aslinStatisticalLearningAcquiring2012,
  title = {Statistical Learning: {{From}} Acquiring Specific Items to Forming General Rules},
  author = {Aslin, Richard N. and Newport, Elissa L.},
  year = {2012},
  journal = {Current directions in psychological science},
  volume = {21},
  number = {3},
  pages = {170--176}
}

@article{baayenMixedeffectsModelingCrossed2008,
  title = {Mixed-Effects Modeling with Crossed Random Effects for Subjects and Items},
  author = {Baayen, R. Harald and Davidson, Douglas J. and Bates, Douglas M.},
  year = {2008},
  journal = {Journal of memory and language},
  volume = {59},
  number = {4},
  pages = {390--412},
  keywords = {multilevel,statistika}
}

@article{baayenRealExperimentFactorial2010,
  title = {A {{Real Experiment}} Is a {{Factorial Experiment}}?},
  author = {Baayen, R. H.},
  year = {2010},
  journal = {The Mental Lexicon},
  volume = {5},
  number = {1},
  pages = {149--157},
  issn = {1871-1340, 1871-1375},
  doi = {10.1075/ml.5.1.06baa},
  language = {en}
}

@book{bacheMagrittrForwardPipeOperator2014,
  title = {Magrittr: {{A Forward}}-{{Pipe Operator}} for {{R}}},
  author = {Bache, Stefan Milton and Wickham, Hadley},
  year = {2014}
}

@article{balotaEnglishLexiconProject2007,
  title = {The {{English Lexicon Project}}},
  author = {Balota, David A. and Yap, Melvin J. and Hutchison, Keith A. and Cortese, Michael J. and Kessler, Brett and Loftis, Bjorn and Neely, James H. and Nelson, Douglas L. and Simpson, Greg B. and Treiman, Rebecca},
  year = {2007},
  month = aug,
  journal = {Behavior Research Methods},
  volume = {39},
  number = {3},
  pages = {445--459},
  issn = {1554-351X, 1554-3528},
  doi = {10.3758/BF03193014},
  language = {en}
}

@incollection{balotaMegastudiesWhatMillions2012,
  title = {Megastudies: {{What}} Do {{Millions}} (or so) of {{Trials Tell}} Us {{About Lexical Processing}}?},
  booktitle = {Visual {{Word Recognition}} ({{Models}} and {{Methods}}, {{Orthography}} and {{Phonology}})},
  author = {Balota, David A. and Yap, Melvin J. and Hutchison, Keith A. and Cortese, Michael J.},
  editor = {Adelman, James S},
  year = {2012},
  volume = {1},
  pages = {90--115},
  publisher = {{Psychology Press}},
  address = {{Hove}},
  keywords = {megastudy}
}

@article{balotaMovingMeanStudies2011,
  title = {Moving beyond the Mean in Studies of Mental Chronometry: {{The}} Power of Response Time Distributional Analyses},
  author = {Balota, David A. and Yap, Melvin J.},
  year = {2011},
  journal = {Current Directions in Psychological Science},
  volume = {20},
  number = {3},
  pages = {160--166},
  keywords = {metodologija}
}

@incollection{balotaVisualWordRecognition2006,
  title = {Visual {{Word Recognition}}: {{The Journey}} from {{Features}} to {{Meaning}} ({{A Travel Update}})},
  booktitle = {Handbook of {{Psycholinguistics}}},
  author = {Balota, David A. and Yap, Melvin J. and Cortese, Michael J.},
  year = {2006},
  edition = {Second},
  pages = {285--375},
  publisher = {{Academic Press}}
}

@article{bannerConsiderationsAssessingModel2017,
  title = {Considerations for Assessing Model Averaging of Regression Coefficients},
  author = {Banner, Katharine M. and Higgs, Megan D.},
  year = {2017},
  journal = {Ecological Applications},
  volume = {27},
  number = {1},
  pages = {78--93},
  keywords = {multi-model-inference,statistika},
  file = {/home/denis/Zotero/storage/W5XG3D8F/eap.html}
}

@article{baribaultMetastudiesRobustTests2018,
  title = {Metastudies for Robust Tests of Theory},
  author = {Baribault, Beth and Donkin, Chris and Little, Daniel R. and Trueblood, Jennifer S. and Oravecz, Zita and van Ravenzwaaij, Don and White, Corey N. and Boeck, Paul De and Vandekerckhove, Joachim},
  year = {2018},
  month = mar,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {11},
  pages = {2607--2612},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1708285114},
  abstract = {We describe and demonstrate an empirical strategy useful for discovering and replicating empirical effects in psychological science. The method involves the design of a metastudy, in which many independent experimental variables\textemdash that may be moderators of an empirical effect\textemdash are indiscriminately randomized. Radical randomization yields rich datasets that can be used to test the robustness of an empirical claim to some of the vagaries and idiosyncrasies of experimental protocols and enhances the generalizability of these claims. The strategy is made feasible by advances in hierarchical Bayesian modeling that allow for the pooling of information across unlike experiments and designs and is proposed here as a gold standard for replication research and exploratory research. The practical feasibility of the strategy is demonstrated with a replication of a study on subliminal priming.},
  chapter = {Colloquium Paper},
  copyright = {\textcopyright{} 2018 . http://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
  language = {en},
  pmid = {29531092},
  file = {/home/denis/Zotero/storage/M6A655DQ/2607.html}
}

@article{barkerTruthModelsModel2015,
  title = {Truth, Models, Model Sets, {{AIC}}, and Multimodel Inference: {{A Bayesian}} Perspective: {{Bayesian Multimodel Inference}}},
  shorttitle = {Truth, Models, Model Sets, {{AIC}}, and Multimodel Inference},
  author = {Barker, Richard J. and Link, William A.},
  year = {2015},
  month = jul,
  journal = {The Journal of Wildlife Management},
  volume = {79},
  number = {5},
  pages = {730--738},
  issn = {0022541X},
  doi = {10.1002/jwmg.890},
  language = {en},
  keywords = {multi-model-inference,statistika}
}

@article{baronModeratorMediatorVariable1986,
  title = {The Moderator\textendash Mediator Variable Distinction in Social Psychological Research: {{Conceptual}}, Strategic, and Statistical Considerations.},
  author = {Baron, Reuben M. and Kenny, David A.},
  year = {1986},
  journal = {Journal of personality and social psychology},
  volume = {51},
  number = {6},
  pages = {1173},
  publisher = {{American Psychological Association}},
  isbn = {1939-1315},
  keywords = {statistika}
}

@incollection{barringerHistoryCausalAnalysis2013,
  title = {A {{History}} of {{Causal Analysis}} in the {{Social Sciences}}},
  booktitle = {Handbook of {{Causal Analysis}} for {{Social Research}}},
  author = {Barringer, Sondra N. and Eliason, Scott R. and Leahey, Erin},
  editor = {Morgan, Stephen L.},
  year = {2013},
  series = {Handbooks of Sociology and Social Research},
  pages = {9--26},
  publisher = {{Springer Netherlands}},
  isbn = {978-94-007-6093-6 978-94-007-6094-3},
  keywords = {causal-inference,sem,statistika}
}

@article{bartlettBootstrapInferenceMultiple2019,
  title = {Bootstrap {{Inference}} for {{Multiple Imputation}} under {{Uncongeniality}} and {{Misspecification}}},
  author = {Bartlett, Jonathan W. and Hughes, Rachael A.},
  year = {2019},
  month = nov,
  journal = {arXiv:1911.09980 [stat]},
  eprint = {1911.09980},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Multiple imputation has become one of the most popular approaches for handling missing data in statistical analyses. Part of this success is due to Rubin's simple combination rules. These give frequentist valid inferences when the imputation and analysis procedures are so called congenial and the complete data analysis is valid, but otherwise may not. Roughly speaking, congeniality corresponds to whether the imputation and analysis models make different assumptions about the data. In practice imputation and analysis procedures are often not congenial, such that tests may not have the correct size and confidence interval coverage deviates from the advertised level. We examine a number of recent proposals which combine bootstrapping with multiple imputation, and determine which are valid under uncongeniality and model misspecification. Imputation followed by bootstrapping generally does not result in valid variance estimates under uncongeniality or misspecification, whereas bootstrapping followed by imputation does. We recommend a particular computationally efficient variant of bootstrapping followed by imputation.},
  archiveprefix = {arXiv},
  language = {en},
  keywords = {bootstrap,metodologija,multiple-imputation,statistika}
}

@article{batesCrossvalidationWhatDoes,
  title = {Cross-Validation: What Does It Estimate and How Well Does It Do It?},
  author = {Bates, Stephen and Hastie, Trevor and Tibshirani, Robert},
  pages = {36},
  abstract = {Cross-validation is a widely-used technique to estimate prediction error, but its behavior is complex and not fully understood. Ideally, one would like to think that cross-validation estimates the prediction error for the model at hand, fit to the training data. We prove that this is not the case for the linear model fit by ordinary least squares; rather it estimates the average prediction error of models fit on other unseen training sets drawn from the same population. We further show that this phenomenon occurs for most popular estimates of prediction error, including data splitting, bootstrapping, and Mallow's Cp. Next, the standard confidence intervals for prediction error derived from cross-validation may have coverage far below the desired level. Because each data point is used for both training and testing, there are correlations among the measured accuracies for each fold, and so the usual estimate of variance is too small. We introduce a nested cross-validation scheme to estimate this variance more accurately, and show empirically that this modification leads to intervals with approximately correct coverage in many examples where traditional cross-validation intervals fail. Lastly, our analysis also shows that when producing confidence intervals for prediction accuracy with simple data splitting, one should not re-fit the model on the combined data, since this invalidates the confidence intervals.},
  language = {en},
  keywords = {statistika}
}

@article{batesFittingLinearMixedeffects2015,
  title = {Fitting {{Linear Mixed}}-Effects {{Models Using}} Lme4},
  author = {Bates, Douglas and M{\"a}chler, Martin and Bolker, Ben and Walker, Steve},
  year = {2015},
  journal = {Journal of Statistical Software},
  volume = {67},
  number = {1},
  pages = {1--48},
  doi = {10.18637/jss.v067.i01},
  keywords = {software}
}

@book{beaujeanLatentVariableModeling2014,
  title = {Latent {{Variable Modeling Using R}}: {{A Step}}-by-{{Step Guide}}},
  author = {Beaujean, A. Alexander},
  year = {2014},
  publisher = {{Routledge}},
  isbn = {1-317-97073-X},
  keywords = {latent,statistika}
}

@article{beckerStatisticalControlCorrelational2016,
  title = {Statistical Control in Correlational Studies: 10 Essential Recommendations for Organizational Researchers},
  shorttitle = {Statistical Control in Correlational Studies},
  author = {Becker, Thomas E. and Atinc, Guclu and Breaugh, James A. and Carlson, Kevin D. and Edwards, Jeffrey R. and Spector, Paul E.},
  year = {2016},
  journal = {Journal of Organizational Behavior},
  volume = {37},
  number = {2},
  pages = {157--167},
  keywords = {collinearity,statistika},
  file = {/home/denis/Zotero/storage/XH8XLX8S/job.html}
}

@article{bender2021dangers,
  title = {On the Dangers of Stochastic Parrots: {{Can}} Language Models Be Too Big},
  author = {Bender, Emily M and Gebru, Timnit and {McMillan-Major}, Angelina and Shmitchell, Shmargaret},
  year = {2021},
  journal = {Proceedings of FAccT},
  keywords = {ethics-privacy}
}

@article{bergerUnifiedFrequentistBayesian1997,
  title = {Unified Frequentist and {{Bayesian}} Testing of a Precise Hypothesis},
  author = {Berger, James O. and Boukai, Ben and Wang, Yinping},
  year = {1997},
  journal = {Statistical Science},
  volume = {12},
  number = {3},
  pages = {133--160},
  keywords = {statistika}
}

@article{betancourtConceptualIntroductionHamiltonian2018,
  title = {A {{Conceptual Introduction}} to {{Hamiltonian Monte Carlo}}},
  author = {Betancourt, Michael},
  year = {2018},
  month = jul,
  journal = {arXiv:1701.02434 [stat]},
  eprint = {1701.02434},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Hamiltonian Monte Carlo has proven a remarkable empirical success, but only recently have we begun to develop a rigorous understanding of why it performs so well on difficult problems and how it is best applied in practice. Unfortunately, that understanding is confined within the mathematics of differential geometry which has limited its dissemination, especially to the applied communities for which it is particularly important. In this review I provide a comprehensive conceptual account of these theoretical foundations, focusing on developing a principled intuition behind the method and its optimal implementations rather of any exhaustive rigor. Whether a practitioner or a statistician, the dedicated reader will acquire a solid grasp of how Hamiltonian Monte Carlo works, when it succeeds, and, perhaps most importantly, when it fails.},
  archiveprefix = {arXiv},
  keywords = {bayes,statistika}
}

@article{bickhardTragedyOperationalism2001,
  ids = {bickhardTragedyOperationalism2001a},
  title = {The {{Tragedy}} of {{Operationalism}}},
  author = {Bickhard, Mark H.},
  year = {2001},
  month = feb,
  journal = {Theory \& Psychology},
  volume = {11},
  number = {1},
  pages = {35--44},
  issn = {0959-3543, 1461-7447},
  doi = {10.1177/0959354301111002},
  abstract = {Operational definitions were a neo-Machean development that connected with the positivism of Logical Positivism. Logical Positivism failed, with the failure of operational definitions being just one of multiple and multifarious failures of Logical Positivism more broadly. Operationalism, however, has continued to seduce psychology more than half a century after it was repudiated by philosophers of science, including the very Logical Positivists who had first taken it seriously. It carries with it a presupposed metaphysics that is false in virtually all of its particulars, and thereby distorts and obscures genuine issues concerning the nature of theory and of science. It makes it particularly difficult for psychologists, under the thrall of this dogma, to free themselves from these false presuppositions, and to think about, create, and critique genuine scientific theory and process. That is the tragedy of operationalism.},
  language = {en},
  keywords = {filozofija-znanosti}
}

@techreport{bishop2017big,
  title = {Big Data and Data Sharing: {{Ethical}} Issues},
  author = {Bishop, Libby},
  year = {2017},
  institution = {{UK Data Archive}},
  keywords = {ethics-privacy}
}

@article{bodnerTenSimpleRules2021,
  title = {Ten Simple Rules for Tackling Your First Mathematical Models: {{A}} Guide for Graduate Students by Graduate Students},
  shorttitle = {Ten Simple Rules for Tackling Your First Mathematical Models},
  author = {Bodner, Korryn and Brimacombe, Chris and Chenery, Emily S. and Greiner, Ariel and McLeod, Anne M. and Penk, Stephanie R. and Soto, Juan S. Vargas},
  year = {2021},
  month = jan,
  journal = {PLOS Computational Biology},
  volume = {17},
  number = {1},
  pages = {e1008539},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008539},
  language = {en},
  keywords = {computational-modeling,statistika}
}

@book{book:1055912,
  title = {Latent {{Variable Models}} and {{Factor Analysis}}: {{A Unified Approach}}},
  author = {David J. Bartholomew, Martin Knott, Irini Moustaki},
  year = {2011},
  series = {Wiley Series in Probability and Statistics},
  edition = {Third},
  publisher = {{Wiley}},
  isbn = {0-470-97192-4 978-0-470-97192-5},
  keywords = {latent,statistika}
}

@book{book:1497323,
  title = {Solaris},
  author = {Lem, Stanis{\l}aw},
  year = {2016},
  publisher = {{Faber \& Faber}},
  isbn = {0-571-31157-1 978-0-571-31157-6},
  keywords = {beletristika}
}

@book{book:982269,
  title = {Handbook of {{Causal Analysis}} for {{Social Research}}},
  editor = {Morgan, Stephen L.},
  year = {2013},
  series = {Handbooks of Sociology and Social Research},
  edition = {First},
  publisher = {{Springer Netherlands}},
  isbn = {978-94-007-6093-6 978-94-007-6094-3},
  keywords = {causal-inference,statistika}
}

@book{borensteinIntroductionMetaanalysis2011,
  title = {Introduction to Meta-Analysis},
  author = {Borenstein, Michael and Hedges, Larry V. and Higgins, Julian PT and Rothstein, Hannah R.},
  year = {2011},
  publisher = {{John Wiley \& Sons}},
  isbn = {1-119-96437-7},
  keywords = {meta-analiza,metodologija}
}

@article{bostonParallelProcessingSentence2011,
  title = {Parallel Processing and Sentence Comprehension Difficulty},
  author = {Boston, Marisa Ferrara and Hale, John T. and Vasishth, Shravan and Kliegl, Reinhold},
  year = {2011},
  journal = {Language and Cognitive Processes},
  volume = {26},
  number = {3},
  pages = {301--349},
  keywords = {psihologija-jezika}
}

@article{boulesteixReplicationCrisisMethodological2020,
  title = {A Replication Crisis in Methodological Research?},
  author = {Boulesteix, Anne-Laure and Hoffmann, Sabine and Charlton, Alethea and Seibold, Heidi},
  year = {2020},
  journal = {Significance},
  volume = {17},
  number = {5},
  pages = {18--21},
  issn = {1740-9713},
  doi = {10.1111/1740-9713.01444},
  abstract = {Statisticians have been keen to critique statistical aspects of the ``replication crisis'' in other scientific disciplines. But new statistical tools are often published and promoted without any thought to replicability. This needs to change, argue Anne-Laure Boulesteix, Sabine Hoffmann, Alethea Charlton and Heidi Seibold},
  copyright = {\textcopyright{} 2020 The Royal Statistical Society},
  language = {en},
  annotation = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/1740-9713.01444},
  file = {/home/denis/Zotero/storage/STL4XJTT/1740-9713.html}
}

@article{bransonImprovingCovariateBalance2016,
  title = {Improving Covariate Balance in {{2K}} Factorial Designs via Rerandomization with an Application to a {{New York City Department}} of {{Education High School Study}}},
  author = {Branson, Zach and Dasgupta, Tirthankar and Rubin, Donald B.},
  year = {2016},
  month = dec,
  journal = {The Annals of Applied Statistics},
  volume = {10},
  number = {4},
  pages = {1958--1976},
  issn = {1932-6157, 1941-7330},
  doi = {10.1214/16-AOAS959},
  abstract = {A few years ago, the New York Department of Education (NYDE) was planning to conduct an experiment involving five new intervention programs for a selected set of New York City high schools. The goal was to estimate the causal effects of these programs and their interactions on the schools' performance. For each of the schools, about 50 premeasured covariates were available. The schools could be randomly assigned to the 32 treatment combinations of this 25252\^\{5\} factorial experiment, but such an allocation could have resulted in a huge covariate imbalance across treatment groups. Standard methods used to prevent confounding of treatment effects with covariate effects (e.g., blocking) were not intuitive due to the large number of covariates. In this paper, we explore how the recently proposed and studied method of rerandomization can be applied to this problem and other factorial experiments. We propose how to implement rerandomization in factorial experiments, extend the theoretical properties of rerandomization from single-factor experiments to 2K2K2\^\{K\} factorial designs, and demonstrate, using the NYDE data, how such a designed experiment can improve precision of estimated factorial effects.},
  language = {EN},
  mrnumber = {MR3592044},
  zmnumber = {06688764},
  keywords = {metodologija,rerandomization,statistika},
  file = {/home/denis/Zotero/storage/3WWVANSR/1483606847.html}
}

@incollection{brazeOrthographyWordRecognition2017,
  title = {Orthography, {{Word Recognition}}, and {{Reading}}},
  booktitle = {Handbook of {{Psycholinguistics}}},
  author = {Braze, David and Gong, Tao},
  editor = {Fern{\'a}ndez, Eva M. and Smith Cairns, Helen},
  year = {2017},
  pages = {269--293},
  publisher = {{Wiley Blackwell}}
}

@article{bringHowStandardizeRegression1994,
  title = {How to Standardize Regression Coefficients},
  author = {Bring, Johan},
  year = {1994},
  journal = {The American Statistician},
  volume = {48},
  number = {3},
  pages = {209--213},
  keywords = {regresija,statistika},
  file = {/home/denis/Zotero/storage/3B493JHT/00031305.1994.html}
}

@article{bromanDataOrganizationSpreadsheets2018,
  title = {Data Organization in Spreadsheets},
  author = {Broman, Karl W. and Woo, Kara H.},
  year = {2018},
  journal = {The American Statistician},
  volume = {72},
  number = {1},
  pages = {2--10},
  keywords = {metodologija,software}
}

@article{brownAutomaticMeasurementPropositional2008,
  title = {Automatic Measurement of Propositional Idea Density from Part-of-Speech Tagging},
  author = {Brown, Cati and Snodgrass, Tony and Kemper, Susan J. and Herman, Ruth and Covington, Michael A.},
  year = {2008},
  journal = {Behavior research methods},
  volume = {40},
  number = {2},
  pages = {540--545}
}

@article{brownRobustTestsEquality1974,
  title = {Robust Tests for the Equality of Variances},
  author = {Brown, Morton B. and Forsythe, Alan B.},
  year = {1974},
  journal = {Journal of the American Statistical Association},
  volume = {69},
  number = {346},
  pages = {364--367},
  keywords = {statistika}
}

@article{brysbaertImpactWordPrevalence2016,
  title = {The {{Impact}} of {{Word Prevalence}} on {{Lexical Decision Times}}: {{Evidence}} from the {{Dutch Lexicon Project}} 2.},
  author = {Brysbaert, Marc and Stevens, Micha{\"e}l and Mandera, Pawe{\l} and Keuleers, Emmanuel},
  year = {2016},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  volume = {42},
  number = {3},
  pages = {441--458},
  keywords = {megastudy,psihologija-jezika}
}

@article{brysbaertMovingKuceraFrancis2009,
  title = {Moving {{Beyond Ku\v{c}era}} and {{Francis}}: {{A Critical Evaluation}} of {{Current Word Frequency Norms}} and the {{Introduction}} of a {{New}} and {{Improved Word Frequency Measure}} for {{American English}}},
  author = {Brysbaert, Marc and New, Boris},
  year = {2009},
  journal = {Behavior research methods},
  volume = {41},
  number = {4},
  pages = {977--990},
  keywords = {psihologija-jezika,word-frequency}
}

@article{brysbaertPowerAnalysisEffect2018,
  title = {Power {{Analysis}} and {{Effect Size}} in {{Mixed Effects Models}}: {{A Tutorial}}},
  shorttitle = {Power {{Analysis}} and {{Effect Size}} in {{Mixed Effects Models}}},
  author = {Brysbaert, Marc and Stevens, Micha{\"e}l},
  year = {2018},
  month = jan,
  journal = {Journal of Cognition},
  volume = {1},
  number = {1},
  pages = {9},
  issn = {2514-4820},
  doi = {10.5334/joc.10},
  language = {en},
  keywords = {effect-size,multilevel,stat-power,statistika}
}

@article{brysbaertRecognitionTimes542019,
  title = {Recognition {{Times}} for 54 {{Thousand Dutch Words}}: {{Data}} from the {{Dutch Crowdsourcing Project}}},
  shorttitle = {Recognition {{Times}} for 54 {{Thousand Dutch Words}}},
  author = {Brysbaert, Marc and Keuleers, Emmanuel and Mandera, Pawe{\l}},
  year = {2019},
  month = jul,
  journal = {Psychologica Belgica},
  volume = {59},
  number = {1},
  pages = {281--300},
  issn = {2054-670X},
  doi = {10.5334/pb.491},
  language = {en},
  keywords = {megastudy}
}

@article{bubMethodologicalIssuesConfronting2000,
  title = {Methodological {{Issues Confronting PET And fMRI Studies Of Cognitive Function}}},
  author = {Bub, Daniel N.},
  year = {2000},
  month = jul,
  journal = {Cognitive Neuropsychology},
  volume = {17},
  number = {5},
  pages = {467--484},
  issn = {0264-3294, 1464-0627},
  doi = {10.1080/026432900410793},
  language = {en},
  keywords = {fmri,metodologija}
}

@incollection{bundesenAttention2005,
  title = {Attention},
  booktitle = {Attention},
  author = {Bundesen, 2,3 ), C. ( 1 and Habekost, 5 ), T. ( 4},
  editor = {Lamberts, K. and Goldstone, R.},
  year = {2005 / 01 / 01 /},
  pages = {105--129},
  publisher = {{SAGE Publications Inc.}},
  doi = {10.4135/9781848608177.n4},
  isbn = {978-1-84860-817-7},
  language = {English},
  annotation = {105}
}

@article{burknerBrmsPackageBayesian2017,
  title = {Brms: {{An R}} Package for {{Bayesian}} Multilevel Models Using {{Stan}}},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2017},
  journal = {Journal of statistical software},
  volume = {80},
  number = {1},
  pages = {1--28},
  isbn = {1548-7660}
}

@article{burnhamAICModelSelection2011,
  title = {{{AIC}} Model Selection and Multimodel Inference in Behavioral Ecology: Some Background, Observations, and Comparisons},
  shorttitle = {{{AIC}} Model Selection and Multimodel Inference in Behavioral Ecology},
  author = {Burnham, Kenneth P. and Anderson, David R. and Huyvaert, Kathryn P.},
  year = {2011},
  journal = {Behavioral ecology and sociobiology},
  volume = {65},
  number = {1},
  pages = {23--35},
  keywords = {aic,information-theory,statistika}
}

@article{buurenMiceMultivariateImputation2011,
  title = {Mice: {{Multivariate Imputation}} by {{Chained Equations}} in {{R}}},
  shorttitle = {Mice},
  author = {van Buuren, Stef and {Groothuis-Oudshoorn}, Karin},
  year = {2011},
  month = dec,
  journal = {Journal of Statistical Software},
  volume = {45},
  number = {1},
  pages = {1--67},
  issn = {1548-7660},
  doi = {10.18637/jss.v045.i03},
  copyright = {Copyright (c) 2009 Stef van Buuren, Karin Groothuis-Oudshoorn},
  language = {en},
  keywords = {missing-data,multiple-imputation,software,statistika},
  file = {/home/denis/Zotero/storage/NJSSGNIA/v045i03.html}
}

@book{byrneStructuralEquationModeling2016,
  title = {Structural {{Equation Modeling}} with {{Mplus}}: {{Basic Concepts}}, {{Applications}}, and {{Programming}}},
  author = {Byrne, Barbara M.},
  year = {2016},
  publisher = {{Routledge}},
  isbn = {1-136-66346-0},
  keywords = {sem,statistika}
}

@article{cadeModelAveragingMuddled2015,
  title = {Model Averaging and Muddled Multimodel Inferences},
  author = {Cade, Brian S.},
  year = {2015},
  month = sep,
  journal = {Ecology},
  volume = {96},
  number = {9},
  pages = {2370--2382},
  issn = {0012-9658},
  doi = {10.1890/14-1639.1},
  language = {en},
  keywords = {multi-model-inference,statistika}
}

@book{cantyBootBootstrapSPlus2017,
  title = {Boot: {{Bootstrap R}} ({{S}}-{{Plus}}) {{Functions}}},
  author = {Canty, Angelo and Ripley, B. D.},
  year = {2017},
  keywords = {bootstrap}
}

@incollection{carpenterWorkingMemoryConstraints1994,
  title = {Working Memory Constraints in Comprehension: {{Evidence}} from Individual Differences, Aphasia, and Aging},
  booktitle = {Handbook of Psycholinguistics},
  author = {Carpenter, Patricia A},
  editor = {Gernsbacher, M A},
  year = {1994},
  pages = {1075--1122},
  publisher = {{Academic Press}},
  address = {{San Diego, CA}}
}

@article{carreirasSublexicalRepresentationsFront2004,
  title = {Sublexical Representations and the `Front End' of Visual Word Recognition},
  author = {Carreiras, Manuel and Grainger, Jonathan},
  year = {2004},
  month = jun,
  journal = {Language and Cognitive Processes},
  volume = {19},
  number = {3},
  pages = {321--331},
  issn = {0169-0965, 1464-0732},
  doi = {10.1080/01690960344000288},
  language = {en},
  keywords = {psihologija-jezika}
}

@book{carrollPsychologyLanguage2008,
  ids = {carrollPsychologyLanguage2008a},
  title = {Psychology of Language},
  author = {Carroll, David W.},
  year = {2008},
  edition = {5th ed.},
  publisher = {{Thomson/Wadsworth}},
  address = {{Belmont, CA}},
  keywords = {psihologija-jezika,Psycholinguistics,Textbooks}
}

@book{carterTypographicDesignForm2015,
  title = {Typographic Design: {{Form}} and Communication},
  author = {Carter, Rob and Meggs, Philip B. and Day, Ben and Maxa, Sandra and Sanders, Mark},
  year = {2015},
  publisher = {{John Wiley \& Sons}},
  isbn = {978-1-118-71581-9}
}

@book{cessda_training_team_2020_3820473,
  title = {{{CESSDA}} Data Management Expert Guide},
  author = {{CESSDA Training Team}},
  year = {2020},
  month = jan,
  publisher = {{CESSDA ERIC}}
}

@article{chalmers2003experimental,
  title = {Experimental Manipulation of Prior Experience: {{Effects}} on Item and Associative Recognition},
  author = {Chalmers, Kerry and Humphreys, Michael},
  year = {2003},
  journal = {Memory},
  volume = {11},
  number = {3},
  pages = {233--246},
  publisher = {{Taylor \& Francis}},
  keywords = {psihologija-jezika,word-exposure}
}

@article{changPsycholinguisticDatabaseTraditional2016,
  title = {A {{Psycholinguistic Database}} for {{Traditional Chinese Character Naming}}},
  author = {Chang, Ya-Ning and Hsu, Chun-Hsien and Tsai, Jie-Li and Chen, Chien-Liang and Lee, Chia-Ying},
  year = {2016},
  month = mar,
  journal = {Behavior Research Methods},
  volume = {48},
  number = {1},
  pages = {112--122},
  issn = {1554-3528},
  doi = {10.3758/s13428-014-0559-7},
  language = {en},
  keywords = {megastudy}
}

@book{chernickBootstrapMethodsGuide2011,
  title = {Bootstrap Methods: {{A}} Guide for Practitioners and Researchers},
  author = {Chernick, Michael R.},
  year = {2011},
  volume = {619},
  publisher = {{John Wiley \& Sons}},
  isbn = {1-118-21159-6},
  keywords = {bootstrap}
}

@article{cinelliCrashCourseGood2020,
  title = {A {{Crash Course}} in {{Good}} and {{Bad Controls}}},
  author = {Cinelli, Carlos and Forney, Andrew and Pearl, Judea},
  year = {2020},
  journal = {SSRN Electronic Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3689437},
  abstract = {Many students, especially in econometrics, express frustration with the way a problem known as ``bad control'' is evaded, if not mishandled, in the traditional literature. The problem arises when the addition of a variable to a regression equation produces an unintended discrepancy between the regression coefficient and the effect that the coefficient is expected to represent. Avoiding such discrepancies presents a challenge not only to practitioners of econometrics, but to all analysts in the data intensive sciences. This note describes graphical tools for understanding, visualizing, and resolving the problem through a series of illustrative examples. We have found that the examples presented here can serve as a powerful instructional device to supplement formal discussions of the problem. By making this ``crash course'' accessible to instructors and practitioners, we hope to avail these tools to a broader community of scientists concerned with the causal interpretation of regression models.},
  language = {en},
  keywords = {causal-inference}
}

@techreport{cinelliMakingSenseSensitivity2018,
  title = {Making Sense of Sensitivity: {{Extending}} Omitted Variable Bias},
  shorttitle = {Making Sense of Sensitivity},
  author = {Cinelli, Carlos and Hazlett, Chad},
  year = {2018},
  institution = {{Working Paper}},
  keywords = {causal-inference,regresija}
}

@book{cohenAppliedMultipleRegression2003,
  title = {Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences},
  author = {Cohen, Jacob and Cohen, Patricia and West, Stephen G and Aiken, Leona S},
  year = {2003},
  publisher = {{Lawrence Erlbaum Associates}},
  address = {{Mahwah, NJ}}
}

@book{cohenStatisticalPowerAnalysis2013,
  title = {Statistical Power Analysis for the Behavioral Sciences},
  author = {Cohen, Jacob},
  year = {2013},
  publisher = {{Routledge}},
  keywords = {effect-size,stat-power,statistika}
}

@incollection{coltheartAccessInternalLexicon1977,
  title = {Access to the {{Internal Lexicon}}},
  booktitle = {Attention and {{Performance}}},
  author = {Coltheart, Max and Davelaar, Eddy and Jonasson, John T. and Besner, Derek},
  editor = {Dornick, S},
  year = {1977},
  volume = {VI},
  pages = {535--556},
  publisher = {{Erlbaum}},
  keywords = {orthographic-neighborhood,psihologija-jezika}
}

@article{conwayWorkingMemorySpan2005,
  title = {Working Memory Span Tasks: {{A}} Methodological Review and User's Guide},
  author = {Conway, Andrew RA and Kane, Michael J. and Bunting, Michael F. and Hambrick, D. Zach and Wilhelm, Oliver and Engle, Randall W.},
  year = {2005},
  journal = {Psychonomic bulletin \& review},
  volume = {12},
  number = {5},
  pages = {769--786},
  keywords = {complex-span-test}
}

@book{cooperHandbookResearchSynthesis2009,
  title = {The Handbook of Research Synthesis and Meta-Analysis},
  author = {Cooper, Harris and Hedges, Larry V. and Valentine, Jeffrey C.},
  year = {2009},
  publisher = {{Russell Sage Foundation}},
  isbn = {1-61044-138-9},
  keywords = {lit-review,meta-analiza,metodologija}
}

@article{copPresentingGECOEyetracking2017,
  title = {Presenting {{GECO}}: {{An}} Eyetracking Corpus of Monolingual and Bilingual Sentence Reading},
  shorttitle = {Presenting {{GECO}}},
  author = {Cop, Uschi and Dirix, Nicolas and Drieghe, Denis and Duyck, Wouter},
  year = {2017},
  month = apr,
  journal = {Behavior Research Methods},
  volume = {49},
  number = {2},
  pages = {602--615},
  issn = {1554-3528},
  doi = {10.3758/s13428-016-0734-0},
  abstract = {This article introduces GECO, the Ghent EyeTracking Corpus, a monolingual and bilingual corpus of the eyetracking data of participants reading a complete novel. English monolinguals and Dutch\textendash English bilinguals read an entire novel, which was presented in paragraphs on the screen. The bilinguals read half of the novel in their first language, and the other half in their second language. In this article, we describe the distributions and descriptive statistics of the most important reading time measures for the two groups of participants. This large eyetracking corpus is perfectly suited for both exploratory purposes and more directed hypothesis testing, and it can guide the formulation of ideas and theories about naturalistic reading processes in a meaningful context. Most importantly, this corpus has the potential to evaluate the generalizability of monolingual and bilingual language theories and models to the reading of long texts and narratives. The corpus is freely available at http://expsy.ugent.be/downloads/ geco.},
  language = {en},
  keywords = {megastudy}
}

@article{corteseParticipantsShiftResponse2017,
  title = {Participants Shift Response Deadlines Based on List Difficulty during Reading-Aloud Megastudies},
  author = {Cortese, Michael J. and Khanna, Maya M. and Kopp, Robert and Santo, Jonathan B. and Preston, Kailey S. and Van Zuiden, Tyler},
  year = {2017},
  journal = {Memory \& cognition},
  volume = {45},
  number = {4},
  pages = {589--599},
  keywords = {megastudy}
}

@incollection{corteseVisualWordRecognition2012,
  title = {Visual {{Word Recognition}} in {{Skilled Adult Readers}}},
  booktitle = {The {{Cambridge Handbook}} of {{Psycholinguistics}}},
  author = {Cortese, Michael J. and Balota, David A.},
  editor = {Spivey, M. and Joanisse, M. and McRae, K.},
  year = {2012},
  pages = {159--185},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, UK}},
  keywords = {psihologija-jezika}
}

@article{cortinaRestrictedVarianceInteraction2018,
  title = {Restricted {{Variance Interaction Effects}}: {{What They Are}} and {{Why They Are Your Friends}}},
  author = {Cortina, Jose M. and Koehler, Tine and Keeler, Kathleen R. and Nielsen, Bo Bernhard},
  year = {2018},
  journal = {Journal of Management},
  pages = {0149206318770735},
  keywords = {statistika}
}

@article{coxStatisticalScienceCurrent2020,
  title = {Statistical {{Science}}: {{Some Current Challenges}}},
  shorttitle = {Statistical {{Science}}},
  author = {Cox, David R. and Kartsonaki, Christiana and Keogh, Ruth},
  year = {2020},
  month = jul,
  journal = {Harvard Data Science Review},
  publisher = {{PubPub}},
  issn = {,},
  doi = {10.1162/99608f92.a6699bda},
  abstract = {A broad review is given of the role of statistical concepts in the design of studies, in various aspects of data collection and definition and especially in the analysis and interpretation of data. Outline examples are given from various fields of application with some emphasis on epidemiology and medical statistics. The role of probability in various stages of investigation is outlined, in particular its place in the assessment of uncertainty in the conclusions.},
  language = {en},
  keywords = {statistika}
}

@article{credeQuestionableResearchPractices2019,
  title = {Questionable Research Practices When Using Confirmatory Factor Analysis},
  author = {Crede, Marcus and Harms, Peter},
  year = {2019},
  month = feb,
  journal = {Journal of Managerial Psychology},
  volume = {34},
  number = {1},
  pages = {18--30},
  issn = {0268-3946},
  doi = {10.1108/JMP-06-2018-0272},
  abstract = {Purpose \textendash{} The purpose of this paper is to describe common questionable research practices (QRPs) engaged in by management researchers who use confirmatory factor analysis (CFA) as part of their analysis. Design/methodology/approach \textendash{} The authors describe seven questionable analytic practices and then review one year of journal articles published in three top-tier management journals to estimate the base rate of these practices.},
  language = {en},
  keywords = {confirmatory-factor-analysis,metodologija,statistika}
}

@article{cummingInferenceEyeConfidence2005,
  title = {Inference by Eye: Confidence Intervals and How to Read Pictures of Data.},
  author = {Cumming, Geoff and Finch, Sue},
  year = {2005},
  journal = {American Psychologist},
  volume = {60},
  number = {2},
  pages = {170},
  keywords = {effect-size,statistika}
}

@article{cummingPrimerUnderstandingUse2001,
  title = {A Primer on the Understanding, Use, and Calculation of Confidence Intervals That Are Based on Central and Noncentral Distributions},
  author = {Cumming, Geoff and Finch, Sue},
  year = {2001},
  journal = {Educational and Psychological Measurement},
  volume = {61},
  number = {4},
  pages = {532--574},
  keywords = {statistika}
}

@article{dareSerialParallelProcessing2013,
  title = {Serial and Parallel Processing in Reading: {{Investigating}} the Effects of Parafoveal Orthographic Information on Nonisolated Word Recognition},
  author = {Dare, Natasha and Shillcock, Richard},
  year = {2013},
  journal = {The Quarterly Journal of Experimental Psychology},
  volume = {66},
  number = {3},
  pages = {487--504},
  keywords = {flanker-task}
}

@book{darlingtonRegressionAnalysisLinear2016,
  title = {Regression Analysis and Linear Models: {{Concepts}}, Applications, and Implementation},
  author = {Darlington, Richard B and Hayes, Andrew F},
  year = {2016},
  publisher = {{Guilford Publications}},
  address = {{New York, NY}}
}

@techreport{DataProtectionGuide2020,
  title = {Data {{Protection Guide}}},
  year = {2020},
  pages = {42},
  institution = {{German Data Forum}},
  language = {en},
  file = {/home/denis/Zotero/storage/ETPUBM47/Data Protection Guide - 2nd fully revised edition.pdf}
}

@article{davis-stoberComparingAccuracyExperimental2014,
  title = {Comparing the Accuracy of Experimental Estimates to Guessing: {{A}} New Perspective on Replication and the ``Crisis of Confidence'' in Psychology},
  author = {{Davis-Stober}, Clintin P. and Dana, Jason},
  year = {2014},
  journal = {Behavior Research Methods},
  volume = {46},
  number = {1},
  pages = {1--14},
  keywords = {metodologija,statistika}
}

@book{davisonBootstrapMethodsTheir1997,
  title = {Bootstrap Methods and Their Application},
  author = {Davison, Anthony Christopher and Hinkley, David Victor},
  year = {1997},
  volume = {1},
  publisher = {{Cambridge university press}},
  isbn = {0-521-57471-4},
  keywords = {bootstrap}
}

@article{davisReFiningOrthographic2009,
  title = {Re (de) Fining the Orthographic Neighborhood: {{The}} Role of Addition and Deletion Neighbors in Lexical Decision and Reading.},
  author = {Davis, Colin J. and Perea, Manuel and Acha, Joana},
  year = {2009},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  volume = {35},
  number = {5},
  pages = {1550},
  keywords = {orthographic-neighborhood}
}

@techreport{debruineUnderstandingMixedEffects2019,
  type = {Preprint},
  title = {Understanding Mixed Effects Models through Data Simulation},
  author = {DeBruine, Lisa Marie and Barr, Dale J.},
  year = {2019},
  month = jun,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/xp5cy},
  abstract = {Experimental designs that sample both subjects and stimuli from a larger population need to account for random effects of both subjects and stimuli using mixed effects models. However, much of this research is analyzed using ANOVA on aggregated responses because researchers are not confident specifying and interpreting mixed effects models. The tutorial will explain how to simulate data with random effects structure and analyse the data using linear mixed effects regression (with the lme4 R package), with a focus on interpreting the output in light of the simulated parameters. Data simulation can not only enhance understanding of how these models work, but also enables researchers to perform power calculations for complex designs.},
  keywords = {multilevel,statistika}
}

@article{degrootMeaningSignificanceDifferent2014,
  title = {The Meaning of ``Significance'' for Different Types of Research [Translated and Annotated by {{Eric}}-{{Jan Wagenmakers}}, {{Denny Borsboom}}, {{Josine Verhagen}}, {{Rogier Kievit}}, {{Marjan Bakker}}, {{Angelique Cramer}}, {{Dora Matzke}}, {{Don Mellenbergh}}, and {{Han LJ}} van Der {{Maas}}]},
  author = {{de Groot}, Adrianus Dingeman},
  year = {2014},
  journal = {Acta psychologica},
  volume = {148},
  pages = {188--194},
  keywords = {meta-statistika,metodologija,p-vrijednosti}
}

@article{deutschMorphologicalParafovealPreview2005,
  title = {Morphological Parafoveal Preview Benefit Effects in Reading: {{Evidence}} from {{Hebrew}}},
  author = {Deutsch, Avital and Frost, Ram and Pollatsek, Alexander and Rayner, Keith},
  year = {2005},
  journal = {Language and Cognitive Processes},
  volume = {20},
  number = {1-2},
  pages = {341--371}
}

@techreport{devezerCaseFormalMethodology2020,
  type = {Preprint},
  title = {The Case for Formal Methodology in Scientific Reform},
  author = {Devezer, Berna and Navarro, Danielle J. and Vandekerckhove, Joachim and Buzbas, Erkan Ozge},
  year = {2020},
  month = apr,
  institution = {{Scientific Communication and Education}},
  doi = {10.1101/2020.04.26.048306},
  abstract = {Abstract           Current attempts at methodological reform in sciences come in response to an overall lack of rigor in methodological and scientific practices in experimental sciences. However, some of these reform attempts suffer from the same mistakes and over-generalizations they purport to address. Considering the costs of allowing false claims to become canonized, we argue for more rigor and nuance in methodological reform. By way of example, we present a formal analysis of three common claims in the metascientific literature: (a) that reproducibility is the cornerstone of science; (b) that data must not be used twice in any analysis; and (c) that exploratory projects are characterized by poor statistical practice. We show that none of these three claims are correct in general and we explore when they do and do not hold.},
  language = {en},
  keywords = {metodologija}
}

@article{devezerScientificDiscoveryModelcentric2019,
  title = {Scientific Discovery in a Model-Centric Framework: {{Reproducibility}}, Innovation, and Epistemic Diversity},
  shorttitle = {Scientific Discovery in a Model-Centric Framework},
  author = {Devezer, Berna and Nardin, Luis G. and Baumgaertner, Bert and Buzbas, Erkan Ozge},
  editor = {Fanelli, Daniele},
  year = {2019},
  month = may,
  journal = {PLOS ONE},
  volume = {14},
  number = {5},
  pages = {e0216125},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0216125},
  language = {en}
}

@article{dienesBayesianOrthodoxStatistics2011,
  title = {Bayesian versus Orthodox Statistics: {{Which}} Side Are You On?},
  author = {Dienes, Zoltan},
  year = {2011},
  journal = {Perspectives on Psychological Science},
  volume = {6},
  number = {3},
  pages = {274--290},
  keywords = {bayes,statistika}
}

@article{dienesUsingBayesGet2014,
  title = {Using {{Bayes}} to Get the Most out of Non-Significant Results},
  author = {Dienes, Zoltan},
  year = {2014},
  journal = {Frontiers in psychology},
  volume = {5},
  pages = {781},
  keywords = {bayes}
}

@article{dirix2018well,
  title = {How Well Do Word Recognition Measures Correlate? {{Effects}} of Language Context and Repeated Presentations},
  author = {Dirix, Nicolas and Brysbaert, Marc and Duyck, Wouter},
  year = {2018},
  journal = {Behavior research methods},
  pages = {1--17},
  publisher = {{Springer}},
  keywords = {metodologija,psihologija-jezika}
}

@article{dochtermannDevelopingMultipleHypotheses2011,
  title = {Developing Multiple Hypotheses in Behavioral Ecology},
  author = {Dochtermann, Ned A. and Jenkins, Stephen H.},
  year = {2011},
  month = jan,
  journal = {Behavioral Ecology and Sociobiology},
  volume = {65},
  number = {1},
  pages = {37--45},
  issn = {0340-5443, 1432-0762},
  doi = {10.1007/s00265-010-1039-4},
  language = {en},
  keywords = {multi-model-inference,statistika}
}

@misc{doornBayesFactorsMixed2021,
  title = {Bayes {{Factors}} for {{Mixed Models}}},
  author = {van Doorn, Johnny and Aust, Frederik and Haaf, Julia M. and Stefan, Angelika and Wagenmakers, Eric-Jan},
  year = {2021},
  month = feb,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/y65h8},
  abstract = {Although Bayesian mixed models are increasingly popular for data analysis in psychology and other fields, there remains considerable ambiguity on the most appropriate Bayes factor hypothesis test to quantify the degree to which the data support the presence or absence of an experimental effect. Specifically, different choices for both the null model and the alternative model are possible, and each choice constitutes a different definition of an effect resulting in a different test outcome. We outline the common approaches and focus on the impact of aggregation, the effect of measurement error, the choice of prior distribution, and the detection of interactions. For concreteness, three example scenarios showcase how seemingly innocuous choices can lead to dramatic differences in statistical evidence. We hope this work will facilitate a more explicit discussion about best practices in Bayes factor hypothesis testing in mixed models.},
  keywords = {statistika}
}

@article{dormannCollinearityReviewMethods2013,
  title = {Collinearity: A Review of Methods to Deal with It and a Simulation Study Evaluating Their Performance},
  shorttitle = {Collinearity},
  author = {Dormann, Carsten F. and Elith, Jane and Bacher, Sven and Buchmann, Carsten and Carl, Gudrun and Carr{\'e}, Gabriel and Marqu{\'e}z, Jaime R. Garc{\'i}a and Gruber, Bernd and Lafourcade, Bruno and Leit{\~a}o, Pedro J. and M{\"u}nkem{\"u}ller, Tamara and McClean, Colin and Osborne, Patrick E. and Reineking, Bj{\"o}rn and Schr{\"o}der, Boris and Skidmore, Andrew K. and Zurell, Damaris and Lautenbach, Sven},
  year = {2013},
  journal = {Ecography},
  volume = {36},
  number = {1},
  pages = {27--46},
  issn = {1600-0587},
  doi = {10.1111/j.1600-0587.2012.07348.x},
  abstract = {Collinearity refers to the non independence of predictor variables, usually in a regression-type analysis. It is a common feature of any descriptive ecological data set and can be a problem for parameter estimation because it inflates the variance of regression parameters and hence potentially leads to the wrong identification of relevant predictors in a statistical model. Collinearity is a severe problem when a model is trained on data from one region or time, and predicted to another with a different or unknown structure of collinearity. To demonstrate the reach of the problem of collinearity in ecology, we show how relationships among predictors differ between biomes, change over spatial scales and through time. Across disciplines, different approaches to addressing collinearity problems have been developed, ranging from clustering of predictors, threshold-based pre-selection, through latent variable methods, to shrinkage and regularisation. Using simulated data with five predictor-response relationships of increasing complexity and eight levels of collinearity we compared ways to address collinearity with standard multiple regression and machine-learning approaches. We assessed the performance of each approach by testing its impact on prediction to new data. In the extreme, we tested whether the methods were able to identify the true underlying relationship in a training dataset with strong collinearity by evaluating its performance on a test dataset without any collinearity. We found that methods specifically designed for collinearity, such as latent variable methods and tree based models, did not outperform the traditional GLM and threshold-based pre-selection. Our results highlight the value of GLM in combination with penalised methods (particularly ridge) and threshold-based pre-selection when omitted variables are considered in the final interpretation. However, all approaches tested yielded degraded predictions under change in collinearity structure and the `folk lore'-thresholds of correlation coefficients between predictor variables of |r| {$>$}0.7 was an appropriate indicator for when collinearity begins to severely distort model estimation and subsequent prediction. The use of ecological understanding of the system in pre-analysis variable selection and the choice of the least sensitive statistical approaches reduce the problems of collinearity, but cannot ultimately solve them.},
  language = {en},
  keywords = {collinearity,statistika}
}

@misc{dormannModelAveragingEcology2018,
  title = {Model Averaging in Ecology: A Review of {{Bayesian}}, Information-theoretic, and Tactical Approaches for Predictive Inference},
  shorttitle = {Model Averaging in Ecology},
  author = {Dormann, Carsten F. and Calabrese, Justin M. and Guillera-Arroita, Gurutzeta and Matechou, Eleni and Bahn, Volker and Barto{\'n}, Kamil and Beale, Colin M. and Ciuti, Simone and Elith, Jane and Gerstner, Katharina and Guelat, J{\'e}r{\^o}me and Keil, Petr and Lahoz-Monfort, Jos{\'e} J. and Pollock, Laura J. and Reineking, Bj{\"o}rn and Roberts, David R. and Schr{\"o}der, Boris and Thuiller, Wilfried and Warton, David I. and Wintle, Brendan A. and Wood, Simon N. and W{\"u}est, Rafael O. and Hartig, Florian},
  year = {2018},
  month = nov,
  journal = {Ecological Monographs},
  doi = {10.1002/ecm.1309},
  howpublished = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/ecm.1309},
  language = {en},
  keywords = {multi-model-inference,statistika},
  file = {/home/denis/Zotero/storage/8YRJ3HW5/ecm.html}
}

@article{draheimCombiningReactionTime2016,
  title = {Combining Reaction Time and Accuracy: {{The}} Relationship between Working Memory Capacity and Task Switching as a Case Example},
  author = {Draheim, Christopher and Hicks, Kenny L. and Engle, Randall W.},
  year = {2016},
  journal = {Perspectives on Psychological Science},
  volume = {11},
  number = {1},
  pages = {133--155},
  keywords = {metodologija}
}

@incollection{dreierQualityAssessmentMetaanalysis2013,
  title = {Quality {{Assessment}} in {{Meta}}-Analysis},
  booktitle = {Methods of {{Clinical Epidemiology}}},
  author = {Dreier, Maren},
  editor = {Doi, Suhail A. R. and Williams, Gail M.},
  year = {2013},
  pages = {213--228},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  abstract = {Quality assessment of primary studies to evaluate the reliability of study results is an essential and mandatory part of meta-analyses. It refers to the internal validity of a study and is described more precisely as assessing the risk of bias. Potential biases derive from selection of participants, data collection, analysis and selective reporting of study results. Quality assessment tools systematically collect information about study characteristics that may lead to bias in order to estimate the overall risk of bias. There are numerous tools available; they can be classified into checklists, scales and component ratings. Focusing on tools for assessing randomized controlled studies, an overview of covered elements of six selected generic tools is given. The Cochrane Collaboration's tool is described in more detail because it incorporates some important features. Practical aspects of conducting quality assessments are discussed including the meaning and importance of detailed and precise guidance.},
  isbn = {978-3-642-37131-8},
  keywords = {meta-analiza}
}

@book{edgeStatisticalThinkingScratch2019,
  title = {Statistical {{Thinking}} from {{Scratch}}: {{A Primer}} for {{Scientists}}},
  author = {Edge, M. D.},
  year = {2019},
  publisher = {{Oxford University Press, USA}},
  isbn = {0-19-882762-8},
  keywords = {statistika}
}

@article{edwardsBayesianStatisticalInference1963,
  title = {Bayesian Statistical Inference for Psychological Research.},
  author = {Edwards, Ward and Lindman, Harold and Savage, Leonard J.},
  year = {1963},
  journal = {Psychological review},
  volume = {70},
  number = {3},
  pages = {193},
  keywords = {bayes,statistika}
}

@article{efronPredictionEstimationAttribution2020,
  title = {Prediction, {{Estimation}}, and {{Attribution}}},
  author = {Efron, Bradley},
  year = {2020},
  month = apr,
  journal = {Journal of the American Statistical Association},
  volume = {115},
  number = {530},
  pages = {636--655},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.2020.1762613},
  abstract = {The scientific needs and computational limitations of the twentieth century fashioned classical statistical methodology. Both the needs and limitations have changed in the twenty-first, and so has the methodology. Large-scale prediction algorithms\textemdash neural nets, deep learning, boosting, support vector machines, random forests\textemdash have achieved star status in the popular press. They are recognizable as heirs to the regression tradition, but ones carried out at enormous scale and on titanic datasets. How do these algorithms compare with standard regression techniques such as ordinary least squares or logistic regression? Several key discrepancies will be examined, centering on the differences between prediction and estimation or prediction and attribution (significance testing). Most of the discussion is carried out through small numerical examples.},
  annotation = {\_eprint: https://doi.org/10.1080/01621459.2020.1762613}
}

@article{elliottWhatTestRetestReliability2020,
  title = {What {{Is}} the {{Test}}-{{Retest Reliability}} of {{Common Task}}-{{Functional MRI Measures}}? {{New Empirical Evidence}} and a {{Meta}}-{{Analysis}}},
  shorttitle = {What {{Is}} the {{Test}}-{{Retest Reliability}} of {{Common Task}}-{{Functional MRI Measures}}?},
  author = {Elliott, Maxwell L. and Knodt, Annchen R. and Ireland, David and Morris, Meriwether L. and Poulton, Richie and Ramrakha, Sandhya and Sison, Maria L. and Moffitt, Terrie E. and Caspi, Avshalom and Hariri, Ahmad R.},
  year = {2020},
  month = jun,
  journal = {Psychological Science},
  pages = {095679762091678},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797620916786},
  abstract = {Identifying brain biomarkers of disease risk is a growing priority in neuroscience. The ability to identify meaningful biomarkers is limited by measurement reliability; unreliable measures are unsuitable for predicting clinical outcomes. Measuring brain activity using task functional MRI (fMRI) is a major focus of biomarker development; however, the reliability of task fMRI has not been systematically evaluated. We present converging evidence demonstrating poor reliability of task-fMRI measures. First, a meta-analysis of 90 experiments (N = 1,008) revealed poor overall reliability\textemdash mean intraclass correlation coefficient (ICC) = .397. Second, the test-retest reliabilities of activity in a priori regions of interest across 11 common fMRI tasks collected by the Human Connectome Project (N = 45) and the Dunedin Study (N = 20) were poor (ICCs = .067\textendash.485). Collectively, these findings demonstrate that common task-fMRI measures are not currently suitable for brain biomarker discovery or for individual-differences research. We review how this state of affairs came to be and highlight avenues for improving task-fMRI reliability.},
  language = {en},
  keywords = {fmri,meta-science,metodologija}
}

@article{ercegEffectMoralCongruence2018,
  title = {The {{Effect}} of {{Moral Congruence}} of {{Calls}} to {{Action}} and {{Salient Social Norms}} on {{Online Charitable Donations}}: {{A Protocol Study}}},
  shorttitle = {The {{Effect}} of {{Moral Congruence}} of {{Calls}} to {{Action}} and {{Salient Social Norms}} on {{Online Charitable Donations}}},
  author = {Erceg, Nikola and Burghart, Matthias and Cottone, Alessia and Lorimer, Jessica and Manku, Kiran and P{\"u}tz, Hannah and Vla{\v s}i{\v c}ek, Denis and Willems, Manou},
  year = {2018},
  journal = {Frontiers in Psychology},
  volume = {9},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2018.01913},
  abstract = {Online advertising is an important tool that can be utilized by charities to elicit attention and funding. A critical examination of advertisement strategies is thus necessary to increase the efficacy of fundraising efforts. Previous studies have shown that individuals' moral views and perceptions of social norms can play important roles in charitable behavior. Thus, the current protocol describes a study to examine whether framing charitable advertisements in line with participants' morality and increasing the salience of descriptive social norms increases subsequent charitable behavior. We describe experimental, online methods, whereby participants are provided with a framed call-to-action and normative information within a custom-developed application or existing survey platform. Furthermore, in the exploratory fashion, we discuss the possibility of collecting participants' Facebook data and predicting moral profiles from this data. If there is an increased rate of donations as a result of moral compatibility and/or increased norm salience, charities can leverage this knowledge to increase the donations by tailoring their campaigns in a more appealing way for their prospective donors. Moreover, if it turns out to be possible to predict one's moral profile from Facebook footprints, charities can use this knowledge to find and target people that are more likely to support their cause. However, this introduces important ethical questions that are discussed within this protocol.},
  language = {English}
}

@article{eriksenEffectsNoiseLetters1974,
  title = {Effects of Noise Letters upon the Identification of a Target Letter in a Nonsearch Task},
  author = {Eriksen, Barbara A. and Eriksen, Charles W.},
  year = {1974},
  journal = {Perception \& psychophysics},
  volume = {16},
  number = {1},
  pages = {143--149},
  keywords = {flanker-task}
}

@article{eriksenFlankersTaskResponse1995,
  title = {The Flankers Task and Response Competition: {{A}} Useful Tool for Investigating a Variety of Cognitive Problems},
  author = {Eriksen, Charles W.},
  year = {1995},
  journal = {Visual Cognition},
  volume = {2},
  number = {2-3},
  pages = {101--118},
  keywords = {flanker-task}
}

@article{etzIntroductionBayesianInference2018,
  title = {Introduction to {{Bayesian}} Inference for Psychology},
  author = {Etz, Alexander and Vandekerckhove, Joachim},
  year = {2018},
  journal = {Psychonomic Bulletin \& Review},
  volume = {25},
  number = {1},
  pages = {5--34},
  keywords = {bayes,statistika}
}

@book{everittClusterAnalysis2011,
  title = {Cluster {{Analysis}}},
  author = {Everitt, Brian and Landau, Sabine and Leese, Morven and Stahl, Daniel},
  year = {2011},
  publisher = {{Wiley}},
  language = {en}
}

@incollection{farmerIndividualDifferencesSentence2012,
  title = {Individual Differences in Sentence Processing},
  booktitle = {Cambridge Handbook of Psycholinguistics},
  author = {Farmer, Thomas A and Misyak, Jennifer B and Christiansen, Morten H},
  editor = {Spivey, M. and Joanisse, M. and McRae, K.},
  year = {2012},
  pages = {353--364},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, UK}}
}

@article{faulStatisticalPowerAnalyses2009,
  title = {Statistical Power Analyses Using {{G}}* {{Power}} 3.1: {{Tests}} for Correlation and Regression Analyses},
  shorttitle = {Statistical Power Analyses Using {{G}}* {{Power}} 3.1},
  author = {Faul, Franz and Erdfelder, Edgar and Buchner, Axel and Lang, Albert-Georg},
  year = {2009},
  journal = {Behavior research methods},
  volume = {41},
  number = {4},
  pages = {1149--1160},
  keywords = {software,statistika}
}

@article{fenglerLikelihoodApproximationNetworks2021,
  title = {Likelihood Approximation Networks ({{LANs}}) for Fast Inference of Simulation Models in Cognitive Neuroscience},
  author = {Fengler, Alexander and Govindarajan, Lakshmi N and Chen, Tony and Frank, Michael J},
  editor = {Wyart, Valentin and Behrens, Timothy E and Acerbi, Luigi and Daunizeau, Jean},
  year = {2021},
  month = apr,
  journal = {eLife},
  volume = {10},
  pages = {e65074},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.65074},
  abstract = {In cognitive neuroscience, computational modeling can formally adjudicate between theories and affords quantitative fits to behavioral/brain data. Pragmatically, however, the space of plausible generative models considered is dramatically limited by the set of models with known likelihood functions. For many models, the lack of a closed-form likelihood typically impedes Bayesian inference methods. As a result, standard models are evaluated for convenience, even when other models might be superior. Likelihood-free methods exist but are limited by their computational cost or their restriction to particular inference scenarios. Here, we propose neural networks that learn approximate likelihoods for arbitrary generative models, allowing fast posterior sampling with only a one-off cost for model simulations that is amortized for future inference. We show that these methods can accurately recover posterior parameter distributions for a variety of neurocognitive process models. We provide code allowing users to deploy these methods for arbitrary hierarchical model instantiations without further training.},
  keywords = {computational-modeling,statistika}
}

@article{ferrandMEGALEXMegastudyVisual2018,
  ids = {ferrandMEGALEXMegastudyVisual2018a},
  title = {{{MEGALEX}}: {{A Megastudy}} of {{Visual}} and {{Auditory Word Recognition}}},
  author = {Ferrand, Ludovic and M{\'e}ot, Alain and Spinelli, Elsa and New, Boris and Pallier, Christophe and Bonin, Patrick and Dufau, St{\'e}phane and Math{\^o}t, Sebastiaan and Grainger, Jonathan},
  year = {2018},
  journal = {Behavior research methods},
  volume = {50},
  number = {3},
  pages = {1285--1307},
  keywords = {megastudy,psihologija-jezika}
}

@article{fiedlerLongWayAerror2012,
  title = {The Long Way from {$\alpha$}-Error Control to Validity Proper: {{Problems}} with a Short-Sighted False-Positive Debate},
  author = {Fiedler, Klaus and Kutzner, Florian and Krueger, Joachim I},
  year = {2012},
  journal = {Perspectives on Psychological Science},
  volume = {7},
  number = {6},
  pages = {661--669},
  keywords = {statistika}
}

@article{fiedlerToolsToysTruisms2004,
  title = {Tools, {{Toys}}, {{Truisms}}, and {{Theories}}: {{Some Thoughts}} on the {{Creative Cycle}} of {{Theory Formation}}},
  shorttitle = {Tools, {{Toys}}, {{Truisms}}, and {{Theories}}},
  author = {Fiedler, Klaus},
  year = {2004},
  month = may,
  journal = {Personality and Social Psychology Review},
  volume = {8},
  number = {2},
  pages = {123--131},
  issn = {1088-8683, 1532-7957},
  doi = {10.1207/s15327957pspr0802_5},
  language = {en},
  keywords = {filozofija-znanosti}
}

@book{fieldDiscoveringStatisticsUsing2012,
  title = {Discovering {{Statistics Using R}}},
  author = {Field, Andy and Miles, Jeremy and Field, Zoey},
  year = {2012},
  publisher = {{SAGE Publications Ltd}},
  address = {{Thousand Oaks, CA}}
}

@article{fischbacherZTreeZurichToolbox2007,
  title = {Z-{{Tree}}: {{Zurich}} Toolbox for Ready-Made Economic Experiments},
  author = {Fischbacher, Urs},
  year = {2007},
  journal = {Experimental economics},
  volume = {10},
  number = {2},
  pages = {171--178}
}

@techreport{flakeMeasurementSchmeasurementQuestionable2019,
  type = {Preprint},
  title = {Measurement {{Schmeasurement}}: {{Questionable Measurement Practices}} and {{How}} to {{Avoid Them}}},
  shorttitle = {Measurement {{Schmeasurement}}},
  author = {Flake, Jessica Kay and Fried, Eiko I},
  year = {2019},
  month = jan,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/hs7wm},
  abstract = {In this paper, we define questionable measurement practices (QMPs) as decisions researchers make that raise doubts about the validity of the measures, and ultimately the validity of study conclusions. Doubts arise for a host of reasons including a lack of transparency, ignorance, negligence, or misrepresentation of the evidence. We describe the scope of the problem and focus on how transparency is a part of the solution. A lack of measurement transparency makes it impossible to evaluate potential threats to internal, external, statistical conclusion, and construct validity. We demonstrate that psychology is plagued by a measurement schmeasurement attitude: QMPs are common, hide a stunning source of researcher degrees of freedom, pose a serious threat to cumulative psychological science, but are largely ignored. We address these challenges by providing a set of questions that researchers and consumers of scientific research can consider to identify and avoid QMPs. Transparent answers to these measurement questions promote rigorous research, allow for thorough evaluations of a study's inferences, and are necessary for meaningful replication studies.},
  language = {en},
  keywords = {statistika}
}

@misc{flisDisciplineMethodRecent2018,
  type = {Dissertation},
  title = {Discipline {{Through Method}}: {{Recent}} History and Philosophy of Scientific Psychology (1950-2018)},
  shorttitle = {Discipline {{Through Method}}},
  author = {Flis, I.},
  year = {2018},
  month = oct,
  journal = {FI Scientific Library},
  abstract = {Discipline Through Method investigates the disciplinary formation of scientific psychology in the second part of the twentieth century. In the period since the 1950s, research methods in scientific psychology were institutionalized across the varied communities of experimental, animal, educational, social, clinical, and applied psychologists. In the thesis, the epistemological implications of this institutionalization are discussed through the lens of existing historical and philosophical scholarship on scientific psychology's methods, and the criticism of those methods that has been gaining steam in the reform movement forming around the replication crisis in 2010s. Although the conventions of institutionalized scientific psychology have allowed psychologists to expand their field drastically since World War II, the thesis casts a critical look on the question whether that expansion in number of practitioners, researchers, journal articles, and journals has actually lead to what the scientific community perceives as cumulative growth in psychological knowledge. Methods and disciplinary formation of psychology are approached in three ways: through textbooks, journals, and psychologists' debates in the wake of the 2010s replication crisis. Textbooks were investigated as instructional manuals of disciplinary boundary-work, which provide expert psychologists with a platform for their broad views on the nature of psychology as a science. In particular, Hilgard's Introduction to Psychology was investigated because it went through thirteen editions in the period from 1950 to 2000, providing a unique view on the authors' choices in ``updating'' the textbook as psychology changed. Journals were approached in a different way \textendash{} by data-mining more than half a million titles/abstracts of journal articles retrieved from the APA's database PsycINFO. In this way, psychology's English-language literature was visualized, and the structure of that visualization was analyzed. The close-reading of Hilgard's textbook and the stable structure of the journal literature indicates a methodological core to how psychological research was conducted during the whole period. An evaluation of that methodological core is provided by focusing on the replication crisis debates and the views psychologists-reformers express on the current state and future reform of their disciplinary conventions and research practices.},
  copyright = {Open Access (free)},
  howpublished = {http://dspace.library.uu.nl/handle/1874/373086},
  language = {en},
  file = {/home/denis/Zotero/storage/K4HQP9Q7/373086.html}
}

@article{fongCovariateBalancingPropensity2018,
  title = {Covariate Balancing Propensity Score for a Continuous Treatment: {{Application}} to the Efficacy of Political Advertisements},
  shorttitle = {Covariate Balancing Propensity Score for a Continuous Treatment},
  author = {Fong, Christian and Hazlett, Chad and Imai, Kosuke},
  year = {2018},
  month = mar,
  journal = {The Annals of Applied Statistics},
  volume = {12},
  number = {1},
  pages = {156--177},
  issn = {1932-6157},
  doi = {10.1214/17-AOAS1101},
  language = {en},
  keywords = {causal-inference,statistika}
}

@book{foxAppliedRegressionAnalysis2015,
  title = {Applied Regression Analysis and Generalized Linear Models},
  author = {Fox, John},
  year = {2015},
  publisher = {{Sage Publications}},
  keywords = {statistika},
  file = {/home/denis/Zotero/storage/4CG4Z2S2/books.html}
}

@book{foxCompanionAppliedRegression2011,
  title = {An {{R Companion}} to {{Applied Regression}}},
  author = {Fox, John and Weisberg, Sanford},
  year = {2011},
  edition = {Second},
  publisher = {{Sage}},
  address = {{Thousand Oaks CA}}
}

@book{foxCompanionAppliedRegression2018,
  title = {An {{R}} Companion to Applied Regression},
  author = {Fox, John and Weisberg, Sanford},
  year = {2018},
  publisher = {{Sage Publications}},
  keywords = {statistika},
  file = {/home/denis/Zotero/storage/H652FBVW/books.html}
}

@article{francisFrequencyExcessSuccess2014,
  title = {The Frequency of Excess Success for Articles in {{Psychological Science}}},
  author = {Francis, Gregory},
  year = {2014},
  journal = {Psychonomic bulletin \& review},
  volume = {21},
  number = {5},
  pages = {1180--1187},
  keywords = {metodologija}
}

@article{francisTooGoodBe2012,
  title = {Too Good to Be True: {{Publication}} Bias in Two Prominent Studies from Experimental Psychology},
  author = {Francis, Gregory},
  year = {2012},
  journal = {Psychonomic bulletin \& review},
  volume = {19},
  number = {2},
  pages = {151--156},
  keywords = {metodologija}
}

@article{freckletonDealingCollinearityBehavioural2011,
  title = {Dealing with Collinearity in Behavioural and Ecological Data: Model Averaging and the Problems of Measurement Error},
  shorttitle = {Dealing with Collinearity in Behavioural and Ecological Data},
  author = {Freckleton, Robert P.},
  year = {2011},
  journal = {Behavioral Ecology and Sociobiology},
  volume = {65},
  number = {1},
  pages = {91--101},
  keywords = {collinearity,statistika}
}

@techreport{friedLackTheoryBuilding2020,
  type = {Preprint},
  title = {Lack of Theory Building and Testing Impedes Progress in the Factor and Network Literature},
  author = {Fried, Eiko I},
  year = {2020},
  month = feb,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/zg84s},
  abstract = {The last decade has brought reforms to improve methodological practices, with the goal to increase the reliability and replicability of effects. However, explanations of effects remain scarce, and a growing chorus of scholars argues that the replicability crisis has distracted from a crisis of theory. In the same decade, the empirical literature using factor and network models has grown rapidly. I discuss three ways in which this literature falls short of theory building and testing. First, statistical and theoretical models are conflated, leading to invalid inferences such as the existence of psychological constructs based on factor models, or recommendations for clinical interventions based on network models. I demonstrate this inferential gap in a simulation study on statistical equivalence: excellent model fit does little to corroborate a theory, regardless of quality or quantity of data. Second, researchers fail to explicate theories about psychological constructs, but use implicit causal beliefs to guide inferences. These latent theories have led to problematic best practices in psychological research where inferences are drawn based on one specific causal model that is assumed, but not explicated. Third, explicated theories are often weak theories: narrative and imprecise descriptions vulnerable to hidden assumptions and unknowns. They fail to make clear predictions, and it remains unclear whether statistical effects corroborate such theories or not. Weak theories are immune to refutation or revision. I argue that these three challenges to theory building and testing are common and harmful, and impede theory formation, failure, and reform. A renewed focus on theoretical psychology and formal models offers a way forward.},
  language = {en},
  keywords = {metodologija,statistika}
}

@book{friedmanElementsStatisticalLearning2001,
  title = {The {{Elements}} of {{Statistical Learning}}},
  author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
  year = {2001},
  volume = {1},
  publisher = {{Springer series in statistics New York}},
  keywords = {statistika}
}

@article{friedmanGraphicalViewsSuppression2005,
  title = {Graphical Views of Suppression and Multicollinearity in Multiple Linear Regression},
  author = {Friedman, Lynn and Wall, Melanie},
  year = {2005},
  journal = {The American Statistician},
  volume = {59},
  number = {2},
  pages = {127--136},
  keywords = {collinearity,regresija,statistika,suppressor},
  file = {/home/denis/Zotero/storage/M3ERXMNZ/000313005X41337.html}
}

@article{friedmanRelationsInhibitionInterference2004,
  title = {The Relations among Inhibition and Interference Control Functions: A Latent-Variable Analysis.},
  author = {Friedman, Naomi P. and Miyake, Akira},
  year = {2004},
  journal = {Journal of experimental psychology: General},
  volume = {133},
  number = {1},
  pages = {101},
  keywords = {flanker-task}
}

@book{friendlyCandiscVisualizingGeneralized2017,
  title = {Candisc: {{Visualizing Generalized Canonical Discriminant}} and {{Canonical Correlation Analysis}}},
  author = {Friendly, Michael and Fox, John},
  year = {2017}
}

@article{futrellNaturalStoriesCorpus,
  title = {The {{Natural Stories Corpus}}},
  author = {Futrell, Richard and Gibson, Edward and Tily, Harry J and Blank, Idan and Vishnevetsky, Anastasia and Piantadosi, Steven T and Fedorenko, Evelina},
  pages = {7},
  abstract = {It is now a common practice to compare models of human language processing by comparing how well they predict behavioral and neural measures of processing difficulty, such as reading times, on corpora of rich naturalistic linguistic materials. However, many of these corpora, which are based on naturally-occurring text, do not contain many of the low-frequency syntactic constructions that are often required to distinguish between processing theories. Here we describe a new corpus consisting of English texts edited to contain many low-frequency syntactic constructions while still sounding fluent to native speakers. The corpus is annotated with hand-corrected Penn Treebank-style parse trees and includes self-paced reading time data and aligned audio recordings. Here we give an overview of the content of the corpus and release the data.},
  language = {en},
  keywords = {megastudy}
}

@article{gabryVisualizationBayesianWorkflow2019,
  title = {Visualization in {{Bayesian}} Workflow},
  author = {Gabry, Jonah and Simpson, Daniel and Vehtari, Aki and Betancourt, Michael and Gelman, Andrew},
  year = {2019},
  journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  volume = {182},
  number = {2},
  pages = {389--402},
  issn = {1467-985X},
  doi = {10.1111/rssa.12378},
  abstract = {Bayesian data analysis is about more than just computing a posterior distribution, and Bayesian visualization is about more than trace plots of Markov chains. Practical Bayesian data analysis, like all data analysis, is an iterative process of model building, inference, model checking and evaluation, and model expansion. Visualization is helpful in each of these stages of the Bayesian workflow and it is indispensable when drawing inferences from the types of modern, high dimensional models that are used by applied researchers.},
  language = {en},
  keywords = {statistika},
  annotation = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssa.12378},
  file = {/home/denis/Zotero/storage/LP2SNKIJ/rssa.html}
}

@article{galipaudEcologistsOverestimateImportance2014,
  title = {Ecologists Overestimate the Importance of Predictor Variables in Model Averaging: A Plea for Cautious Interpretations},
  shorttitle = {Ecologists Overestimate the Importance of Predictor Variables in Model Averaging},
  author = {Galipaud, Matthias and Gillingham, Mark A. F. and David, Morgan and Dechaume-Moncharmont, Fran{\c c}ois-Xavier},
  year = {2014},
  journal = {Methods in Ecology and Evolution},
  volume = {5},
  number = {10},
  pages = {983--991},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.12251},
  abstract = {Information-theory procedures are powerful tools for multimodel inference and are now standard methods in ecology. When performing model averaging on a given set of models, the importance of a predictor variable is commonly estimated by summing the weights of models where the variable appears, the so-called sum of weights (SW). However, SWs have received little methodological attention and are frequently misinterpreted. We assessed the reliability of SW by performing model selection and averaging on simulated data sets including variables strongly and weakly correlated to the response variable and a variable unrelated to the response. Our aim was to investigate how useful SWs are to inform about the relative importance of predictor variables. SW can take a wide range of possible values, even for predictor variables unrelated to the response. As a consequence, SW with intermediate values cannot be confidently interpreted as denoting importance for the considered predictor variable. Increasing sample size using an alternative information criterion for model selection or using only a subset of candidate models for model averaging did not qualitatively change our results: a variable of a given effect size can take a wide range of SW values. Contrary to what is assumed in many ecological studies, it seems hazardous to define a threshold for SW above which a variable is considered as having a statistical effect on the response and SW is not a measure of effect size. Although we did not consider every possible condition of analysis, it is likely that in most situations, SW is a poor estimate of variable's importance.},
  language = {en},
  keywords = {multi-model-inference,statistika}
}

@article{galipaudFarewellSumAkaike2017,
  title = {A Farewell to the Sum of {{Akaike}} Weights: {{The}} Benefits of Alternative Metrics for Variable Importance Estimations in Model Selection},
  shorttitle = {A Farewell to the Sum of {{Akaike}} Weights},
  author = {Galipaud, Matthias and Gillingham, Mark A. F. and {Dechaume-Moncharmont}, Fran{\c c}ois-Xavier},
  editor = {Freckleton, Robert},
  year = {2017},
  month = dec,
  journal = {Methods in Ecology and Evolution},
  volume = {8},
  number = {12},
  pages = {1668--1678},
  issn = {2041210X},
  doi = {10.1111/2041-210X.12835},
  language = {en},
  keywords = {multi-model-inference,statistika}
}

@article{gaoSelectiveInferenceHierarchical2020,
  title = {Selective {{Inference}} for {{Hierarchical Clustering}}},
  author = {Gao, Lucy L. and Bien, Jacob and Witten, Daniela},
  year = {2020},
  month = dec,
  journal = {arXiv:2012.02936 [stat]},
  eprint = {2012.02936},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Testing for a difference in means between two groups is fundamental to answering research questions across virtually every scientific area. Classical tests control the Type I error rate when the groups are defined a priori. However, when the groups are instead defined via a clustering algorithm, then applying a classical test for a difference in means between the groups yields an extremely inflated Type I error rate. Notably, this problem persists even if two separate and independent data sets are used to define the groups and to test for a difference in their means. To address this problem, in this paper, we propose a selective inference approach to test for a difference in means between two clusters obtained from any clustering method. Our procedure controls the selective Type I error rate by accounting for the fact that the null hypothesis was generated from the data. We describe how to efficiently compute exact p-values for clusters obtained using agglomerative hierarchical clustering with many commonly used linkages. We apply our method to simulated data and to single-cell RNA-seq data.},
  archiveprefix = {arXiv},
  language = {en},
  keywords = {statistika},
  file = {/home/denis/Zotero/storage/JSFUJ94F/Gao et al. - 2020 - Selective Inference for Hierarchical Clustering.pdf}
}

@book{garnierViridisDefaultColor2018,
  title = {Viridis: {{Default Color Maps}} from 'Matplotlib'},
  author = {Garnier, Simon},
  year = {2018}
}

@book{gelmanArmDataAnalysis2018,
  title = {Arm: {{Data Analysis Using Regression}} and {{Multilevel}}/{{Hierarchical Models}}},
  author = {Gelman, Andrew and Su, Yu-Sung},
  year = {2018},
  keywords = {software}
}

@book{gelmanBayesianDataAnalysis2013,
  title = {Bayesian {{Data Analysis}}},
  author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
  year = {2013},
  publisher = {{CRC press}},
  isbn = {1-4398-4095-4}
}

@article{gelmanBayesianWorkflow2020,
  title = {Bayesian {{Workflow}}},
  author = {Gelman, Andrew and Vehtari, Aki and Simpson, Daniel and Margossian, Charles C. and Carpenter, Bob and Yao, Yuling and Kennedy, Lauren and Gabry, Jonah and B{\"u}rkner, Paul-Christian and Modr{\'a}k, Martin},
  year = {2020},
  month = nov,
  journal = {arXiv:2011.01808 [stat]},
  eprint = {2011.01808},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {The Bayesian approach to data analysis provides a powerful way to handle uncertainty in all observations, model parameters, and model structure using probability theory. Probabilistic programming languages make it easier to specify and fit Bayesian models, but this still leaves us with many options regarding constructing, evaluating, and using these models, along with many remaining challenges in computation. Using Bayesian inference to solve real-world problems requires not only statistical skills, subject matter knowledge, and programming, but also awareness of the decisions made in the process of data analysis. All of these aspects can be understood as part of a tangled workflow of applied Bayesian statistics. Beyond inference, the workflow also includes iterative model building, model checking, validation and troubleshooting of computational problems, model understanding, and model comparison. We review all these aspects of workflow in the context of several examples, keeping in mind that in practice we will be fitting many models for any given problem, even if only a subset of them will ultimately be relevant for our conclusions.},
  archiveprefix = {arXiv},
  file = {/home/denis/Zotero/storage/Q93W4ZWQ/2011.html}
}

@book{gelmanDataAnalysisUsing2007,
  title = {Data {{Analysis Using Regression}} and {{Multilevel}}/{{Hierarchical Models}}},
  author = {Gelman, Andrew and Hill, Jennifer},
  year = {2007},
  publisher = {{Cambridge university press}},
  keywords = {multilevel,regresija,statistika}
}

@article{gelmanGardenForkingPaths2013,
  title = {The {{Garden}} of {{Forking Paths}}: {{Why Multiple Comparisons}} Can Be a {{Problem}}, {{Even When There}} Is No ``{{Fishing Expedition}}'' or ``p-Hacking'' and the {{Research Hypothesis}} Was {{Posited Ahead}} of {{Time}}},
  author = {Gelman, Andrew and Loken, Eric},
  year = {2013},
  journal = {Department of Statistics, Columbia University},
  keywords = {meta-statistika,metodologija}
}

@article{gelmanPriorCanOften2017,
  title = {The {{Prior Can Often Only Be Understood}} in the {{Context}} of the {{Likelihood}}},
  author = {Gelman, Andrew and Simpson, Daniel and Betancourt, Michael},
  year = {2017},
  month = oct,
  journal = {Entropy},
  volume = {19},
  number = {10},
  pages = {555},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/e19100555},
  abstract = {A key sticking point of Bayesian analysis is the choice of prior distribution, and there is a vast literature on potential defaults including uniform priors, Jeffreys' priors, reference priors, maximum entropy priors, and weakly informative priors. These methods, however, often manifest a key conceptual tension in prior modeling: a model encoding true prior information should be chosen without reference to the model of the measurement process, but almost all common prior modeling techniques are implicitly motivated by a reference likelihood. In this paper we resolve this apparent paradox by placing the choice of prior into the context of the entire Bayesian analysis, from inference to prediction to model evaluation.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  language = {en},
  keywords = {statistika},
  file = {/home/denis/Zotero/storage/9L5NUBZZ/555.html}
}

@article{genestEverythingYouAlways2007,
  title = {Everything {{You Always Wanted}} to {{Know}} about {{Copula Modeling}} but {{Were Afraid}} to {{Ask}}},
  author = {Genest, Christian and Favre, Anne-Catherine},
  year = {2007},
  month = jul,
  journal = {Journal of Hydrologic Engineering},
  volume = {12},
  number = {4},
  pages = {347--368},
  publisher = {{American Society of Civil Engineers}},
  issn = {1084-0699},
  doi = {10.1061/(ASCE)1084-0699(2007)12:4(347)},
  abstract = {This paper presents an introduction to inference for copula models, based on rank methods. By working out in detail a small, fictitious numerical example, the writers exhibit the various steps involved in investigating the dependence between two random variables and in modeling it using copulas. Simple graphical tools and numerical techniques are presented for selecting an appropriate model, estimating its parameters, and checking its goodness-of-fit. A larger, realistic application of the methodology to hydrological data is then presented.},
  language = {EN},
  keywords = {copula,statistika},
  file = {/home/denis/Zotero/storage/A8RWEP7I/(ASCE)1084-0699(2007)124(347).html}
}

@article{geyerFeatureListsConfusion1973,
  title = {Feature Lists and Confusion Matrices},
  author = {Geyer, L. H. and DeWald, C. G.},
  year = {1973},
  month = oct,
  journal = {Perception \& Psychophysics},
  volume = {14},
  number = {3},
  pages = {471--482},
  issn = {1532-5962},
  doi = {10.3758/BF03211185},
  abstract = {This report compares three feature list sets for capital letters, previously proposed by different investigators, on the ability of each to predict empirical confusion matrices. Toward this end, several variants of assumed information processes in recognition were also compared. The best model incorporated: (1) variable feature retrieval probabilities, (2) a goodness-of-match lower threshold below which guessing determines response, and (3) response bias on guessing trials. This model, when combined with one particular proposed feature list set, produced stress values of less than 9\% in comparisons to empirical matrices for each of three different Ss. The feature retrieval probability vectors associated with these minimum-stress predictions were highly correlated (\$\$\textbackslash bar r = .83\$\$), suggesting considerable generality of process and feature sets between Ss.},
  language = {en},
  keywords = {psihologija-jezika}
}

@article{giamQuantifyingVariableImportance2016,
  title = {Quantifying Variable Importance in a Multimodel Inference Framework},
  author = {Giam, Xingli and Olden, Julian D.},
  year = {2016},
  journal = {Methods in Ecology and Evolution},
  pages = {388--397},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.12492@10.1111/(ISSN)2041-210X.StatisticalEcology},
  abstract = {The sum of Akaike weights (SW) is often used to quantify relative variable importance (RVI) within the information-theoretic (IT) multimodel inference framework. A recent study (Galipaud et al. 2014, Methods in Ecology and Evolution 5: 983) questioned the validity of the SW approach. Regrettably, this study is flawed because SW was evaluated with an inappropriate benchmark. Irrespective of this study's methodological issues, RVI metrics based on the relative contribution of explanatory variables in explaining the variance in the response variable (partitioned R2-based) are lacking in multimodel inference. We re-evaluated the validity of SW by repeating Galipaud et al.'s experiment but with an appropriate benchmark. When explanatory variables are uncorrelated, the quantity that SW estimates (i.e. the probability that a variable is included in the actual best IT model) is monotonically related to squared zero-order correlation coefficients (r2) between explanatory variables and the response variable. The degree of correspondence between SW and r2 rankings (not values) of variables in data sets with uncorrelated explanatory variables was therefore used as a benchmark to evaluate the validity of SW as a RVI metric. To address the lack of partitioned R2-based RVI metrics in multimodel inference, we proposed 2 metrics: (a) Iweighted, the average model probability-weighted partitioned R2; and (b) Ibest, the partitioned R2 derived from the best IT model. We performed Monte Carlo simulations to evaluate the utility of Iweighted and Ibest versus partitioned R2 derived from the global model (Iglobal). SW rankings matched r2 rankings of variables; therefore, SW is a valid measure of RVI. Among partitioned R2-based metrics, Iweighted and Iglobal were generally more accurate in estimating the population partitioned R2. Iweighted performed better when explanatory variables were uncorrelated, whereas Iglobal was better in smaller data sets with correlated explanatory variables. To improve the utility of Iweighted in such data sets, we proposed approaches to eliminate or reduce the influence of correlated variables. Despite recent criticisms, our results show that SW is a valid RVI metric. To quantify RVI in terms of the R2 explained by each variable, Iweighted and Iglobal are the preferred RVI metrics.},
  copyright = {\textcopyright{} 2015 The Authors. Methods in Ecology and Evolution \textcopyright{} 2015 British Ecological Society},
  language = {en},
  keywords = {multi-model-inference,statistika}
}

@article{gischeForecastingCausalEffects2020,
  title = {Forecasting {{Causal Effects}} of {{Interventions}} versus {{Predicting Future Outcomes}}},
  author = {Gische, Christian and West, Stephen G. and Voelkle, Manuel C.},
  year = {2020},
  month = sep,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  pages = {1--18},
  issn = {1070-5511, 1532-8007},
  doi = {10.1080/10705511.2020.1780598},
  abstract = {The present article provides a didactic presentation and extension of selected features of Pearl's DAG-based approach to causal inference for researchers familiar with structural equation modeling. We illustrate key concepts using a cross-lagged panel design. We distinguish between (a) forecasts of the value of an outcome variable after an intervention and (b) predictions of future values of an outcome variable. We consider the mean level and variance of the outcome variable as well as the probability that the outcome will fall within an acceptable range. We extend this basic approach to include additive random effects, allowing us to distinguish between average effects of interventions and person-specific effects of interven\- tions. We derive optimal person-specific treatment levels and show that optimal treatment levels may differ across individuals. We present worked examples using simulated data based on the results of a prior empirical study of the relationship between blood insulin and glucose levels.},
  language = {en},
  keywords = {causal-inference,statistika}
}

@article{godfrey-smithStrategyModelbasedScience2006,
  title = {The Strategy of Model-Based Science},
  author = {{Godfrey-Smith}, Peter},
  year = {2006},
  journal = {Biology and philosophy},
  volume = {21},
  number = {5},
  pages = {725--740},
  publisher = {{Springer}},
  keywords = {filozofija-znanosti}
}

@article{gohSemanticRichnessEffects2016,
  title = {Semantic {{Richness Effects}} in {{Spoken Word Recognition}}: {{A Lexical Decision}} and {{Semantic Categorization Megastudy}}},
  shorttitle = {Semantic {{Richness Effects}} in {{Spoken Word Recognition}}},
  author = {Goh, Winston D. and Yap, Melvin J. and Lau, Mabel C. and Ng, Melvin M. R. and Tan, Luuan-Chin},
  year = {2016},
  month = jun,
  journal = {Frontiers in Psychology},
  volume = {7},
  pages = {976},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2016.00976},
  abstract = {A large number of studies have demonstrated that semantic richness dimensions [e.g., number of features, semantic neighborhood density, semantic diversity, concreteness, emotional valence] influence word recognition processes. Some of these richness effects appear to be task-general, while others have been found to vary across tasks. Importantly, almost all of these findings have been found in the visual word recognition literature. To address this gap, we examined the extent to which these semantic richness effects are also found in spoken word recognition, using a megastudy approach that allows for an examination of the relative contribution of the various semantic properties to performance in two tasks: lexical decision, and semantic categorization. The results show that concreteness, valence, and number of features accounted for unique variance in latencies across both tasks in a similar direction\textemdash faster responses for spoken words that were concrete, emotionally valenced, and with a high number of features\textemdash while arousal, semantic neighborhood density, and semantic diversity did not influence latencies. Implications for spoken word recognition processes are discussed.},
  language = {en},
  keywords = {megastudy}
}

@article{graesserCohMetrixAnalysisText2004,
  title = {Coh-{{Metrix}}: {{Analysis}} of Text on Cohesion and Language},
  author = {Graesser, Arthur C and McNamara, Danielle S and Louwerse, Max M and Cai, Zhiqiang},
  year = {2004},
  journal = {Behavior research methods, instruments, \& computers},
  volume = {36},
  number = {2},
  pages = {193--202},
  keywords = {coh-metrix}
}

@article{graingerLetterPerceptionPixels2008,
  title = {Letter Perception: From Pixels to Pandemonium},
  shorttitle = {Letter Perception},
  author = {Grainger, Jonathan and Rey, Arnaud and Dufau, St{\'e}phane},
  year = {2008},
  month = oct,
  journal = {Trends in Cognitive Sciences},
  volume = {12},
  number = {10},
  pages = {381--387},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2008.06.006},
  abstract = {In 1959, Oliver Selfridge proposed a model of letter perception, the Pandemonium model, in which the central hypothesis was that letters are identified via their component features. Although a consensus developed around this general approach over the years, key evidence in its favor remained lacking. Recent research has started to provide important evidence in favor of feature-based letter perception, describing the nature of the features, and the time-course of processes involved in mapping features onto abstract letter identities. There is now hope that future `pandemonium-like' models will be able to account for the rich empirical database on letter identification that has accumulated over the past 50 years, hence solving one key component of the reading process.},
  language = {en},
  keywords = {psihologija-jezika}
}

@article{greenlandCausalDiagramsEpidemiologic1999,
  title = {Causal {{Diagrams}} for {{Epidemiologic Research}}},
  author = {Greenland, Sander and Pearl, Judea and Robins, James M.},
  year = {1999},
  journal = {Epidemiology},
  volume = {10},
  number = {1},
  pages = {37--48},
  abstract = {Causal diagrams have a long history of informal use and, more recently, have undergone formal development for applications in expert systems and robotics. We provide an introduction to these developments and their use in epidemiologic research. Causal diagrams can provide a starting point for identifying variables that must be measured and controlled to obtain unconfounded effect estimates. They also provide a method for critical evaluation of traditional epidemiologic criteria for confounding. In particular, they reveal certain heretofore unnoticed shortcomings of those criteria when used in considering multiple potential confounders. We show how to modify the traditional criteria to correct those shortcomings. (Epidemiology 1999;10:37\textendash 48) \textcopyright{} 1999 Lippincott Williams \& Wilkins, Inc.},
  isbn = {1044-3983},
  keywords = {causal-inference,dag,statistika},
  annotation = {Accession Number: 00001648-199901000-00008}
}

@article{greenlandFALLACYEMPLOYINGSTANDARDIZED1986,
  title = {{{THE FALLACY OF EMPLOYING STANDARDIZED REGRESSION COEFFICIENTS AND CORRELATIONS AS MEASURES OF EFFECT}}},
  author = {Greenland, Sander and Schlesselman, James J. and Criqui, Michael H.},
  year = {1986},
  month = feb,
  journal = {American Journal of Epidemiology},
  volume = {123},
  number = {2},
  pages = {203--208},
  issn = {0002-9262},
  doi = {10.1093/oxfordjournals.aje.a114229},
  abstract = {SANDER GREENLAND, JAMES J. SCHLESSELMAN, MICHAEL H. CRIQUI;  THE FALLACY OF EMPLOYING STANDARDIZED REGRESSION COEFFICIENTS AND CORRELATIONS AS MEASURES OF EFFEC},
  language = {en},
  keywords = {regresija,statistika},
  file = {/home/denis/Zotero/storage/VY3QVTD4/57724.html}
}

@article{greenlandStatisticalTestsPalues2016,
  title = {Statistical {{Tests}}, p-Alues, {{Confidence Intervals}}, and {{Power}}: {{A Guide}} to {{Misinterpretations}}},
  shorttitle = {Statistical Tests, {{P}} Values, Confidence Intervals, and Power},
  author = {Greenland, Sander and Senn, Stephen J. and Rothman, Kenneth J. and Carlin, John B. and Poole, Charles and Goodman, Steven N. and Altman, Douglas G.},
  year = {2016},
  month = apr,
  journal = {European Journal of Epidemiology},
  volume = {31},
  number = {4},
  pages = {337--350},
  issn = {0393-2990, 1573-7284},
  doi = {10.1007/s10654-016-0149-3},
  language = {en},
  keywords = {statistika}
}

@article{greenSimrPackagePower2016,
  ids = {greenSIMRPackagePower2016b},
  title = {Simr: {{An R Package}} for {{Power Analysis}} of {{Generalized Linear Mixed Models}} by {{Simulation}}},
  shorttitle = {{{SIMR}}},
  author = {Green, Peter and MacLeod, Catriona J.},
  year = {2016},
  month = apr,
  journal = {Methods in Ecology and Evolution},
  volume = {7},
  number = {4},
  pages = {493--498},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.12504},
  abstract = {Summary The r package simr allows users to calculate power for generalized linear mixed models from the lme4 package. The power calculations are based on Monte Carlo simulations. It includes tools for (i) running a power analysis for a given model and design; and (ii) calculating power curves to assess trade-offs between power and sample size. This paper presents a tutorial using a simple example of count data with mixed effects (with structure representative of environmental monitoring data) to guide the user along a gentle learning curve, adding only a few commands or options at a time.},
  keywords = {multilevel,software,stat-power}
}

@article{grueber2011multimodel,
  title = {Multimodel Inference in Ecology and Evolution: Challenges and Solutions},
  author = {Grueber, CE and Nakagawa, S and Laws, RJ and Jamieson, IG},
  year = {2011},
  journal = {Journal of evolutionary biology},
  volume = {24},
  number = {4},
  pages = {699--711},
  publisher = {{Wiley Online Library}},
  keywords = {information-theory,multi-model-inference,statistika}
}

@techreport{gruijtersFallacyManipulationChecks2020,
  title = {On the Fallacy of Manipulation "Checks" and the Road towards Strong Inference},
  author = {Gruijters, Stefan},
  year = {2020},
  month = aug,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/fkzv5},
  abstract = {Manipulation checks are often included in studies to boost confidence in a particular causal explanation. As a general principle, it is worthwhile to have some degree of certainty that a manipulation or treatment caused variation in the independent variable of interest. However, this paper purports that manipulation checks do not pave the way towards inferential confidence. This paper posits that a) manipulation checks do not improve our causal explanations, and b) that they are potential threats to internal validity. Rather than useful, manipulation checks are at best uninformative, but more likely compromise the interpretation of experimental results. The second half of this paper advocates alternative approaches to test a causal explanation, emphasizing a need to focus on the exclusion of rival explanations. I conclude that rather than relying on manipulation checks as a `Band-Aid' method to alleviate validity concerns, inferential rigor can be improved by generating and excluding alternative explanations for a given effect.}
}

@article{gruszkaHandbookIndividualDifferences2010,
  title = {Handbook of Individual Differences in Cognition},
  author = {Gruszka, Aleksandra and Matthews, Gerald and Szymura, B{\l}a{\.z}ej},
  year = {2010},
  journal = {Attention, Memory and Executive Control ``Heidelberg London: Springer New York}
}

@techreport{guestHowComputationalModeling2020,
  type = {Preprint},
  title = {How Computational Modeling Can Force Theory Building in Psychological Science},
  author = {Guest, Olivia and Martin, Andrea E.},
  year = {2020},
  month = feb,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/rybh9},
  abstract = {Psychology endeavors to develop theories of human capacities and behaviors based on a variety of methodologies and dependent measures. We argue that one of the most divisive factors in our field is whether researchers choose to employ computational modeling of theories (over and above data) during the scientific inference process. Modeling is undervalued, yet holds promise for advancing psychological science. The inherent demands of computational modeling guide us towards better science by forcing us to conceptually analyze, specify, and formalise intuitions which otherwise remain unexamined \textemdash{} what we dub ``open theory''. Constraining our inference process through modeling enables us to build explanatory and predictive theories. Herein, we present scientific inference in psychology as a path function, where each step shapes the next. Computational modeling can constrain these steps, thus advancing scientific inference over and above stewardship of experimental practice (e.g., preregistration). If psychology continues to eschew computational modeling, we predict more replicability ``crises'' and persistent failure at coherent theory-building. This is because without formal modelling we lack open and transparent theorising. We also explain how to formalise, specify, and implement a computational model, emphasizing that the advantages of modeling can be achieved by anyone with benefit to all.}
}

@misc{haigUnderstandingReplicationWay2020,
  title = {Understanding {{Replication}} in a {{Way That}} Is {{True}} to {{Science}}},
  author = {Haig, Brian},
  year = {2020},
  month = oct,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/v784s},
  abstract = {In this article, I critically examine a number of widely held beliefs about the nature of replication and its place in science, with particular reference to psychology. In doing so, I present a number of underappreciated understandings of the nature of science more generally. I contend that some contributors to the replication debates overstate the importance of replication in science and mischaracterize the relationship between direct and conceptual replication. I also claim that there has been a failure to appreciate sufficiently the variety of legitimate replication practices that scientists engage in. In this regard, I highlight the tendency to pay insufficient attention to methodological triangulation as an important strategy for justifying empirical claims. I argue, further, that the replication debates tend to overstate the closeness of the relationship between replication and theory construction. Some features of this relationship are spelt out with reference to both the hypothetico-deductive and the abductive accounts of scientific method. Additionally, an evaluation of the status of replication in different characterizations of scientific progress is undertaken. I maintain that viewing replication as just one element of the wide array of scientific endeavors leads to the conclusion that it is not as prominent in science as is often claimed.},
  keywords = {meta-science}
}

@article{hainesLearningReliabilityParadox2020,
  title = {Learning from the {{Reliability Paradox}}: {{How Theoretically Informed Generative Models Can Advance}} the {{Social}}, {{Behavioral}}, and {{Brain Sciences}}},
  shorttitle = {Learning from the {{Reliability Paradox}}},
  author = {Haines, Nathaniel and Kvam, Peter D. and Irving, Louis H. and Smith, Colin and Beauchaine, Theodore P. and Pitt, Mark A. and Ahn, Woo-Young and Turner, Brandon},
  year = {2020},
  month = aug,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/xr7y3},
  abstract = {Behavioral tasks (e.g., Stroop task) that produce replicable group-level effects (e.g., Stroop effect) often fail to reliably capture individual differences between participants (e.g., low test-retest reliability). This ``reliability paradox'' has led many researchers to conclude that most behavioral tasks cannot be used to develop and advance theories of individual differences. However, these conclusions are derived from statistical models that provide only superficial summary descriptions of behavioral data, thereby ignoring theoretically-relevant data-generating mechanisms that underly individual-level behavior. More generally, such descriptive methods lack the flexibility to test and develop increasingly complex theories of individual differences. To resolve this theory-description gap, we present generative modeling approaches, which involve using background knowledge to specify how behavior is generated at the individual level, and in turn how the distributions of individual-level mechanisms are characterized at the group level\textemdash all in a single joint model. Generative modeling shifts our focus away from estimating descriptive statistical ``effects'' toward estimating psychologically meaningful parameters, while simultaneously accounting for measurement error that would otherwise attenuate individual difference correlations. Using simulations and empirical data from the Implicit Association Test and Stroop, Flanker, Posner Cueing, and Delay Discounting tasks, we demonstrate how generative models yield (1) higher test-retest reliability estimates, and (2) more theoretically informative parameter estimates relative to traditional statistical approaches. Our results reclaim optimism regarding the utility of behavioral paradigms for testing and advancing theories of individual differences, and emphasize the importance of formally specifying and checking model assumptions to reduce theory-description gaps and facilitate principled theory development.},
  file = {/home/denis/Zotero/storage/67VQPHTP/xr7y3.html}
}

@article{halesImprovingPsychologicalScience2019,
  title = {Improving {{Psychological Science}} through {{Transparency}} and {{Openness}}: {{An Overview}}},
  shorttitle = {Improving {{Psychological Science}} through {{Transparency}} and {{Openness}}},
  author = {Hales, Andrew H. and Wesselmann, Eric D. and Hilgard, Joseph},
  year = {2019},
  month = mar,
  journal = {Perspectives on Behavior Science},
  volume = {42},
  number = {1},
  pages = {13--31},
  issn = {2520-8977},
  doi = {10.1007/s40614-018-00186-8},
  abstract = {The ability to independently verify and replicate observations made by other researchers is a hallmark of science. In this article, we provide an overview of recent discussions concerning replicability and best practices in mainstream psychology with an emphasis on the practical benefists to both researchers and the field as a whole. We first review challenges individual researchers face in producing research that is both publishable and reliable. We then suggest methods for producing more accurate research claims, such as transparently disclosing how results were obtained and analyzed, preregistering analysis plans, and publicly posting original data and materials. We also discuss ongoing changes at the institutional level to incentivize stronger research. These include officially recognizing open science practices at the journal level, disconnecting the publication decision from the results of a study, training students to conduct replications, and publishing replications. We conclude that these open science practices afford exciting low-cost opportunities to improve the quality of psychological science.},
  language = {en},
  keywords = {reproducibility-crisis}
}

@article{handDeconstructingStatisticalQuestions1994,
  title = {Deconstructing {{Statistical Questions}}},
  author = {Hand, David J.},
  year = {1994},
  journal = {Journal of the Royal Statistical Society. Series A (Statistics in Society)},
  volume = {157},
  number = {3},
  pages = {317},
  issn = {09641998},
  doi = {10.2307/2983526},
  abstract = {Too much current statistical work takes a superficial view of the client's research question, adopting techniques which have a solid history, a sound mathematical basis or readily available software, but without considering in depth whether the questions being answered are in fact those which should be asked. Examples, some familiar and others less so, are given to illustrate this assertion. It is clear that establishing the mapping from the client's domain to a statistical question is one of the most difficult parts of a statistical analysis. It is a part in which the responsibility is shared by both client and statistician. A plea is made for more research effort to go in this direction and some suggestions are made for ways to tackle the problem.},
  language = {en},
  keywords = {statistika}
}

@book{hardleAppliedMultivariateStatistical2015,
  title = {Applied {{Multivariate Statistical Analysis}}},
  author = {H{\"a}rdle, Wolfgang Karl and Simar, L{\'e}opold},
  year = {2015},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-45171-7},
  isbn = {978-3-662-45170-0 978-3-662-45171-7},
  language = {en},
  keywords = {multivariate,statistika}
}

@book{harleyPsychologyLanguageData2014,
  ids = {harleyPsychologyLanguageData2014a},
  title = {The {{Psychology}} of {{Language}}: {{From Data}} to {{Theory}}},
  author = {Harley, Trevor A.},
  year = {2014},
  edition = {Fourth},
  publisher = {{Psychology Press}},
  address = {{London, UK}},
  keywords = {psihologija-jezika,Psycholinguistics,PSYCHOLOGY / Cognitive Psychology}
}

@book{harrelljrRegressionModelingStrategies2015,
  title = {Regression {{Modeling Strategies}}: {{With Applications}} to {{Linear Models}}, {{Logistic}} and {{Ordinal Regression}}, and {{Survival Analysis}}},
  shorttitle = {Regression Modeling Strategies},
  author = {Harrell Jr, Frank E},
  year = {2015},
  publisher = {{Springer}},
  file = {/home/denis/Zotero/storage/MG9V6PIM/books.html}
}

@article{harrellRegressionModellingStrategies1984,
  title = {Regression Modelling Strategies for Improved Prognostic Prediction},
  author = {Harrell, Frank E. and Lee, Kerry L. and Califf, Robert M. and Pryor, David B. and Rosati, Robert A.},
  year = {1984},
  journal = {Statistics in Medicine},
  volume = {3},
  number = {2},
  pages = {143--152},
  issn = {1097-0258},
  doi = {10.1002/sim.4780030207},
  abstract = {Regression models such as the Cox proportional hazards model have had increasing use in modelling and estimating the prognosis of patients with a variety of diseases. Many applications involve a large number of variables to be modelled using a relatively small patient sample. Problems of overfitting and of identifying important covariates are exacerbated in analysing prognosis because the accuracy of a model is more a function of the number of events than of the sample size. We used a general index of predictive discrimination to measure the ability of a model developed on training samples of varying sizes to predict survival in an independent test sample of patients suspected of having coronary artery disease. We compared three methods of model fitting: (1) standard `step-up' variable selection, (2) incomplete principal components regression, and (3) Cox model regression after developing clinical indices from variable clusters. We found regression using principal components to offer superior predictions in the test sample, whereas regression using indices offers easily interpretable models nearly as good as the principal components models. Standard variable selection has a number of deficiencies.},
  copyright = {Copyright \textcopyright{} 1984 John Wiley \& Sons, Ltd.},
  language = {en},
  keywords = {statistika},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.4780030207},
  file = {/home/denis/Zotero/storage/8CJBL5LG/sim.html}
}

@article{harrison2014using,
  title = {Using Observation-Level Random Effects to Model Overdispersion in Count Data in Ecology and Evolution},
  author = {Harrison, Xavier A},
  year = {2014},
  journal = {PeerJ},
  volume = {2},
  pages = {e616},
  publisher = {{PeerJ Inc.}},
  keywords = {metodologija,statistika}
}

@article{harrisonBriefIntroductionMixedeffects2018,
  title = {A {{Brief Introduction}} to {{Mixed}}-Effects {{Modelling}} and {{Multi}}-Model {{Inference}} in {{Ecology}}},
  author = {Harrison, Xavier A. and Donaldson, Lynda and {Correa-Cano}, Maria Eugenia and Evans, Julian and Fisher, David N. and Goodwin, Cecily E. D. and Robinson, Beth S. and Hodgson, David J. and Inger, Richard},
  year = {2018},
  month = may,
  journal = {PeerJ},
  volume = {6},
  pages = {e4794},
  issn = {2167-8359},
  doi = {10.7717/peerj.4794},
  abstract = {The use of linear mixed effects models (LMMs) is increasingly common in the analysis of biological data. Whilst LMMs offer a flexible approach to modelling a broad range of data types, ecological data are often complex and require complex model structures, and the fitting and interpretation of such models is not always straightforward. The ability to achieve robust biological inference requires that practitioners know how and when to apply these tools. Here, we provide a general overview of current methods for the application of LMMs to biological data, and highlight the typical pitfalls that can be encountered in the statistical modelling process. We tackle several issues regarding methods of model selection, with particular reference to the use of information theory and multi-model inference in ecology. We offer practical solutions and direct the reader to key references that provide further technical detail for those seeking a deeper understanding. This overview should serve as a widely accessible code of best practice for applying LMMs to complex biological problems and model structures, and in doing so improve the robustness of conclusions drawn from studies investigating ecological and evolutionary questions.},
  language = {en},
  keywords = {multilevel,statistika}
}

@book{hayesIntroductionMediationModeration2017,
  title = {Introduction to Mediation, Moderation, and Conditional Process Analysis: {{A}} Regression-Based Approach},
  author = {Hayes, Andrew F.},
  year = {2017},
  publisher = {{Guilford publications}},
  isbn = {1-4625-3465-1},
  keywords = {medijacija,statistika}
}

@book{heckIntroductionMultilevelModeling2015,
  title = {An {{Introduction}} to {{Multilevel Modeling Techniques}}: {{MLM}} and {{SEM Approaches Using Mplus}}},
  author = {Heck, Ronald H. and Thomas, Scott L.},
  year = {2015},
  publisher = {{Routledge}},
  isbn = {1-317-59850-4},
  keywords = {multilevel,statistika}
}

@article{hedgeReliabilityParadoxWhy2018,
  title = {The Reliability Paradox: {{Why}} Robust Cognitive Tasks Do Not Produce Reliable Individual Differences},
  author = {Hedge, Craig and Powell, Georgina and Sumner, Petroc},
  year = {2018},
  journal = {Behavior Research Methods},
  volume = {50},
  number = {3},
  pages = {1166--1186},
  keywords = {flanker-task}
}

@article{hegyi2011using,
  title = {Using Information Theory as a Substitute for Stepwise Regression in Ecology and Behavior},
  author = {Hegyi, Gergely and Garamszegi, L{\'a}szl{\'o} Zsolt},
  year = {2011},
  journal = {Behavioral Ecology and Sociobiology},
  volume = {65},
  number = {1},
  pages = {69--76},
  publisher = {{Springer}},
  keywords = {information-theory,multi-model-inference,statistika}
}

@book{hernanCausalInferenceWhat,
  title = {Causal {{Inference}}: {{What If}}},
  author = {Hern{\'a}n, Miguel A and Robins, James M},
  publisher = {{Chapman and Hall/CRC}},
  language = {en},
  keywords = {causal-inference,statistika}
}

@article{hershbergerStructuralEquationModels2011,
  title = {Structural {{Equation Models}}},
  author = {Hershberger, Scott L.},
  editor = {Lovri{\'c}, Miodrag},
  year = {2011},
  journal = {International Encyclopedia of Statistical Science},
  pages = {1552--1555},
  publisher = {{Springer}},
  isbn = {3-642-04897-8},
  keywords = {sem,statistika}
}

@book{hesterGlueInterpretedString2019,
  title = {Glue: {{Interpreted}} String Literals},
  author = {Hester, Jim},
  year = {2019},
  keywords = {software}
}

@article{heymanFillingGapsSpeeded2016,
  title = {Filling the {{Gaps}}: {{A Speeded Word Fragment Completion Megastudy}}},
  author = {Heyman, Tom and Van Akeren, Liselotte and Hutchison, Keith A. and Storms, Gert},
  year = {2016},
  journal = {Behavior research methods},
  volume = {48},
  number = {4},
  pages = {1508--1527},
  keywords = {megastudy}
}

@article{hoffmanMultilevelModelsExperimental2007,
  title = {Multilevel Models for the Experimental Psychologist: {{Foundations}} and Illustrative Examples},
  author = {Hoffman, Lesa and Rovine, Michael J.},
  year = {2007},
  journal = {Behavior Research Methods},
  volume = {39},
  number = {1},
  pages = {101--117},
  keywords = {metodologija,multilevel,statistika}
}

@article{hollandReviewRecommendationsIntegrating2017,
  title = {Review and Recommendations for Integrating Mediation and Moderation},
  author = {Holland, Samantha J. and Shore, Daniel B. and Cortina, Jose M.},
  year = {2017},
  journal = {Organizational Research Methods},
  volume = {20},
  number = {4},
  pages = {686--720},
  keywords = {statistika}
}

@article{hootenGuideBayesianModel2015,
  title = {A Guide to {{Bayesian}} Model Selection for Ecologists},
  author = {Hooten, M. B. and Hobbs, N. T.},
  year = {2015},
  month = feb,
  journal = {Ecological Monographs},
  volume = {85},
  number = {1},
  pages = {3--28},
  issn = {0012-9615},
  doi = {10.1890/14-0661.1},
  abstract = {The steady upward trend in the use of model selection and Bayesian methods in ecological research has made it clear that both approaches to inference are important for modern analysis of models and data. However, in teaching Bayesian methods and in working with our research colleagues, we have noticed a general dissatisfaction with the available literature on Bayesian model selection and multimodel inference. Students and researchers new to Bayesian methods quickly find that the published advice on model selection is often preferential in its treatment of options for analysis, frequently advocating one particular method above others. The recent appearance of many articles and textbooks on Bayesian modeling has provided welcome background on relevant approaches to model selection in the Bayesian framework, but most of these are either very narrowly focused in scope or inaccessible to ecologists. Moreover, the methodological details of Bayesian model selection approaches are spread thinly throughout the literature, appearing in journals from many different fields. Our aim with this guide is to condense the large body of literature on Bayesian approaches to model selection and multimodel inference and present it specifically for quantitative ecologists as neutrally as possible. We also bring to light a few important and fundamental concepts relating directly to model selection that seem to have gone unnoticed in the ecological literature. Throughout, we provide only a minimal discussion of philosophy, preferring instead to examine the breadth of approaches as well as their practical advantages and disadvantages. This guide serves as a reference for ecologists using Bayesian methods, so that they can better understand their options and can make an informed choice that is best aligned with their goals for inference.},
  language = {en},
  keywords = {bayes,multi-model-inference,statistika}
}

@article{hothornSimultaneousInferenceGeneral2008,
  title = {Simultaneous Inference in General Parametric Models},
  author = {Hothorn, Torsten and Bretz, Frank and Westfall, Peter},
  year = {2008},
  journal = {Biometrical Journal},
  volume = {50},
  number = {3},
  pages = {346--363},
  keywords = {software}
}

@book{hoxMultilevelAnalysisTechniques2010,
  title = {Multilevel Analysis: {{Techniques}} and Applications},
  author = {Hox, Joop J.},
  year = {2010},
  edition = {Second},
  publisher = {{Routledge}},
  address = {{Hove, UK}},
  isbn = {1-317-30868-9},
  keywords = {multilevel,statistika}
}

@article{hsiehAgerelatedChangesContribute2012,
  title = {Do Age-Related Changes Contribute to the Flanker Effect?},
  author = {Hsieh, Shulan and Liang, Yu-Chi and Tsai, Yu-Che},
  year = {2012},
  journal = {Clinical Neurophysiology},
  volume = {123},
  number = {5},
  pages = {960--972},
  keywords = {flanker-task}
}

@book{hubertyAppliedMANOVADiscriminant2006,
  title = {Applied {{MANOVA}} and Discriminant Analysis},
  author = {Huberty, Carl J. and Olejnik, Stephen},
  year = {2006},
  volume = {498},
  publisher = {{John Wiley \& Sons}},
  isbn = {0-471-78946-1},
  keywords = {multivariate,statistika}
}

@article{hughesAccountingMissingData2019,
  title = {Accounting for {{Missing Data}} in {{Statistical Analyses}}: {{Multiple Imputation}} Is Not {{Always}} the {{Answer}}},
  shorttitle = {Accounting for Missing Data in Statistical Analyses},
  author = {Hughes, Rachael A and Heron, Jon and Sterne, Jonathan A C and Tilling, Kate},
  year = {2019},
  month = aug,
  journal = {International Journal of Epidemiology},
  volume = {48},
  number = {4},
  pages = {1294--1304},
  issn = {0300-5771, 1464-3685},
  doi = {10.1093/ije/dyz032},
  abstract = {Background: Missing data are unavoidable in epidemiological research, potentially leading to bias and loss of precision. Multiple imputation (MI) is widely advocated as an improvement over complete case analysis (CCA). However, contrary to widespread belief, CCA is preferable to MI in some situations. Methods: We provide guidance on choice of analysis when data are incomplete. Using causal diagrams to depict missingness mechanisms, we describe when CCA will not be biased by missing data and compare MI and CCA, with respect to bias and efficiency, in a range of missing data situations. We illustrate selection of an appropriate method in practice. Results: For most regression models, CCA gives unbiased results when the chance of being a complete case does not depend on the outcome after taking the covariates into consideration, which includes situations where data are missing not at random. Consequently, there are situations in which CCA analyses are unbiased while MI analyses, assuming missing at random (MAR), are biased. By contrast MI, unlike CCA, is valid for all MAR situations and has the potential to use information contained in the incomplete cases and auxiliary variables to reduce bias and/or improve precision. For this reason, MI was preferred over CCA in our real data example. Conclusions: Choice of method for dealing with missing data is crucial for validity of conclusions, and should be based on careful consideration of the reasons for the missing data, missing data patterns and the availability of auxiliary information.},
  language = {en},
  keywords = {missing-data,multiple-imputation,statistika}
}

@article{hughesAlternativesSwitchcostScoring2014,
  title = {Alternatives to Switch-Cost Scoring in the Task-Switching Paradigm: {{Their}} Reliability and Increased Validity},
  author = {Hughes, Meredith M. and Linck, Jared A. and Bowles, Anita R. and Koeth, Joel T. and Bunting, Michael F.},
  year = {2014},
  journal = {Behavior research methods},
  volume = {46},
  number = {3},
  pages = {702--721},
  keywords = {metodologija}
}

@article{hullmanInteractiveAnalysisNeeds,
  title = {Interactive {{Analysis Needs Theories}} of {{Inference}}},
  author = {Hullman, Jessica and Gelman, Andrew},
  pages = {31},
  abstract = {Computer science research has produced increasingly sophisticated software interfaces for interactive and exploratory analysis, optimized for easy pattern finding and data exposure. But assuming that identifying what's in the data is the end goal of analysis misrepresents strong connections between exploratory and confirmatory analysis and contributes to shallow analyses. We discuss how the concept of a model check unites exploratory and confirmatory analysis, and review proposed Bayesian and classical statistical theories of inference for visual analysis in light of this view. Viewing interactive analysis as driven by model checks suggests new directions for software, such as features for specifying one's intuitive reference model, including built-in reference distributions and graphical elicitation of parameters and priors, during exploratory analysis, as well as potential lessons to be learned from attempting to build fully automated, human-like statistical workflows.},
  language = {en},
  keywords = {statistika}
}

@article{husseyHiddenInvalidity152020,
  title = {Hidden {{Invalidity Among}} 15 {{Commonly Used Measures}} in {{Social}} and {{Personality Psychology}}},
  author = {Hussey, Ian and Hughes, Sean},
  year = {2020},
  month = apr,
  journal = {Advances in Methods and Practices in Psychological Science},
  pages = {251524591988290},
  issn = {2515-2459, 2515-2467},
  doi = {10.1177/2515245919882903},
  abstract = {It has recently been demonstrated that metrics of structural validity are severely underreported in social and personality psychology. We comprehensively assessed structural validity in a uniquely large and varied data set (N = 144,496 experimental sessions) to investigate the psychometric properties of some of the most widely used self-report measures (k = 15 questionnaires, 26 scales) in social and personality psychology. When the scales were assessed using the modal practice of considering only internal consistency, 88\% of them appeared to possess good validity. Yet when validity was assessed comprehensively (via internal consistency, immediate and delayed test-retest reliability, factor structure, and measurement invariance for age and gender groups), only 4\% demonstrated good validity. Furthermore, the less commonly a test was reported in the literature, the more likely the scales were to fail that test (e.g., scales failed measurement invariance much more often than internal consistency). This suggests that the pattern of underreporting in the field may represent widespread hidden invalidity of the measures used and may therefore pose a threat to many research findings. We highlight the degrees of freedom afforded to researchers in the assessment and reporting of structural validity and introduce the concept of validity hacking (v-hacking), similar to the better-known concept of p-hacking. We argue that the practice of v-hacking should be acknowledged and addressed.},
  language = {en},
  keywords = {meta-science,metodologija}
}

@incollection{hyonaFovealParafovealProcessing2011,
  title = {Foveal and Parafoveal Processing during Reading.},
  booktitle = {The {{Oxford Handbook}} of {{Eye Movements}}},
  author = {Hy{\"o}n{\"a}, Jukka},
  editor = {Liversedge, S. P. and Gilchrist, Iain D. and Everling, Stefan},
  year = {2011},
  pages = {819--838},
  publisher = {{Oxford University Press}},
  address = {{oxford}}
}

@article{iacobucciMeanCenteringHelps2016,
  title = {Mean Centering Helps Alleviate ``Micro'' but Not ``Macro'' Multicollinearity},
  author = {Iacobucci, Dawn and Schneider, Matthew J. and Popovich, Deidre L. and Bakamitsos, Georgios A.},
  year = {2016},
  month = dec,
  journal = {Behavior Research Methods},
  volume = {48},
  number = {4},
  pages = {1308--1317},
  issn = {1554-3528},
  doi = {10.3758/s13428-015-0624-x},
  abstract = {There seems to be confusion among researchers regarding whether it is good practice to center variables at their means prior to calculating a product term to estimate an interaction in a multiple regression model. Many researchers use mean centered variables because they believe it's the thing to do or because reviewers ask them to, without quite understanding why. Adding to the confusion is the fact that there is also a perspective in the literature that mean centering does not reduce multicollinearity. In this article, we clarify the issues and reconcile the discrepancy. We distinguish between ``micro'' and ``macro'' definitions of multicollinearity and show how both sides of such a debate can be correct. To do so, we use proofs, an illustrative dataset, and a Monte Carlo simulation to show the precise effects of mean centering on both individual correlation coefficients as well as overall model indices. We hope to contribute to the literature by clarifying the issues, reconciling the two perspectives, and quelling the current confusion regarding whether and how mean centering can be a useful practice.},
  language = {en},
  keywords = {statistika}
}

@article{imaiIdentificationInferenceSensitivity2010,
  title = {Identification, {{Inference}} and {{Sensitivity Analysis}} for {{Causal Mediation Effects}}},
  author = {Imai, Kosuke and Keele, Luke and Yamamoto, Teppei},
  year = {2010},
  month = feb,
  journal = {Statistical Science},
  volume = {25},
  number = {1},
  pages = {51--71},
  issn = {0883-4237},
  doi = {10.1214/10-STS321},
  abstract = {Causal mediation analysis is routinely conducted by applied researchers in a variety of disciplines. The goal of such an analysis is to investigate alternative causal mechanisms by examining the roles of intermediate variables that lie in the causal paths between the treatment and outcome variables. In this paper we first prove that under a particular version of sequential ignorability assumption, the average causal mediation effect (ACME) is nonparametrically identified. We compare our identification assumption with those proposed in the literature. Some practical implications of our identification result are also discussed. In particular, the popular estimator based on the linear structural equation model (LSEM) can be interpreted as an ACME estimator once additional parametric assumptions are made. We show that these assumptions can easily be relaxed within and outside of the LSEM framework and propose simple nonparametric estimation strategies. Second, and perhaps most importantly, we propose a new sensitivity analysis that can be easily implemented by applied researchers within the LSEM framework. Like the existing identifying assumptions, the proposed sequential ignorability assumption may be too strong in many applied settings. Thus, sensitivity analysis is essential in order to examine the robustness of empirical findings to the possible existence of an unmeasured confounder. Finally, we apply the proposed methods to a randomized experiment from political psychology. We also make easy-to-use software available to implement the proposed methods.},
  language = {en},
  keywords = {causal-inference,medijacija,statistika}
}

@article{imbensPotentialOutcomeDirected2020,
  title = {Potential {{Outcome}} and {{Directed Acyclic Graph Approaches}} to {{Causality}}: {{Relevance}} for {{Empirical Practice}} in {{Economics}}},
  shorttitle = {Potential {{Outcome}} and {{Directed Acyclic Graph Approaches}} to {{Causality}}},
  author = {Imbens, Guido W.},
  year = {2020},
  month = dec,
  journal = {Journal of Economic Literature},
  volume = {58},
  number = {4},
  pages = {1129--1179},
  issn = {0022-0515},
  doi = {10.1257/jel.20191597},
  abstract = {(Pearl and Mackenzie 2018). I also discuss the potential outcome framework developed by Rubin and coauthors (e.g., Rubin 2006), building on work by Neyman (1990 [1923]). I then discuss the relative merits of these approaches for empirical work in economics, focusing on the questions each framework answers well, and why much of the the work in economics is closer in spirit to the potential outcome perspective.},
  language = {en},
  keywords = {causal-inference},
  file = {/home/denis/Zotero/storage/IPFT7NMU/articles.html}
}

@book{jaccardInteractionEffectsLogistic2001,
  title = {Interaction {{Effects}} in {{Logistic Regression}}},
  author = {Jaccard, James A},
  year = {2001},
  publisher = {{Sage}},
  address = {{Thousand Oaks, CA}}
}

@book{jamesIntroductionStatisticalLearning2013,
  title = {An Introduction to Statistical Learning},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  year = {2013},
  volume = {112},
  publisher = {{Springer}},
  address = {{New York, NY}}
}

@article{jareckiFrameworkBuildingCognitive2020,
  title = {A {{Framework}} for {{Building Cognitive Process Models}}},
  author = {Jarecki, Jana Bianca and Tan, Jolene and Jenny, Mirjam},
  year = {2020},
  month = apr,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/9uk25},
  abstract = {The term process model is widely used but rarely agreed upon. This paper proposes a framework for characterizing and building cognitive process models. Process models model not only inputs and outputs but also model the ongoing information transformations at a given level of abstraction. We argue that four dimensions characterize process models: They specify intermediate stages containing the hypothesized mental information processing. They make predictions not only for the behavior of interest but also for process-related variables. Third, the models' process predictions can be derived from the input without reverse inference from the output data. Fourth, the presumed information transformation steps are not contradicting current knowledge of human cognitive capacities. Finally, process models require a conceptual scope specifying what the model refers to, that is, the information entering the mind, the proposed mental events, and the behavior of interest. This framework can be used for refining models before testing them or after testing them empirically, and it does not rely on specific modeling paradigms. It can be a guideline for developing cognitive process models. Moreover, the framework can advance currently unresolved debates about which models belong to the category of process models.},
  file = {/home/denis/Zotero/storage/96GHKQP2/9uk25.html}
}

@book{jaspteamJASPVersionComputer2018,
  title = {{{JASP}} ({{Version}} 0.9)[{{Computer}} Software]},
  author = {{JASP Team}},
  year = {2018},
  keywords = {software}
}

@article{johnMeasuringPrevalenceQuestionable2012,
  title = {Measuring the {{Prevalence}} of {{Questionable Research Practices With Incentives}} for {{Truth Telling}}},
  author = {John, Leslie K. and Loewenstein, George and Prelec, Drazen},
  year = {2012},
  month = may,
  journal = {Psychological Science},
  volume = {23},
  number = {5},
  pages = {524--532},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1177/0956797611430953},
  abstract = {Cases of clear scientific misconduct have received significant media attention recently, but less flagrantly questionable research practices may be more prevalent and, ultimately, more damaging to the academic enterprise. Using an anonymous elicitation format supplemented by incentives for honest reporting, we surveyed over 2,000 psychologists about their involvement in questionable research practices. The impact of truth-telling incentives on self-admissions of questionable research practices was positive, and this impact was greater for practices that respondents judged to be less defensible. Combining three different estimation methods, we found that the percentage of respondents who have engaged in questionable practices was surprisingly high. This finding suggests that some questionable practices may constitute the prevailing research norm.},
  language = {en},
  keywords = {meta-science,metodologija}
}

@book{joreskogLISRELStructuralEquation1993,
  title = {{{LISREL}} 8: {{Structural}} Equation Modeling with the {{SIMPLIS}} Command Language},
  author = {J{\"o}reskog, Karl G. and S{\"o}rbom, Dag},
  year = {1993},
  publisher = {{Scientific Software International}},
  isbn = {0-89498-033-5},
  keywords = {sem}
}

@article{juddExperimentsMoreOne2017,
  title = {Experiments with {{More Than One Random Factor}}: {{Designs}}, {{Analytic Models}}, and {{Statistical Power}}},
  shorttitle = {Experiments with {{More Than One Random Factor}}},
  author = {Judd, Charles M. and Westfall, Jacob and Kenny, David A.},
  year = {2017},
  month = jan,
  journal = {Annual Review of Psychology},
  volume = {68},
  number = {1},
  pages = {601--625},
  issn = {0066-4308, 1545-2085},
  doi = {10.1146/annurev-psych-122414-033702},
  abstract = {Traditional methods of analyzing data from psychological experiments are based on the assumption that there is a single random factor (normally participants) to which generalization is sought. However, many studies involve at least two random factors (e.g., participants and the targets to which they respond, such as words, pictures, or individuals). The application of traditional analytic methods to the data from such studies can result in serious bias in testing experimental effects. In this review, we develop a comprehensive typology of designs involving two random factors, which may be either crossed or nested, and one fixed factor, condition. We present appropriate linear mixed models for all designs and develop effect size measures. We provide the tools for power estimation for all designs. We then discuss issues of design choice, highlighting power and feasibility considerations. Our goal is to encourage appropriate analytic methods that produce replicable results for studies involving new samples of both participants and targets.},
  language = {en},
  keywords = {effect-size,multilevel,stat-power,statistika}
}

@article{kassTenSimpleRules2016,
  title = {Ten {{Simple Rules}} for {{Effective Statistical Practice}}},
  author = {Kass, Robert E. and Caffo, Brian S. and Davidian, Marie and Meng, Xiao-Li and Yu, Bin and Reid, Nancy},
  editor = {Lewitter, Fran},
  year = {2016},
  month = jun,
  journal = {PLOS Computational Biology},
  volume = {12},
  number = {6},
  pages = {e1004961},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004961},
  language = {en},
  keywords = {statistika}
}

@book{kayTidybayesTidyData2019,
  title = {Tidybayes: {{Tidy}} Data and Geoms for {{Bayesian}} Models},
  author = {Kay, Matthew},
  year = {2019},
  doi = {10.5281/zenodo.1308151},
  keywords = {software}
}

@article{kelleyEffectsNonnormalDistributions2005,
  title = {The Effects of Nonnormal Distributions on Confidence Intervals around the Standardized Mean Difference: {{Bootstrap}} and Parametric Confidence Intervals},
  author = {Kelley, Ken},
  year = {2005},
  journal = {Educational and Psychological Measurement},
  volume = {65},
  number = {1},
  pages = {51--69},
  keywords = {bootstrap,effect-size,statistika}
}

@article{kennedyKnowYourPopulation2020,
  title = {Know Your Population and Know Your Model: {{Using}} Model-Based Regression and Poststratification to Generalize Findings beyond the Observed Sample},
  shorttitle = {Know Your Population and Know Your Model},
  author = {Kennedy, Lauren and Gelman, Andrew},
  year = {2020},
  month = apr,
  journal = {arXiv:1906.11323 [stat]},
  eprint = {1906.11323},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Psychology research focuses on interactions, and this has deep implications for inference from non-representative samples. For the goal of estimating average treatment effects, we propose to fit a model allowing treatment to interact with background variables and then average over the distribution of these variables in the population. This can be seen as an extension of multilevel regression and poststratification (MRP), a method used in political science and other areas of survey research, where researchers wish to generalize from a sparse and possibly non-representative sample to the general population. In this paper, we discuss areas where this method can be used in the psychological sciences. We use our method to estimate the norming distribution for the Big Five Personality Scale using open source data. We argue that large open data sources like this and other collaborative data sources can be combined with MRP to help resolve current challenges of generalizability and replication in psychology.},
  archiveprefix = {arXiv},
  language = {en},
  keywords = {statistika}
}

@article{kennedyUsingSexGender2020,
  title = {Using Sex and Gender in Survey Adjustment},
  author = {Kennedy, Lauren and Khanna, Katharine and Simpson, Daniel and Gelman, Andrew},
  year = {2020},
  month = sep,
  journal = {arXiv:2009.14401 [stat]},
  eprint = {2009.14401},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Accounting for sex and gender characteristics is a complex, structural challenge in social science research. While other methodology papers consider issues surrounding appropriate measurement, we consider how gender and sex impact adjustments for non-response patterns in sampling and survey estimates. We consider the problem of survey adjustment arising from the recent push toward measuring sex or gender as a non-binary construct. This is challenging not only in that response categories differ between sex and gender measurement, but also in that both of these attributes are potentially multidimensional. In this manuscript we reflect on similarities to measuring race/ethnicity before considering the ethical and statistical implications of the options available to us. We do not conclude with a single best recommendation but rather an awareness of the complexity of the issues surrounding this challenge and the benefits and weaknesses of different approaches.},
  archiveprefix = {arXiv},
  language = {en}
}

@incollection{kesslerWritingSystemsTheir2015,
  title = {Writing {{Systems}}: {{Their Properties}} and {{Implications}} for {{Reading}}},
  booktitle = {The {{Oxford Handbook}} of {{Reading}}},
  author = {Kessler, Brett and Treiman, Rebecca},
  editor = {Pollatsek, Alexander and Treiman, Rebecca},
  year = {2015},
  pages = {10--25},
  publisher = {{Oxford University Press}}
}

@article{keuleersBritishLexiconProject2012,
  ids = {keuleersBritishLexiconProject2012a},
  title = {The {{British Lexicon Project}}: {{Lexical Decision Data}} for 28,730 {{Monosyllabic}} and {{Disyllabic English Words}}},
  author = {Keuleers, Emmanuel and Lacey, Paula and Rastle, Kathleen and Brysbaert, Marc},
  year = {2012},
  journal = {Behavior research methods},
  volume = {44},
  number = {1},
  pages = {287--304},
  keywords = {megastudy,psihologija-jezika}
}

@article{keuleersMegastudiesCrowdsourcingLarge2015,
  ids = {keuleersMegastudiesCrowdsourcingLarge2015b},
  title = {Megastudies, {{Crowdsourcing}}, and {{Large Datasets}} in {{Psycholinguistics}}: {{An Overview}} of {{Recent Developments}}},
  shorttitle = {Megastudies, Crowdsourcing, and Large Datasets in Psycholinguistics},
  author = {Keuleers, Emmanuel and Balota, David A.},
  year = {2015},
  month = aug,
  journal = {Quarterly Journal of Experimental Psychology},
  volume = {68},
  number = {8},
  pages = {1457--1468},
  issn = {1747-0218, 1747-0226},
  doi = {10.1080/17470218.2015.1051065},
  language = {en}
}

@article{keuleersWordKnowledgeCrowd2015,
  title = {Word {{Knowledge}} in the {{Crowd}}: {{Measuring Vocabulary Size}} and {{Word Prevalence}} in a {{Massive Online Experiment}}},
  shorttitle = {Word Knowledge in the Crowd},
  author = {Keuleers, Emmanuel and Stevens, Micha{\"e}l and Mandera, Pawe{\l} and Brysbaert, Marc},
  year = {2015},
  month = aug,
  journal = {The Quarterly Journal of Experimental Psychology},
  volume = {68},
  number = {8},
  pages = {1665--1692},
  issn = {1747-0218},
  doi = {10.1080/17470218.2015.1022560},
  abstract = {We use the results of a large online experiment on word knowledge in Dutch to investigate variables influencing vocabulary size in a large population and to examine the effect of word prevalence\textemdash the percentage of a population knowing a word\textemdash as a measure of word occurrence. Nearly 300,000 participants were presented with about 70 word stimuli (selected from a list of 53,000 words) in an adapted lexical decision task. We identify age, education, and multilingualism as the most important factors influencing vocabulary size. The results suggest that the accumulation of vocabulary throughout life and in multiple languages mirrors the logarithmic growth of number of types with number of tokens observed in text corpora (Herdan's law). Moreover, the vocabulary that multilinguals acquire in related languages seems to increase their first language (L1) vocabulary size and outweighs the loss caused by decreased exposure to L1. In addition, we show that corpus word frequency and prevalence are complementary measures of word occurrence covering a broad range of language experiences. Prevalence is shown to be the strongest independent predictor of word processing times in the Dutch Lexicon Project, making it an important variable for psycholinguistic research.},
  pmid = {25715025},
  keywords = {metodologija,psihologija-jezika},
  file = {/home/denis/Zotero/storage/C3ZXYBXJ/17470218.2015.html}
}

@article{kieselControlInterferenceTask2010,
  title = {Control and Interference in Task Switching\textemdash{{A}} Review.},
  author = {Kiesel, Andrea and Steinhauser, Marco and Wendt, Mike and Falkenstein, Michael and Jost, Kerstin and Philipp, Andrea M. and Koch, Iring},
  year = {2010},
  journal = {Psychological bulletin},
  volume = {136},
  number = {5},
  pages = {849}
}

@article{kingWhyPropensityScores2016,
  title = {Why Propensity Scores Should Not Be Used for Matching},
  author = {King, Gary and Nielsen, Richard},
  year = {2016},
  journal = {Copy at http://j. mp/1sexgVw Download Citation BibTex Tagged XML Download Paper},
  volume = {378},
  keywords = {causal-inference,statistika}
}

@incollection{kinoshitaVisualWordRecognition2015,
  title = {Visual {{Word Recognition}} in the {{Bayesian Reader Framework}}},
  booktitle = {The {{Oxford Handbook}} of {{Reading}}},
  author = {Kinoshita, Sachiko},
  editor = {Pollatsek, Alexander and Treiman, Rebecca},
  year = {2015},
  pages = {63--75},
  publisher = {{Oxford University Press}},
  file = {/home/denis/Zotero/storage/R3CF3U82/books.html}
}

@article{kleinMixedBinarycontinuousCopula2019,
  title = {Mixed Binary-Continuous Copula Regression Models with Application to Adverse Birth Outcomes},
  author = {Klein, Nadja and Kneib, Thomas and Marra, Giampiero and Radice, Rosalba and Rokicki, Slawa and McGovern, Mark E.},
  year = {2019},
  journal = {Statistics in Medicine},
  volume = {38},
  number = {3},
  pages = {413--436},
  issn = {1097-0258},
  doi = {10.1002/sim.7985},
  abstract = {Bivariate copula regression allows for the flexible combination of two arbitrary, continuous marginal distributions with regression effects being placed on potentially all parameters of the resulting bivariate joint response distribution. Motivated by the risk factors for adverse birth outcomes, many of which are dichotomous, we consider mixed binary-continuous responses that extend the bivariate continuous framework to the situation where one response variable is discrete (more precisely, binary) whereas the other response remains continuous. Utilizing the latent continuous representation of binary regression models, we implement a penalized likelihood\textendash based approach for the resulting class of copula regression models and employ it in the context of modeling gestational age and the presence/absence of low birth weight. The analysis demonstrates the advantage of the flexible specification of regression impacts including nonlinear effects of continuous covariates and spatial effects. Our results imply that racial and spatial inequalities in the risk factors for infant mortality are even greater than previously suggested.},
  copyright = {\textcopyright{} 2018 John Wiley \& Sons, Ltd.},
  language = {en},
  keywords = {copula,statistika},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.7985}
}

@article{kleinPracticalGuideTransparency2018,
  title = {A Practical Guide for Transparency in Psychological Science.},
  author = {Klein, Olivier and Hardwicke, Tom E. and Aust, Frederik and Breuer, Johannes and Danielsson, Henrik and Hofelich Mohr, Alicia and IJzerman, Hans and Nilsonne, Gustav and Vanpaemel, Wolf and Frank, Michael C.},
  year = {2018},
  journal = {Collabra: Psychology},
  volume = {4},
  number = {1},
  pages = {1--15},
  publisher = {{The Regents of the University of California}},
  file = {/home/denis/Zotero/storage/4AS266DW/1999530.html}
}

@book{klinePrinciplesPracticeStructural2016,
  title = {Principles and {{Practice}} of {{Structural Equation Modeling}}},
  author = {Kline, Rex B.},
  year = {2016},
  publisher = {{Guilford publications}},
  isbn = {1-4625-2335-8},
  keywords = {sem,statistika}
}

@article{krauseExpyrimentPythonLibrary2014,
  title = {Expyriment: {{A Python}} Library for Cognitive and Neuroscientific Experiments},
  author = {Krause, Florian and Lindemann, Oliver},
  year = {2014},
  journal = {Behavior Research Methods},
  volume = {46},
  number = {2},
  pages = {416--428},
  keywords = {metodologija,python}
}

@article{krocMeasurementProtocolsRandomvariablevalued2020,
  title = {Measurement Protocols, Random-Variable-Valued Measurements, and Response Process Error: {{Estimation}} and Inference When Sample Data Are Not Deterministic},
  shorttitle = {Measurement Protocols, Random-Variable-Valued Measurements, and Response Process Error},
  author = {Kroc, Edward},
  year = {2020},
  month = oct,
  journal = {PLOS ONE},
  volume = {15},
  number = {10},
  pages = {e0239821},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0239821},
  abstract = {Random-variable-valued measurements (RVVMs) are proposed as a new framework for treating measurement processes that generate non-deterministic sample data. They operate by assigning a probability measure to each observed sample instantiation of a global measurement process for some particular random quantity of interest, thus allowing for the explicit quantification of response process error. Common methodologies to date treat only measurement processes that generate fixed values for each sample unit, thus generating full (though possibly inaccurate) information on the random quantity of interest. However, many applied research situations in the non-experimental sciences naturally contain response process error, e.g. when psychologists assess patient agreement with various diagnostic survey items or when conservation biologists perform formal assessments to classify species-at-risk. Ignoring the sample-unit-level uncertainty of response process error in such measurement processes can greatly compromise the quality of resulting inferences. In this paper, a general theory of RVVMs is proposed to handle response process error, and several applications are considered.},
  language = {en},
  keywords = {statistika},
  file = {/home/denis/Zotero/storage/35SM5WL7/article.html;/home/denis/Zotero/storage/SFYDARS4/article.html}
}

@article{kruschkeBayesianAssessmentNull2011,
  title = {Bayesian {{Assessment}} of {{Null Values Via Parameter Estimation}} and {{Model Comparison}}},
  author = {Kruschke, John K.},
  year = {2011},
  month = may,
  journal = {Perspectives on Psychological Science},
  volume = {6},
  number = {3},
  pages = {299--312},
  issn = {1745-6916, 1745-6924},
  doi = {10.1177/1745691611406925},
  abstract = {Psychologists have been trained to do data analysis by asking whether null values can be rejected. Is the difference between groups nonzero? Is choice accuracy not at chance level? These questions have been traditionally addressed by null hypothesis significance testing (NHST). NHST has deep problems that are solved by Bayesian data analysis. As psychologists transition to Bayesian data analysis, it is natural to ask how Bayesian analysis assesses null values. The article explains and evaluates two different Bayesian approaches. One method involves Bayesian model comparison (and uses Bayes factors). The second method involves Bayesian parameter estimation and assesses whether the null value falls among the most credible values. Which method to use depends on the specific question that the analyst wants to answer, but typically the estimation approach (not using Bayes factors) provides richer information than the model comparison approach.},
  language = {en},
  keywords = {bayes,statistika}
}

@book{kruschkeDoingBayesianData2014,
  title = {Doing {{Bayesian}} Data Analysis: {{A}} Tutorial with {{R}}, {{JAGS}}, and {{Stan}}},
  author = {Kruschke, John},
  year = {2014},
  publisher = {{Academic Press}},
  isbn = {0-12-405916-3},
  keywords = {bayes}
}

@article{kruschkeRejectingAcceptingParameter,
  title = {Rejecting or {{Accepting Parameter Values}} in {{Bayesian Estimation}}},
  author = {Kruschke, John K},
  pages = {11},
  abstract = {This article explains a decision rule that uses Bayesian posterior distributions as the basis for accepting or rejecting null values of parameters. This decision rule focuses on the range of plausible values indicated by the highest density interval of the posterior distribution and the relation between this range and a region of practical equivalence (ROPE) around the null value. The article also discusses considerations for setting the limits of a ROPE and emphasizes that analogous considerations apply to setting the decision thresholds for p values and Bayes factors.},
  language = {en},
  keywords = {bayes,statistika}
}

@article{kupermanVirtualExperimentsMegastudies2015,
  title = {Virtual {{Experiments}} in {{Megastudies}}: {{A Case Study}} of {{Language}} and {{Emotion}}},
  shorttitle = {Virtual Experiments in Megastudies},
  author = {Kuperman, Victor},
  year = {2015},
  month = aug,
  journal = {Quarterly Journal of Experimental Psychology},
  volume = {68},
  number = {8},
  pages = {1693--1710},
  issn = {1747-0218, 1747-0226},
  doi = {10.1080/17470218.2014.989865},
  abstract = {A recent dramatic increase in the number and scope of chronometric and norming lexical megastudies offers the ability to conduct virtual experiments, that is, to draw samples of items with properties that vary in critical linguistic dimensions. This paper introduces a bootstrapping approach which enables testing research hypotheses against a range of samples selected in a uniform, principled manner and evaluates how likely a theoretically motivated pattern is in a broad distribution of possible outcome patterns. We apply this approach to conflicting theoretical and empirical accounts of the relationship between the psychological valence (positivity) of a word and its speed of recognition. To this end, we conduct three sets of multiple virtual experiments with a factorial and a regression design, drawing data from two lexical decision megastudies. We discuss the influence that criteria for stimuli selection, statistical power, collinearity and the choice of dataset have on the efficacy and outcomes of the bootstrapping procedure.},
  language = {en}
}

@article{kvarvenComparingMetaanalysesPreregistered2020,
  title = {Comparing Meta-Analyses and Preregistered Multiple-Laboratory Replication Projects},
  author = {Kvarven, Amanda and Str{\o}mland, Eirik and Johannesson, Magnus},
  year = {2020},
  month = apr,
  journal = {Nature Human Behaviour},
  volume = {4},
  number = {4},
  pages = {423--434},
  issn = {2397-3374},
  doi = {10.1038/s41562-019-0787-z},
  language = {en},
  keywords = {meta-science,metodologija}
}

@article{lajeunesseFacilitatingSystematicReviews2016,
  title = {Facilitating Systematic Reviews, Data Extraction and Meta-analysis with the Metagear Package for {{R}}},
  author = {Lajeunesse, Marc J.},
  year = {2016},
  journal = {Methods in Ecology and Evolution},
  volume = {7},
  number = {3},
  pages = {323--330},
  keywords = {lit-review,meta-analiza,metodologija,r}
}

@article{lakensCalculatingReportingEffect2013,
  title = {Calculating and Reporting Effect Sizes to Facilitate Cumulative Science: A Practical Primer for t-Tests and {{ANOVAs}}},
  author = {Lakens, Dani{\"e}l},
  year = {2013},
  journal = {Frontiers in psychology},
  volume = {4},
  pages = {863},
  keywords = {effect-size,statistika}
}

@article{lakensEquivalenceTestsPractical2017,
  title = {Equivalence Tests: A Practical Primer for t Tests, Correlations, and Meta-Analyses},
  author = {Lakens, Dani{\"e}l},
  year = {2017},
  journal = {Social Psychological and Personality Science},
  volume = {8},
  number = {4},
  pages = {355--362},
  keywords = {statistika}
}

@article{lakensPerformingHighPowered2014,
  title = {Performing High-powered Studies Efficiently with Sequential Analyses},
  author = {Lakens, Dani{\"e}l},
  year = {2014},
  journal = {European Journal of Social Psychology},
  volume = {44},
  number = {7},
  pages = {701--710},
  keywords = {metodologija,sequential-analysis,statistika}
}

@article{lakensProfessorsAreNot2017,
  title = {Professors Are Not Elderly: {{Evaluating}} the Evidential Value of Two Social Priming Effects through p-Curve Analyses},
  author = {Lakens, Daniel},
  year = {2017},
  keywords = {metodologija,statistika}
}

@article{lakensSailingSeasChaos2014,
  title = {Sailing from the Seas of Chaos into the Corridor of Stability: {{Practical}} Recommendations to Increase the Informational Value of Studies},
  author = {Lakens, Dani{\"e}l and Evers, Ellen RK},
  year = {2014},
  journal = {Perspectives on Psychological Science},
  volume = {9},
  number = {3},
  pages = {278--292},
  keywords = {metodologija,sequential-analysis,statistika}
}

@book{lambertsHandbookCognition2004,
  title = {Handbook of {{Cognition}}},
  author = {Lamberts, K. and Goldstone, R.},
  year = {2004},
  publisher = {{SAGE Publications}},
  isbn = {978-1-84787-136-7}
}

@article{landauerStructuralDifferencesCommon1973,
  title = {Structural Differences between Common and Rare Words: {{Failure}} of Equivalence Assumptions for Theories of Word Recognition},
  shorttitle = {Structural Differences between Common and Rare Words},
  author = {Landauer, T. K. and Streeter, L. A.},
  year = {1973},
  month = apr,
  journal = {Journal of Verbal Learning and Verbal Behavior},
  volume = {12},
  number = {2},
  pages = {119--131},
  issn = {0022-5371},
  doi = {10.1016/S0022-5371(73)80001-5},
  abstract = {Theoretical discussions of word frequency effects often assume words of different usage frequencies to be equivalent in other respects relevant to perception. Such assumptions were found to be unwarranted. In Study I, common as compared to rare words were found to be confusable with a greater number of other words by a substitution of a single letter. Moreover, the average usage frequency of such ``neighbors'' was higher for common words. In Study II, common and rare words were found to contain different distributions of phonemes and graphemes. In Study III, one-syllable words containing phonemes typical of common as compared to rare words were found to be more intelligible, ceteris paribus. The relation of these findings to theories of word-frequency effects is discussed.},
  language = {en},
  keywords = {psihologija-jezika}
}

@article{langeAssessingNaturalDirect2014,
  title = {Assessing {{Natural Direct}} and {{Indirect Effects Through Multiple Pathways}}},
  author = {Lange, Theis and Rasmussen, Mette and Thygesen, Lau Caspar},
  year = {2014},
  month = feb,
  journal = {American Journal of Epidemiology},
  volume = {179},
  number = {4},
  pages = {513--518},
  issn = {1476-6256, 0002-9262},
  doi = {10.1093/aje/kwt270},
  language = {en},
  keywords = {causal-inference,medijacija,statistika}
}

@article{langeSimpleUnifiedApproach2012,
  title = {A {{Simple Unified Approach}} for {{Estimating Natural Direct}} and {{Indirect Effects}}},
  author = {Lange, Theis and Vansteelandt, Stijn and Bekaert, Maarten},
  year = {2012},
  month = aug,
  journal = {American Journal of Epidemiology},
  volume = {176},
  number = {3},
  pages = {190--195},
  issn = {1476-6256, 0002-9262},
  doi = {10.1093/aje/kwr525},
  language = {en},
  keywords = {causal-inference,medijacija,statistika}
}

@article{leiStructuralEquationModeling2007,
  title = {Structural {{Equation Modeling}}},
  author = {Lei, Pui-Wa},
  editor = {Salkind, Neil J},
  year = {2007},
  journal = {Encyclopedia of Measurement and Statistics},
  pages = {973--976},
  publisher = {{Sage}},
  address = {{Thousand Oaks, CA}},
  keywords = {sem,statistika}
}

@article{liddellAnalyzingOrdinalData2018,
  title = {Analyzing Ordinal Data with Metric Models: {{What}} Could Possibly Go Wrong?},
  shorttitle = {Analyzing Ordinal Data with Metric Models},
  author = {Liddell, Torrin M. and Kruschke, John K.},
  year = {2018},
  month = nov,
  journal = {Journal of Experimental Social Psychology},
  volume = {79},
  pages = {328--348},
  issn = {00221031},
  doi = {10.1016/j.jesp.2018.08.009},
  abstract = {We surveyed all articles in the Journal of Personality and Social Psychology (JPSP), Psychological Science (PS), and the Journal of Experimental Psychology: General (JEP:G) that mentioned the term ``Likert,'' and found that 100\% of the articles that analyzed ordinal data did so using a metric model. We present novel evidence that analyzing ordinal data as if they were metric can systematically lead to errors. We demonstrate false alarms (i.e., detecting an effect where none exists, Type I errors) and failures to detect effects (i.e., loss of power, Type II errors). We demonstrate systematic inversions of effects, for which treating ordinal data as metric indicates the opposite ordering of means than the true ordering of means. We show the same problems \textemdash{} false alarms, misses, and inversions \textemdash{} for interactions in factorial designs and for trend analyses in regression. We demonstrate that averaging across multiple ordinal measurements does not solve or even ameliorate these problems. A central contribution is a graphical explanation of how and when the misrepresentations occur. Moreover, we point out that there is no sure-fire way to detect these problems by treating the ordinal values as metric, and instead we advocate use of ordered-probit models (or similar) because they will better describe the data. Finally, although frequentist approaches to some ordered-probit models are available, we use Bayesian methods because of their flexibility in specifying models and their richness and accuracy in providing parameter estimates. An R script is provided for running an analysis that compares ordered-probit and metric models.},
  language = {en},
  keywords = {bayes,statistika}
}

@article{lockerUseMultilevelModeling2007,
  title = {On the Use of Multilevel Modeling as an Alternative to Items Analysis in Psycholinguistic Research},
  author = {Locker, Lawrence and Hoffman, Lesa and Bovaird, James A.},
  year = {2007},
  journal = {Behavior Research Methods},
  volume = {39},
  number = {4},
  pages = {723--730},
  keywords = {metodologija,multilevel,statistika}
}

@article{lockwoodSpecialIssueMultivariate,
  title = {Special {{Issue}}: {{Multivariate Approaches}} to {{Social Neuroscience}}},
  author = {Lockwood, Patricia L and {Klein-Fl{\"u}gge}, Miriam C},
  pages = {11},
  abstract = {Social neuroscience aims to describe the neural systems that underpin social cognition and behaviour. Over the past decade, researchers have begun to combine computational models with neuroimaging to link social computations to the brain. Inspired by approaches from reinforcement learning theory, which describes how decisions are driven by the unexpectedness of outcomes, accounts of the neural basis of prosocial learning, observational learning, mentalizing and impression formation have been developed. Here we provide an introduction for researchers who wish to use these models in their studies. We consider both theoretical and practical issues related to their implementation, with a focus on specific examples from the field.},
  language = {en},
  keywords = {computational-modeling,statistika}
}

@article{loftusInterpretationInteractions1978,
  title = {On Interpretation of Interactions},
  author = {Loftus, Geoffrey R.},
  year = {1978},
  journal = {Memory \& Cognition},
  volume = {6},
  number = {3},
  pages = {312--319}
}

@article{loftusUsingConfidenceIntervals1994,
  title = {Using {{Confidence Intervals}} in {{Within}}-Subject {{Designs}}},
  author = {Loftus, Geoffrey R. and Masson, Michael E. J.},
  year = {1994},
  month = dec,
  journal = {Psychonomic Bulletin \& Review},
  volume = {1},
  number = {4},
  pages = {476--490},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03210951},
  language = {en},
  keywords = {statistika,visualization}
}

@article{loganExecutiveControlThought2003,
  title = {Executive Control of Thought and Action: {{In}} Search of the Wild Homunculus},
  author = {Logan, Gordon D.},
  year = {2003},
  journal = {Current Directions in Psychological Science},
  volume = {12},
  number = {2},
  pages = {45--48}
}

@article{lokenMeasurementErrorReplication2017,
  title = {Measurement Error and the Replication Crisis},
  author = {Loken, Eric and Gelman, Andrew},
  year = {2017},
  month = feb,
  journal = {Science},
  volume = {355},
  number = {6325},
  pages = {584--585},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aal3618},
  abstract = {Measurement error adds noise to predictions, increases uncertainty in parameter estimates, and makes it more difficult to discover new phenomena or to distinguish among competing theories. A common view is that any study finding an effect under noisy conditions provides evidence that the underlying effect is particularly strong and robust. Yet, statistical significance conveys very little information when measurements are noisy. In noisy research settings, poor measurement can contribute to exaggerated estimates of effect size. This problem and related misunderstandings are key components in a feedback loop that perpetuates the replication crisis in science. The assumption that measurement error always reduces effect sizes is false The assumption that measurement error always reduces effect sizes is false},
  chapter = {Perspectives},
  copyright = {Copyright \textcopyright{} 2017, American Association for the Advancement of Science},
  language = {en},
  pmid = {28183939},
  keywords = {statistika},
  file = {/home/denis/Zotero/storage/SI826XGE/tab-pdf.html}
}

@book{lovricInternationalEncyclopediaStatistical2011,
  title = {International {{Encyclopedia}} of {{Statistical Science}}},
  author = {Lovri{\'c}, Miodrag},
  year = {2011},
  publisher = {{Springer}},
  isbn = {3-642-04897-8},
  keywords = {statistika}
}

@article{lundbergWhatYourEstimand2020,
  title = {What Is {{Your Estimand}}? {{Defining}} the {{Target Quantity Connects Statistical Evidence}} to {{Theory}}},
  shorttitle = {What Is {{Your Estimand}}?},
  author = {Lundberg, Ian and Johnson, Rebecca and Stewart, Brandon M.},
  year = {2020},
  keywords = {causal-inference,meta-statistika,statistika}
}

@article{lyBayesianReanalysesSummary2018,
  title = {Bayesian {{Reanalyses From Summary Statistics}}: {{A Guide}} for {{Academic Consumers}}},
  author = {Ly, Alexander and Raj, Akash and Etz, Alexander and Marsman, Maarten and Gronau, Quentin F. and Wagenmakers, Eric-Jan},
  year = {2018},
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {1},
  number = {3},
  pages = {367--374},
  abstract = {Across the social sciences, researchers have overwhelmingly used the classical statistical paradigm to draw conclusions from data, often focusing heavily on a single number: p. Recent years, however, have witnessed a surge of interest in an alternative statistical paradigm: Bayesian inference, in which probabilities are attached to parameters and models. We feel it is informative to provide statistical conclusions that go beyond a single number, and\textemdash regardless of one's statistical preference\textemdash it can be prudent to report the results from both the classical and the Bayesian paradigms. In order to promote a more inclusive and insightful approach to statistical inference, we show how the Summary Stats module in the open-source software program JASP (https://jasp-stats.org) can provide comprehensive Bayesian reanalyses from just a few commonly reported summary statistics, such as t and N. These Bayesian reanalyses allow researchers\textemdash and also editors, reviewers, readers, and reporters\textemdash to (a) quantify evidence on a continuous scale using Bayes factors, (b) assess the robustness of that evidence to changes in the prior distribution, and (c) gauge which posterior parameter ranges are more credible than others by examining the posterior distribution of the effect size. The procedure is illustrated using Festinger and Carlsmith's (1959) seminal study on cognitive dissonance.},
  keywords = {bayes,statistika}
}

@article{maceachernPreregistrationModelingExercises2019,
  title = {Preregistration of {{Modeling Exercises May Not Be Useful}}},
  author = {MacEachern, Steven N. and Van Zandt, Trisha},
  year = {2019},
  month = dec,
  journal = {Computational Brain \& Behavior},
  volume = {2},
  number = {3},
  pages = {179--182},
  issn = {2522-087X},
  doi = {10.1007/s42113-019-00038-x},
  abstract = {This is a commentary on Lee et al.'s (2019) article encouraging preregistration of model development, fitting, and evaluation. While we are in general agreement with Lee et al.'s characterization of the modeling process, we disagree on whether preregistration of this process will move the scientific enterprise forward. We emphasize the subjective and exploratory nature of model development, and point out that ``under-modeling'' of data (relying on black-box approaches applied to data without data exploration) is as big a problem as ``over-modeling'' (fitting noise, resulting in models that generalize poorly). We also note the potential long-run negative impact of preregistration on future generations of cognitive scientists. It is our opinion that preregistration of model development will lead to less, and to less creative, exploratory analysis (i.e., to more under-modeling), and that Lee at al.'s primary goals can be achieved by requiring publication of raw data and code. We conclude our commentary with suggestions on how to move forward.},
  language = {en},
  keywords = {filozofija-znanosti,meta-science}
}

@article{mackinnonComparisonMethodsTest2002,
  title = {A Comparison of Methods to Test Mediation and Other Intervening Variable Effects.},
  author = {MacKinnon, David P. and Lockwood, Chondra M. and Hoffman, Jeanne M. and West, Stephen G. and Sheets, Virgil},
  year = {2002},
  journal = {Psychological methods},
  volume = {7},
  number = {1},
  pages = {83},
  keywords = {medijacija,statistika},
  file = {/home/denis/Zotero/storage/7Q9VXE52/PMC2819363.html;/home/denis/Zotero/storage/Z3GU84H3/2002-00925-005.html}
}

@article{mackinnonMediationAnalysis2007,
  title = {Mediation {{Analysis}}},
  author = {MacKinnon, David P. and Fairchild, Amanda J. and Fritz, Matthew S.},
  year = {2007},
  journal = {Annual review of psychology},
  volume = {58},
  pages = {593},
  issn = {0066-4308},
  doi = {10.1146/annurev.psych.58.110405.085542},
  abstract = {Mediating variables are prominent in psychological theory and research. A mediating variable transmits the effect of an independent variable on a dependent variable. Differences between mediating variables and confounders, moderators, and covariates are outlined. Statistical methods to assess mediation and modern comprehensive approaches are described. Future directions for mediation analysis are discussed.},
  pmcid = {PMC2819368},
  pmid = {16968208},
  keywords = {medijacija,statistika}
}

@article{madley-dowdProportionMissingData2019,
  ids = {madley-dowdProportionMissingData2019a},
  title = {The Proportion of Missing Data Should Not Be Used to Guide Decisions on Multiple Imputation},
  author = {{Madley-Dowd}, Paul and Hughes, Rachael and Tilling, Kate and Heron, Jon},
  year = {2019},
  month = jun,
  journal = {Journal of Clinical Epidemiology},
  volume = {110},
  pages = {63--73},
  issn = {08954356},
  doi = {10.1016/j.jclinepi.2019.02.016},
  abstract = {Objectives: Researchers are concerned whether multiple imputation (MI) or complete case analysis should be used when a large proportion of data are missing. We aimed to provide guidance for drawing conclusions from data with a large proportion of missingness. Study Design and Setting: Via simulations, we investigated how the proportion of missing data, the fraction of missing information (FMI), and availability of auxiliary variables affected MI performance. Outcome data were missing completely at random or missing at random (MAR). Results: Provided sufficient auxiliary information was available; MI was beneficial in terms of bias and never detrimental in terms of efficiency. Models with similar FMI values, but differing proportions of missing data, also had similar precision for effect estimates. In the absence of bias, the FMI was a better guide to the efficiency gains using MI than the proportion of missing data. Conclusion: We provide evidence that for MAR data, valid MI reduces bias even when the proportion of missingness is large. We advise researchers to use FMI to guide choice of auxiliary variables for efficiency gain in imputation analyses, and that sensitivity analyses including different imputation models may be needed if the number of complete cases is small. \'O 2019 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).},
  language = {en},
  keywords = {metodologija,missing-data,multiple-imputation,statistika}
}

@article{magnussonBayesianLeaveoneoutCrossvalidation2019,
  title = {Bayesian Leave-One-out Cross-Validation for Large Data},
  author = {Magnusson, M{\aa}ns and Andersen, Michael Riis and Jonasson, Johan and Vehtari, Aki},
  year = {2019},
  month = apr,
  journal = {arXiv:1904.10679 [cs, stat]},
  eprint = {1904.10679},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Model inference, such as model comparison, model checking, and model selection, is an important part of model development. Leave-one-out cross-validation (LOO) is a general approach for assessing the generalizability of a model, but unfortunately, LOO does not scale well to large datasets. We propose a combination of using approximate inference techniques and probability-proportional-to-size-sampling (PPS) for fast LOO model evaluation for large datasets. We provide both theoretical and empirical results showing good properties for large data.},
  archiveprefix = {arXiv},
  language = {en},
  keywords = {bayes,cross-validation,statistika}
}

@book{mayoStatisticalInferenceSevere2018,
  title = {Statistical Inference as Severe Testing},
  author = {Mayo, Deborah G.},
  year = {2018},
  publisher = {{Cambridge University Press}},
  keywords = {filozofija-znanosti,statistika}
}

@article{mccarthyMTLDVocdDHDD2010,
  title = {{{MTLD}}, Vocd-{{D}}, and {{HD}}-{{D}}: {{A}} Validation Study of Sophisticated Approaches to Lexical Diversity Assessment},
  author = {McCarthy, Philip M. and Jarvis, Scott},
  year = {2010},
  journal = {Behavior research methods},
  volume = {42},
  number = {2},
  pages = {381--392},
  keywords = {lexical-diversity,metodologija}
}

@article{mccarthyVocdTheoreticalEmpirical2007,
  title = {Vocd: {{A}} Theoretical and Empirical Evaluation},
  author = {McCarthy, Philip M. and Jarvis, Scott},
  year = {2007},
  journal = {Language Testing},
  volume = {24},
  number = {4},
  pages = {459--488},
  keywords = {lexical-diversity,metodologija}
}

@book{mcelreathStatisticalRethinkingBayesian2020,
  title = {Statistical {{Rethinking}}: {{A Bayesian Course}} with {{Examples}} in {{R}} and {{Stan}}},
  author = {McElreath, Richard},
  year = {2020},
  publisher = {{CRC press}},
  isbn = {0-429-63914-7},
  keywords = {bayes,statistika}
}

@article{mcgrawCommonLanguageEffect1992,
  title = {A Common Language Effect Size Statistic.},
  author = {McGraw, Kenneth O. and Wong, S. P.},
  year = {1992},
  journal = {Psychological bulletin},
  volume = {111},
  number = {2},
  pages = {361},
  keywords = {effect-size,statistika}
}

@book{mcnamaraAutomatedEvaluationText2014,
  title = {Automated Evaluation of Text and Discourse with {{Coh}}-{{Metrix}}},
  author = {McNamara, Danielle S and Graesser, Arthur C and McCarthy, Philip M and Cai, Zhiqiang},
  year = {2014},
  publisher = {{Cambridge University Press}},
  address = {{New York, NY}},
  keywords = {coh-metrix}
}

@article{mcneishThanksCoefficientAlpha2018,
  title = {Thanks Coefficient Alpha, We'll Take It from Here.},
  author = {McNeish, Daniel},
  year = {2018},
  journal = {Psychological Methods},
  volume = {23},
  number = {3},
  pages = {412--433},
  issn = {1939-1463(Electronic),1082-989X(Print)},
  doi = {10.1037/met0000144},
  abstract = {Empirical studies in psychology commonly report Cronbach's alpha as a measure of internal consistency reliability despite the fact that many methodological studies have shown that Cronbach's alpha is riddled with problems stemming from unrealistic assumptions. In many circumstances, violating these assumptions yields estimates of reliability that are too small, making measures look less reliable than they actually are. Although methodological critiques of Cronbach's alpha are being cited with increasing frequency in empirical studies, in this tutorial we discuss how the trend is not necessarily improving methodology used in the literature. That is, many studies continue to use Cronbach's alpha without regard for its assumptions or merely cite methodological articles advising against its use to rationalize unfavorable Cronbach's alpha estimates. This tutorial first provides evidence that recommendations against Cronbach's alpha have not appreciably changed how empirical studies report reliability. Then, we summarize the drawbacks of Cronbach's alpha conceptually without relying on mathematical or simulation-based arguments so that these arguments are accessible to a broad audience. We continue by discussing several alternative measures that make less rigid assumptions which provide justifiably higher estimates of reliability compared to Cronbach's alpha. We conclude with empirical examples to illustrate advantages of alternative measures of reliability including omega total, Revelle's omega total, the greatest lower bound, and Coefficient H. A detailed software appendix is also provided to help researchers implement alternative methods. (PsycINFO Database Record (c) 2018 APA, all rights reserved)},
  keywords = {pouzdanost,statistika}
}

@techreport{mellorTransparentScienceMore2018,
  type = {Preprint},
  title = {Transparent Science: {{A}} More Credible, Reproducible, and Publishable Way to Do Science},
  shorttitle = {Transparent Science},
  author = {Mellor, David Thomas and Vazire, Simine and Lindsay, D. Stephen},
  year = {2018},
  month = jan,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/7wkdn},
  abstract = {Background and PerspectiveThis is an exciting time to be a psychological scientist. There is a major new movement that seeks to promote the credibility and replicability of psychological research by enhancing its transparency, with scholarly societies promoting the principles (http://www.psychologicalscience.org/publications/open-science) and groups formed specifically to advance that mission (see http://improvingpsych.org/ and https://cos.io for two examples). While relatively low rates of replicability among scientific findings (Begley \&amp; Ellis, 2012; OSC, 2015; Chang \&amp; Li 2015) inspired the existence of these groups, in this chapter we describe how striving to maximize transparency in your research can benefit both science and your career.},
  keywords = {reproducibility-crisis}
}

@article{mengStatisticalParadisesParadoxes2018,
  ids = {mengStatisticalParadisesParadoxes2018a},
  title = {Statistical Paradises and Paradoxes in Big Data ({{I}}): {{Law}} of Large Populations, Big Data Paradox, and the 2016 {{US}} Presidential Election},
  shorttitle = {Statistical Paradises and Paradoxes in Big Data ({{I}})},
  author = {Meng, Xiao-Li},
  year = {2018},
  month = jun,
  journal = {The Annals of Applied Statistics},
  volume = {12},
  number = {2},
  pages = {685--726},
  issn = {1932-6157},
  doi = {10.1214/18-AOAS1161SF},
  language = {en},
  keywords = {filozofija-znanosti,meta-statistika,statistika}
}

@book{meredithHDIntervalHighestPosterior2018,
  title = {{{HDInterval}}: {{Highest}} ({{Posterior}}) {{Density Intervals}}},
  author = {Meredith, Mike and Kruschke, John},
  year = {2018}
}

@article{merkleBlavaanBayesianStructural2018,
  title = {Blavaan : {{Bayesian Structural Equation Models}} via {{Parameter Expansion}}},
  shorttitle = {{\textbf{Blavaan}}},
  author = {Merkle, Edgar C. and Rosseel, Yves},
  year = {2018},
  journal = {Journal of Statistical Software},
  volume = {85},
  number = {4},
  issn = {1548-7660},
  doi = {10.18637/jss.v085.i04},
  abstract = {This article describes blavaan, an R package for estimating Bayesian structural equation models (SEMs) via JAGS and for summarizing the results. It also describes a novel parameter expansion approach for estimating specific types of models with residual covariances, which facilitates estimation of these models in JAGS. The methodology and software are intended to provide users with a general means of estimating Bayesian SEMs, both classical and novel, in a straightforward fashion. Users can estimate Bayesian versions of classical SEMs with lavaan syntax, they can obtain state-of-the-art Bayesian fit measures associated with the models, and they can export JAGS code to modify the SEMs as desired. These features and more are illustrated by example, and the parameter expansion approach is explained in detail.},
  language = {en},
  keywords = {sem,statistika}
}

@incollection{milinModelsLexicalAccess2017,
  title = {Models of {{Lexical Access}} and {{Morphological Processing}}},
  booktitle = {Handbook of {{Psycholinguistics}}},
  author = {Milin, Petar and Smolka, Eva and Feldman, Laurie Beth},
  editor = {Fern{\'a}ndez, Eva M. and Smith Cairns, Helen},
  year = {2017},
  pages = {240--268},
  publisher = {{Wiley Blackwell}}
}

@misc{millisecondsoftwareInquisitWindows2016,
  title = {Inquisit for {{Windows}} 5.0},
  author = {{Millisecond Software}},
  year = {2016},
  address = {{Seattle, WA}}
}

@article{mirowskiFutureOpenScience2018,
  title = {The Future(s) of Open Science},
  author = {Mirowski, Philip},
  year = {2018},
  month = apr,
  journal = {Social Studies of Science},
  volume = {48},
  number = {2},
  pages = {171--203},
  issn = {0306-3127},
  doi = {10.1177/0306312718772086},
  abstract = {Almost everyone is enthusiastic that `open science' is the wave of the future. Yet when one looks seriously at the flaws in modern science that the movement proposes to remedy, the prospect for improvement in at least four areas are unimpressive. This suggests that the agenda is effectively to re-engineer science along the lines of platform capitalism, under the misleading banner of opening up science to the masses.},
  language = {en},
  keywords = {reproducibility-crisis}
}

@article{mohanGraphicalModelsProcessing2019,
  title = {Graphical {{Models}} for {{Processing Missing Data}}},
  author = {Mohan, Karthika and Pearl, Judea},
  year = {2019},
  month = nov,
  journal = {arXiv:1801.03583 [stat]},
  eprint = {1801.03583},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {This paper reviews recent advances in missing data research using graphical models to represent multivariate dependencies. We first examine the limitations of traditional frameworks from three different perspectives: transparency, estimability and testability. We then show how procedures based on graphical models can overcome these limitations and provide meaningful performance guarantees even when data are Missing Not At Random (MNAR). In particular, we identify conditions that guarantee consistent estimation in broad categories of missing data problems, and derive procedures for implementing this estimation. Finally we derive testable implications for missing data models in both MAR (Missing At Random) and MNAR categories.},
  archiveprefix = {arXiv},
  language = {en},
  keywords = {causal-inference,metodologija,missing-data,statistika}
}

@article{monsellTaskSwitching2003,
  title = {Task Switching},
  author = {Monsell, Stephen},
  year = {2003},
  journal = {Trends in cognitive sciences},
  volume = {7},
  number = {3},
  pages = {134--140}
}

@book{moreyBayesFactorComputationBayes2018,
  title = {{{BayesFactor}}: {{Computation}} of {{Bayes Factors}} for {{Common Designs}}},
  author = {Morey, Richard D. and Rouder, Jeffrey N.},
  year = {2018}
}

@book{morganCounterfactualsCausalInference2015,
  title = {Counterfactuals and Causal Inference},
  author = {Morgan, Stephen L. and Winship, Christopher},
  year = {2015},
  publisher = {{Cambridge University Press}},
  isbn = {1-107-06507-0},
  keywords = {causal-inference,statistika}
}

@article{morganRerandomizationBalanceTiers2015,
  title = {Rerandomization to {{Balance Tiers}} of {{Covariates}}},
  author = {Morgan, Kari Lock and Rubin, Donald B.},
  year = {2015},
  month = oct,
  journal = {Journal of the American Statistical Association},
  volume = {110},
  number = {512},
  pages = {1412--1421},
  issn = {0162-1459},
  doi = {10.1080/01621459.2015.1079528},
  abstract = {When conducting a randomized experiment, if an allocation yields treatment groups that differ meaningfully with respect to relevant covariates, groups should be rerandomized. The process involves specifying an explicit criterion for whether an allocation is acceptable, based on a measure of covariate balance, and rerandomizing units until an acceptable allocation is obtained. Here, we illustrate how rerandomization could have improved the design of an already conducted randomized experiment on vocabulary and mathematics training programs, then provide a rerandomization procedure for covariates that vary in importance, and finally offer other extensions for rerandomization, including methods addressing computational efficiency. When covariates vary in a priori importance, better balance should be required for more important covariates. Rerandomization based on Mahalanobis distance preserves the joint distribution of covariates, but balances all covariates equally. Here, we propose rerandomizing based on Mahalanobis distance within tiers of covariate importance. Because balancing covariates in one tier will in general also partially balance covariates in other tiers, for each subsequent tier we explicitly balance only the components orthogonal to covariates in more important tiers.},
  pmid = {27695149},
  keywords = {metodologija,rerandomization,statistika},
  file = {/home/denis/Zotero/storage/ITNDXTMY/01621459.2015.html}
}

@article{morganRerandomizationImproveCovariate2012,
  title = {Rerandomization to Improve Covariate Balance in Experiments},
  author = {Morgan, Kari Lock and Rubin, Donald B.},
  year = {2012},
  month = apr,
  journal = {The Annals of Statistics},
  volume = {40},
  number = {2},
  pages = {1263--1282},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/12-AOS1008},
  abstract = {Randomized experiments are the ``gold standard'' for estimating causal effects, yet often in practice, chance imbalances exist in covariate distributions between treatment groups. If covariate data are available before units are exposed to treatments, these chance imbalances can be mitigated by first checking covariate balance before the physical experiment takes place. Provided a precise definition of imbalance has been specified in advance, unbalanced randomizations can be discarded, followed by a rerandomization, and this process can continue until a randomization yielding balance according to the definition is achieved. By improving covariate balance, rerandomization provides more precise and trustworthy estimates of treatment effects.},
  language = {EN},
  mrnumber = {MR2985950},
  zmnumber = {1274.62509},
  keywords = {metodologija,rerandomization,statistika},
  file = {/home/denis/Zotero/storage/W8TAK2X4/1342625468.html}
}

@article{muellerAlphabeticLetterIdentification2012,
  title = {Alphabetic Letter Identification: {{Effects}} of Perceivability, Similarity, and Bias},
  shorttitle = {Alphabetic Letter Identification},
  author = {Mueller, Shane T. and Weidemann, Christoph T.},
  year = {2012},
  month = jan,
  journal = {Acta Psychologica},
  volume = {139},
  number = {1},
  pages = {19--37},
  issn = {00016918},
  doi = {10.1016/j.actpsy.2011.09.014},
  abstract = {The legibility of the letters in the Latin alphabet has been measured numerous times since the beginning of experimental psychology. To identify the theoretical mechanisms attributed to letter identification, we report a comprehensive review of literature, spanning more than a century. This review revealed that identification accuracy has frequently been attributed to a subset of three common sources: perceivability, bias, and similarity. However, simultaneous estimates of these values have rarely (if ever) been performed. We present the results of two new experiments which allow for the simultaneous estimation of these factors, and examine how the shape of a visual mask impacts each of them, as inferred through a new statistical model. Results showed that the shape and identity of the mask impacted the inferred perceivability, bias, and similarity space of a letter set, but that there were aspects of similarity that were robust to the choice of mask. The results illustrate how the psychological concepts of perceivability, bias, and similarity can be estimated simultaneously, and how each make powerful contributions to visual letter identification.},
  language = {en},
  keywords = {psihologija-jezika}
}

@book{mullerHereSimplerWay2017,
  title = {Here: {{A Simpler Way}} to {{Find Your Files}}},
  author = {M{\"u}ller, Kirill},
  year = {2017}
}

@article{mundryIssuesInformationTheorybased2011,
  title = {Issues in Information Theory-Based Statistical Inference\textemdash a Commentary from a Frequentist's Perspective},
  author = {Mundry, Roger},
  year = {2011},
  journal = {Behavioral Ecology and Sociobiology},
  volume = {65},
  number = {1},
  pages = {57--68},
  keywords = {information-theory,statistika}
}

@article{murrayMultipleImputationReview2018,
  title = {Multiple {{Imputation}}: {{A Review}} of {{Practical}} and {{Theoretical Findings}}},
  shorttitle = {Multiple {{Imputation}}},
  author = {Murray, Jared S.},
  year = {2018},
  month = may,
  journal = {Statistical Science},
  volume = {33},
  number = {2},
  pages = {142--159},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/18-STS644},
  abstract = {Multiple imputation is a straightforward method for handling missing data in a principled fashion. This paper presents an overview of multiple imputation, including important theoretical results and their practical implications for generating and using multiple imputations. A review of strategies for generating imputations follows, including recent developments in flexible joint modeling and sequential regression/chained equations/fully conditional specification approaches. Finally, we compare and contrast different methods for generating imputations on a range of criteria before identifying promising avenues for future research.},
  language = {EN},
  mrnumber = {MR3797707},
  zmnumber = {1397.62052},
  keywords = {multiple-imputation,statistika},
  file = {/home/denis/Zotero/storage/3H62CSI3/1525313139.html}
}

@article{muthukrishnaProblemTheory2019,
  title = {A Problem in Theory},
  author = {Muthukrishna, Michael and Henrich, Joseph},
  year = {2019},
  month = mar,
  journal = {Nature Human Behaviour},
  volume = {3},
  number = {3},
  pages = {221--229},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-018-0522-1},
  abstract = {The replication crisis facing the psychological sciences is widely regarded as rooted in methodological or statistical shortcomings. We argue that a large part of the problem is the lack of a cumulative theoretical framework or frameworks. Without an overarching theoretical framework that generates hypotheses across diverse domains, empirical programs spawn and grow from personal intuitions and culturally biased folk theories. By providing ways to develop clear predictions, including through the use of formal modelling, theoretical frameworks set expectations that determine whether a new finding is confirmatory, nicely integrating with existing lines of research, or surprising, and therefore requiring further replication and scrutiny. Such frameworks also prioritize certain research foci, motivate the use diverse empirical approaches and, often, provide a natural means to integrate across the sciences. Thus, overarching theoretical frameworks pave the way toward a more general theory of human behaviour. We illustrate one such a theoretical framework: dual inheritance theory.},
  copyright = {2019 Springer Nature Limited},
  language = {en},
  file = {/home/denis/Zotero/storage/N9EMYXVK/s41562-018-0522-1.html}
}

@article{nakagawaModelAveragingMissing2011,
  title = {Model Averaging, Missing Data and Multiple Imputation: A Case Study for Behavioural Ecology},
  shorttitle = {Model Averaging, Missing Data and Multiple Imputation},
  author = {Nakagawa, Shinichi and Freckleton, Robert P.},
  year = {2011},
  journal = {Behavioral Ecology and Sociobiology},
  volume = {65},
  number = {1},
  pages = {103--116},
  keywords = {information-theory,missing-data,multiple-imputation,statistika},
  file = {/home/denis/Zotero/storage/Z5VRM66I/s00265-010-1044-7.html}
}

@article{nation2007orthographic,
  title = {Orthographic Learning via Self-Teaching in Children Learning to Read {{English}}: {{Effects}} of Exposure, Durability, and Context},
  author = {Nation, Kate and Angell, Philip and Castles, Anne},
  year = {2007},
  journal = {Journal of experimental child psychology},
  volume = {96},
  number = {1},
  pages = {71--84},
  publisher = {{Elsevier}},
  keywords = {psihologija-jezika,word-exposure}
}

@article{navarroDevilDeepBlue2019,
  title = {Between the {{Devil}} and the {{Deep Blue Sea}}: {{Tensions Between Scientific Judgement}} and {{Statistical Model Selection}}},
  shorttitle = {Between the {{Devil}} and the {{Deep Blue Sea}}},
  author = {Navarro, Danielle J.},
  year = {2019},
  month = mar,
  journal = {Computational Brain \& Behavior},
  volume = {2},
  number = {1},
  pages = {28--34},
  issn = {2522-087X},
  doi = {10.1007/s42113-018-0019-z},
  abstract = {Discussions of model selection in the psychological literature typically frame the issues as a question of statistical inference, with the goal being to determine which model makes the best predictions about data. Within this setting, advocates of leave-one-out cross-validation and Bayes factors disagree on precisely which prediction problem model selection questions should aim to answer. In this comment, I discuss some of these issues from a scientific perspective. What goal does model selection serve when all models are known to be systematically wrong? How might ``toy problems'' tell a misleading story? How does the scientific goal of explanation align with (or differ from) traditional statistical concerns? I do not offer answers to these questions, but hope to highlight the reasons why psychological researchers cannot avoid asking them.},
  language = {en},
  keywords = {filozofija-znanosti,statistika}
}

@techreport{navarroIfMathematicalPsychology2020,
  type = {Preprint},
  title = {If Mathematical Psychology Did Not Exist We Would Need to Invent It: {{A}} Case Study in Cumulative Theoretical Development},
  shorttitle = {If Mathematical Psychology Did Not Exist We Would Need to Invent It},
  author = {Navarro, Danielle J.},
  year = {2020},
  month = mar,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/ygbjp},
  abstract = {It is commonplace, when discussing the subject of psychological theory, to write articles from the assumption that psychology differs from physical sciences in that we have no psychological theories that would support cumulative, incremental science. In this brief paper I discuss one counterexample, namely Shepard's (1987) universal law of generalization and the various Bayesian extensions that it inspired over the last three decades. Though not disputing the claim that good theories in psychological science are rarer than one would like, I suggest that the subdiscipline of mathematical psychology is a good place to look to find them.},
  language = {en},
  keywords = {filozofija-znanosti}
}

@misc{navarroPathsStrangeSpaces2020,
  title = {Paths in Strange Spaces: {{A}} Comment on Preregistration},
  shorttitle = {Paths in Strange Spaces},
  author = {Navarro, Danielle},
  year = {2020},
  month = sep,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/wxn58},
  abstract = {This is an archived version of a blog post on preregistration. The first half of the post argues that there is not a strong justification for preregistration as a tool to solve problems with statistical inference (p-hacking); the second half argues that preregistration has a stronger justification as one tool (among many) that can aid scientists in documenting our projects. [Note that this archival version exists only because the blog itself no longer does, and as the original has been cited multiple times there is value in ensuring that some version of the blog post remains accessible.]},
  keywords = {meta-science}
}

@article{newmanMissingDataFive2014,
  title = {Missing Data: {{Five}} Practical Guidelines},
  shorttitle = {Missing Data},
  author = {Newman, Daniel A.},
  year = {2014},
  journal = {Organizational Research Methods},
  volume = {17},
  number = {4},
  pages = {372--411},
  keywords = {missing-data,multiple-imputation,statistika},
  file = {/home/denis/Zotero/storage/QANDM2WS/1094428114548590.html}
}

@article{newUseFilmSubtitles2007,
  title = {The {{Use}} of {{Film Subtitles}} to {{Estimate Word Frequencies}}},
  author = {New, Boris and Brysbaert, Marc and Veronis, Jean and Pallier, Christophe},
  year = {2007},
  journal = {Applied psycholinguistics},
  volume = {28},
  number = {4},
  pages = {661--677},
  keywords = {metodologija,psihologija-jezika}
}

@incollection{nicolComprehensionAnaphoraVerb2018,
  title = {The {{Comprehension}} of {{Anaphora}} and {{Verb Agreement}}},
  booktitle = {The {{Handbook}} of {{Psycholinguistics}}},
  author = {Nicol, Janet L. and Barss, Andrew},
  editor = {Fern{\'a}ndez, Eva M. and Smith Cairns, Helen},
  year = {2018},
  pages = {345--364},
  publisher = {{Wiley Blackwell}}
}

@article{nobleQuickGuideOrganizing2009,
  title = {A {{Quick Guide}} to {{Organizing Computational Biology Projects}}},
  author = {Noble, William Stafford},
  year = {2009},
  month = jul,
  journal = {PLOS Computational Biology},
  volume = {5},
  number = {7},
  pages = {e1000424},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1000424},
  language = {en},
  keywords = {software,stat-project-management},
  file = {/home/denis/Zotero/storage/HFLLQZJU/article.html}
}

@article{norrisBayesianReaderExplaining2006,
  title = {The {{Bayesian Reader}}: {{Explaining Word Recognition}} as an {{Optimal Bayesian Decision Process}}},
  shorttitle = {The {{Bayesian}} Reader},
  author = {Norris, Dennis},
  year = {2006},
  journal = {Psychological Review},
  volume = {113},
  number = {2},
  pages = {327--357},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/0033-295X.113.2.327},
  language = {en},
  keywords = {bayesian-reader,psihologija-jezika}
}

@article{norrisPuttingItAll2009,
  title = {Putting It All Together: {{A}} Unified Account of Word Recognition and Reaction-Time Distributions.},
  shorttitle = {Putting It All Together},
  author = {Norris, Dennis},
  year = {2009},
  journal = {Psychological Review},
  volume = {116},
  number = {1},
  pages = {207--219},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/a0014259},
  abstract = {Ratcliff, Gomez and McKoon (2004) suggested much of what goes on in lexical decision is attributable to decision processes, and may not be particularly informative about word recognition. They proposed that lexical decision should be characterized by a decision process, taking the form of a drift-diffusion model (Ratcliff, 1978), which operates on the output of lexical model. The present paper argues that the distinction between perception and decision-making is unnecessary, and that it is possible to give a unified account of both lexical processing and decision making. This claim is supported by formal arguments, and reinforced by simulations showing how the Bayesian Reader model (Norris, 2006) can be extended to fit the data on RT distributions collected by Ratcliff, Gomez and McKoon, simply by adding extra sources of noise. The Bayesian Reader gives an integrated explanation of both word recognition and decision making, using fewer parameters than the diffusion model. It can be thought of as a Bayesian diffusion model, which subsumes Ratcliff's drift-diffusion model as a special case.},
  language = {en},
  keywords = {bayesian-reader,psihologija-jezika}
}

@article{norrisReadingNoisyChannel2012,
  title = {Reading through a Noisy Channel: {{Why}} There's Nothing Special about the Perception of Orthography.},
  shorttitle = {Reading through a Noisy Channel},
  author = {Norris, Dennis and Kinoshita, Sachiko},
  year = {2012},
  journal = {Psychological Review},
  volume = {119},
  number = {3},
  pages = {517--545},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/a0028450},
  abstract = {The goal of research on how letter identity and order are perceived during reading is often characterized as one of ``cracking the orthographic code.'' Here, we suggest that there is no orthographic code to crack: Words are perceived and represented as sequences of letters, just as in a dictionary. Indeed, words are perceived and represented in exactly the same way as other visual objects. The phenomena that have been taken as evidence for specialized orthographic representations can be explained by assuming that perception involves recovering information that has passed through a noisy channel: the early stages of visual perception. The noisy channel introduces uncertainty into letter identity, letter order, and even whether letters are present or absent. We develop a computational model based on this simple principle and show that it can accurately simulate lexical decision data from the lexicon projects in English, French, and Dutch, along with masked priming data that have been taken as evidence for specialized orthographic representations.},
  language = {en},
  keywords = {bayesian-reader,psihologija-jezika}
}

@article{nosekScientificUtopiaII2012,
  title = {Scientific {{Utopia}}: {{II}}. {{Restructuring Incentives}} and {{Practices}} to {{Promote Truth Over Publishability}}},
  shorttitle = {Scientific {{Utopia}}},
  author = {Nosek, Brian A. and Spies, Jeffrey R. and Motyl, Matt},
  year = {2012},
  month = nov,
  journal = {Perspectives on Psychological Science},
  volume = {7},
  number = {6},
  pages = {615--631},
  issn = {1745-6916},
  doi = {10.1177/1745691612459058},
  abstract = {An academic scientist's professional success depends on publishing. Publishing norms emphasize novel, positive results. As such, disciplinary incentives encourage design, analysis, and reporting decisions that elicit positive results and ignore negative results. Prior reports demonstrate how these incentives inflate the rate of false effects in published science. When incentives favor novelty over replication, false results persist in the literature unchallenged, reducing efficiency in knowledge accumulation. Previous suggestions to address this problem are unlikely to be effective. For example, a journal of negative results publishes otherwise unpublishable reports. This enshrines the low status of the journal and its content. The persistence of false findings can be meliorated with strategies that make the fundamental but abstract accuracy motive\textemdash getting it right\textemdash competitive with the more tangible and concrete incentive\textemdash getting it published. This article develops strategies for improving scientific practices and knowledge accumulation that account for ordinary human motivations and biases.},
  language = {en},
  keywords = {reproducibility-crisis}
}

@techreport{nustTenSimpleRules2020,
  title = {Ten {{Simple Rules}} for {{Writing Dockerfiles}} for {{Reproducible Data Science}}},
  author = {N{\"u}st, Daniel and Sochat, Vanessa and Marwick, Ben and Eglen, Stephen and Head, Tim and Hirst, Tony and Evans, Benjamin},
  year = {2020},
  month = apr,
  institution = {{OSF Preprints}},
  doi = {10.31219/osf.io/fsd7t},
  abstract = {Computational science has been greatly improved by the use of containers for packaging software and data dependencies. In a scholarly context, the main drivers for using these containers are transparency and support of reproducibility; in turn, a workflow's reproducibility can be greatly affected by the choices that are made with respect to building containers. In many cases, the build process for the container's image is created from instructions provided in a Dockerfile format. In support of this approach, we present a set of rules to help researchers write understandable Dockerfiles for typical data science workflows. By following the rules in this article, researchers can create containers suitable for sharing with fellow scientists, for including in scholarly communication such as education or scientific papers, and for effective and sustainable personal workflows.}
}

@book{o2016weapons,
  title = {Weapons of Math Destruction: {{How}} Big Data Increases Inequality and Threatens Democracy},
  author = {O'Neil, Cathy},
  year = {2016},
  publisher = {{Penguin}}
}

@article{olveraastiviaCenteringMultipleRegression2018,
  ids = {olveraastiviaCenteringMultipleRegression2019},
  title = {Centering in {{Multiple Regression Does Not Always Reduce Multicollinearity}}: {{How}} to {{Tell When Your Estimates Will Not Benefit From Centering}}},
  author = {Olvera Astivia, Oscar L. and Kroc, Edward},
  year = {2018},
  journal = {Educational and Psychological Measurement},
  pages = {0013164418817801},
  publisher = {{SAGE Publications Inc}},
  keywords = {metodologija,regresija,statistika}
}

@article{orbenAssociationAdolescentWellbeing2019,
  title = {The Association between Adolescent Well-Being and Digital Technology Use},
  author = {Orben, Amy and Przybylski, Andrew K.},
  year = {2019},
  journal = {Nature Human Behaviour},
  volume = {3},
  number = {2},
  pages = {173},
  keywords = {metodologija,specification-curve,statistika},
  file = {/home/denis/Zotero/storage/SVI5SKAU/s41562-018-0506-1.html}
}

@book{ormeMultipleRegressionDiscrete2009,
  title = {Multiple Regression with Discrete Dependent Variables},
  author = {Orme, John G and {Combs-Orme}, Terri},
  year = {2009},
  publisher = {{Oxford University Press}},
  address = {{New York, NY}}
}

@article{oswaldDevelopmentShortDomaingeneral2015,
  title = {The Development of a Short Domain-General Measure of Working Memory Capacity},
  author = {Oswald, Frederick L. and McAbee, Samuel T. and Redick, Thomas S. and Hambrick, David Z.},
  year = {2015},
  journal = {Behavior research methods},
  volume = {47},
  number = {4},
  pages = {1343--1355},
  keywords = {complex-span-test}
}

@book{p.iPermutationParametricBootstrap2005,
  title = {Permutation, {{Parametric}} and {{Bootstrap Tests}} of {{Hypotheses}}: {{A Practical Guide}} to {{Resampling Methods}} for {{Testing Hypotheses}}},
  author = {P.I, Good},
  year = {2005},
  edition = {Third Edition},
  isbn = {0-387-20279-X},
  keywords = {effect-size,statistika}
}

@article{palestroTutorialJointModels2018,
  title = {A Tutorial on Joint Models of Neural and Behavioral Measures of Cognition},
  author = {Palestro, James J. and Bahg, Giwon and Sederberg, Per B. and Lu, Zhong-Lin and Steyvers, Mark and Turner, Brandon M.},
  year = {2018},
  month = jun,
  journal = {Journal of Mathematical Psychology},
  volume = {84},
  pages = {20--48},
  issn = {00222496},
  doi = {10.1016/j.jmp.2018.03.003},
  abstract = {A growing synergy between the fields of cognitive neuroscience and mathematical psychology has sparked the development of several unique statistical approaches exploiting the benefits of both disciplines (Turner, Forstmann et al., 2017). One approach in particular, called joint modeling, attempts to model the covariation between the parameters of ``submodels'' intended to capture important patterns in each stream of data. Joint models present an interesting opportunity to transcend conventional levels of analyses (e.g., Marr's hierarchy; Marr, 1982) by providing fully integrative models (Love, 2015). In this manuscript, we provide a tutorial of two flavors of joint models \textemdash{} the Directed and Covariance approaches. Computational procedures have been developed to apply these approaches to a number of cognitive tasks, yet neither have been made accessible to a wider audience. Here, we provide a stepby-step walkthrough on how to develop submodels of each stream of data, as well as how to link the important model parameters to form one cohesive model. For convenience, we provide code that uses the Just Another Gibbs Sampler (Plummer, 2003) software to perform estimation of the model parameters. We close with a demonstration of the approach applied to actual data from a contrast discrimination task where activation parameters of early visual areas are directly mapped to the drift rate parameter in a simplified version of the diffusion decision model (Ratcliff, 1978).},
  language = {en}
}

@article{palminteriImportanceFalsificationComputational2017,
  title = {The {{Importance}} of {{Falsification}} in {{Computational Cognitive Modeling}}},
  author = {Palminteri, Stefano and Wyart, Valentin and Koechlin, Etienne},
  year = {2017},
  month = jun,
  journal = {Trends in Cognitive Sciences},
  volume = {21},
  number = {6},
  pages = {425--433},
  publisher = {{Elsevier}},
  issn = {1364-6613, 1879-307X},
  doi = {10.1016/j.tics.2017.03.011},
  language = {English},
  pmid = {28476348},
  keywords = {filozofija-znanosti},
  file = {/home/denis/Zotero/storage/A94X9BJI/S1364-6613(17)30054-2.html}
}

@article{papaspiliopoulosGeneralFrameworkParametrization2007,
  title = {A {{General Framework}} for the {{Parametrization}} of {{Hierarchical Models}}},
  author = {Papaspiliopoulos, Omiros and Roberts, Gareth O. and Sk{\"o}ld, Martin},
  year = {2007},
  journal = {Statistical Science},
  volume = {22},
  number = {1},
  pages = {59--73},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237},
  abstract = {In this paper, we describe centering and noncentering methodology as complementary techniques for use in parametrization of broad classes of hierarchical models, with a view to the construction of effective MCMC algorithms for exploring posterior distributions from these models. We give a clear qualitative understanding as to when centering and noncentering work well, and introduce theory concerning the convergence time complexity of Gibbs samplers using centered and noncentered parametrizations. We give general recipes for the construction of noncentered parametrizations, including an auxiliary variable technique called the state-space expansion technique. We also describe partially noncentered methods, and demonstrate their use in constructing robust Gibbs sampler algorithms whose convergence properties are not overly sensitive to the data.},
  keywords = {bayes,statistika}
}

@article{pastotterRetrievalPracticeEnhances2014,
  title = {Retrieval Practice Enhances New Learning: The Forward Effect of Testing},
  author = {Past{\"o}tter, Bernhard and B{\"a}uml, Karl-Heinz Thomas},
  year = {2014},
  journal = {Frontiers in Psychology},
  volume = {5},
  pages = {286},
  keywords = {interpolated-testing}
}

@book{pearlBookWhyNew2018,
  title = {The {{Book}} of {{Why}}: {{The New Science}} of {{Cause}} and {{Effect}}},
  author = {Pearl, Judea and Mackenzie, Dana},
  year = {2018},
  publisher = {{Basic Books}},
  isbn = {0-465-09761-8},
  keywords = {causal-inference,statistika}
}

@incollection{pearlCausalCalculusStatistical1996,
  title = {A {{Causal Calculus}} for {{Statistical Research}}},
  booktitle = {Learning from {{Data}}},
  author = {Pearl, Judea},
  editor = {Bickel, P. and Diggle, P. and Fienberg, S. and Krickeberg, K. and Olkin, I. and Wermuth, N. and Zeger, S. and Fisher, Doug and Lenz, Hans-J.},
  year = {1996},
  volume = {112},
  pages = {23--33},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4612-2404-4_3},
  isbn = {978-0-387-94736-5 978-1-4612-2404-4},
  language = {en},
  keywords = {causal-inference,do-calculus,statistika}
}

@article{pearlCausalDiagramsEmpirical1995,
  title = {Causal {{Diagrams}} for {{Empirical Research}}},
  author = {Pearl, Judea},
  year = {1995},
  journal = {Biometrika},
  volume = {82},
  number = {4},
  pages = {669--710},
  abstract = {The primary aim of this paper is to show how graphical models can be used as a mathematical language for integrating statistical and subject-matter information. In particular, the paper develops a principled, nonparametric framework for causal inference, in which diagrams are queried to determine if the assumptions available are sufficient for identifying causal effects from nonexperimental data. If so the diagrams can be queried to produce mathematical expressions for causal effects in terms of observed distributions; otherwise, the diagrams can be queried to suggest additional observations or auxiliary experiments from which the desired inferences can be obtained.},
  language = {en},
  keywords = {causal-inference,statistika}
}

@techreport{pearlCausalFoundationsStructural2012,
  title = {The Causal Foundations of Structural Equation Modeling},
  author = {Pearl, Judea},
  year = {2012},
  institution = {{CALIFORNIA UNIV LOS ANGELES DEPT OF COMPUTER SCIENCE}},
  keywords = {causal-inference,sem,statistika}
}

@book{pearlCausalInferenceStatistics2016,
  title = {Causal {{Inference}} in {{Statistics}}: {{A Primer}}},
  author = {Pearl, Judea and Glymour, Madelyn and Jewell, Nicholas P.},
  year = {2016},
  publisher = {{John Wiley \& Sons}},
  isbn = {1-119-18684-6},
  keywords = {causal-inference,statistika}
}

@article{pearlCommentUnderstandingSimpson2014,
  ids = {pearlCommentUnderstandingSimpson2014a},
  title = {Comment: {{Understanding Simpson}}'s {{Paradox}}},
  shorttitle = {Comment},
  author = {Pearl, Judea},
  year = {2014},
  month = jan,
  journal = {The American Statistician},
  volume = {68},
  number = {1},
  pages = {8--13},
  issn = {0003-1305, 1537-2731},
  doi = {10.1080/00031305.2014.876829},
  language = {en},
  keywords = {causal-inference,statistika}
}

@article{pearlDirectIndirectEffects2013,
  title = {Direct and {{Indirect Effects}}},
  author = {Pearl, Judea},
  year = {2013},
  journal = {arXiv preprint arXiv:1301.2300},
  eprint = {1301.2300},
  eprinttype = {arxiv},
  archiveprefix = {arXiv},
  keywords = {causal-inference,medijacija}
}

@incollection{pearlEightMythsCausality2013,
  title = {Eight {{Myths About Causality}} and {{Structural Equation Models}}},
  booktitle = {Handbook of {{Causal Analysis}} for {{Social Research}}},
  author = {Pearl, Judea and Bollen, Kenneth A.},
  editor = {Morgan, Stephen L.},
  year = {2013},
  series = {Handbooks of Sociology and Social Research},
  edition = {First},
  pages = {301--328},
  publisher = {{Springer Netherlands}},
  isbn = {978-94-007-6093-6 978-94-007-6094-3},
  keywords = {causal-inference,sem,statistika}
}

@article{pearlFoundationsCausalInference2010,
  title = {The Foundations of Causal Inference},
  author = {Pearl, Judea},
  year = {2010},
  journal = {Sociological Methodology},
  volume = {40},
  number = {1},
  pages = {75--149},
  publisher = {{Wiley Online Library}},
  isbn = {0081-1750},
  keywords = {causal-inference,sem,statistika}
}

@article{pearlInterpretationIdentificationCausal2014,
  title = {Interpretation and {{Identification}} of {{Causal Mediation}}},
  author = {Pearl, Judea},
  year = {2014},
  journal = {Psychological Methods},
  volume = {19},
  number = {4},
  pages = {459--481},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/a0036434},
  abstract = {This article reviews the foundations of causal mediation analysis and offers a general and transparent account of the conditions necessary for the identification of natural direct and indirect effects, thus facilitating a more informed judgment of the plausibility of these conditions in specific applications. I show that the conditions usually cited in the literature are overly restrictive and can be relaxed substantially without compromising identification. In particular, I show that natural effects can be identified by methods that go beyond standard adjustment for confounders, applicable to observational studies in which treatment assignment remains confounded with the mediator or with the outcome. These identification conditions can be validated algorithmically from the diagrammatic description of one's model and are guaranteed to produce unbiased results whenever the description is correct. The identification conditions can be further relaxed in parametric models, possibly including interactions, and permit one to compare the relative importance of several pathways, mediated by interdependent variables.},
  language = {en},
  keywords = {causal-inference,statistika}
}

@article{pearlIntroductionCausalInference2010,
  title = {An {{Introduction}} to {{Causal Inference}}},
  author = {Pearl, Judea},
  year = {2010},
  month = jan,
  journal = {The International Journal of Biostatistics},
  volume = {6},
  number = {2},
  issn = {1557-4679},
  doi = {10.2202/1557-4679.1203},
  abstract = {This paper summarizes recent advances in causal inference and underscores the paradigmatic shifts that must be undertaken in moving from traditional statistical analysis to causal analysis of multivariate data. Special emphasis is placed on the assumptions that underlie all causal inferences, the languages used in formulating those assumptions, the conditional nature of all causal and counterfactual claims, and the methods that have been developed for the assessment of such claims. These advances are illustrated using a general theory of causation based on the Structural Causal Model (SCM) described in Pearl (2000a), which subsumes and unifies other approaches to causation, and provides a coherent mathematical foundation for the analysis of causes and counterfactuals. In particular, the paper surveys the development of mathematical tools for inferring (from a combination of data and assumptions) answers to three types of causal queries: those about (1) the effects of potential interventions, (2) probabilities of counterfactuals, and (3) direct and indirect effects (also known as "mediation"). Finally, the paper defines the formal and conceptual relationships between the structural and potential-outcome frameworks and presents tools for a symbiotic analysis that uses the strong features of both. The tools are demonstrated in the analyses of mediation, causes of effects, and probabilities of causation.},
  language = {en},
  keywords = {causal-inference,dag,statistika}
}

@article{pearlMediationFormulaGuide,
  title = {The {{Mediation Formula}}: {{A Guide}} to the {{Assessment}} of {{Causal Pathways}} in {{Nonlinear Models}}},
  author = {Pearl, Judea},
  pages = {39},
  language = {en},
  keywords = {causal-inference,medijacija,statistika}
}

@incollection{pereaNeighborhoodEffectsVisual2015,
  title = {Neighborhood {{Effects}} in {{Visual Word Recognition}} and {{Reading}}},
  booktitle = {The {{Oxford Handbook}} of {{Reading}}},
  author = {Perea, Manuel},
  editor = {Pollatsek, Alexander and Treiman, Rebecca},
  year = {2015},
  pages = {76--87},
  publisher = {{Oxford University Press}}
}

@article{peruginiSafeguardPowerProtection2014,
  title = {Safeguard Power as a Protection against Imprecise Power Estimates},
  author = {Perugini, Marco and Gallucci, Marcello and Costantini, Giulio},
  year = {2014},
  journal = {Perspectives on Psychological Science},
  volume = {9},
  number = {3},
  pages = {319--332},
  keywords = {metodologija,stat-power,statistika}
}

@book{petersElementsCausalInference2017,
  title = {Elements of {{Causal Inference}}: {{Foundations}} and {{Learning Algorithms}}},
  author = {Peters, Jonas and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
  year = {2017},
  publisher = {{MIT press}},
  isbn = {0-262-03731-9},
  keywords = {causal-inference,statistika}
}

@article{peti-stanticCroatianPsycholinguisticDatabase2021,
  title = {The {{Croatian}} Psycholinguistic Database: Estimates for 6000 Nouns, Verbs, Adjectives and Adverbs},
  author = {{Peti-Stanti{\'c}}, Anita and An{\dj}el, Maja and Gnjidi{\'c}, Vedrana and Kereste{\v s}, Gordana and Ljube{\v s}i{\'c}, Nikola and Masnikosa, Irina and Tonkovi{\'c}, Mirjana and Tu{\v s}ek, Jelena and {Willer-Gold}, Jana and Stanojevi{\'c}, Mateusz-Milan},
  year = {2021},
  journal = {Behavior Research Methods},
  pages = {1--18},
  publisher = {{Springer}},
  isbn = {1554-3528}
}

@article{petistanticPsiholingvistickeMjereIspitivanja2018,
  ids = {petistanticPsiholingvistickeMjereIspitivanja2018a},
  title = {{Psiholingvisti\v{c}ke mjere ispitivanja 3.000 rije\v{c}i hrvatskoga jezika: konkretnost i predo\v{c}ivost}},
  shorttitle = {{Psycholinguistic estimates of 3000 words of Croatian}},
  author = {Peti Stanti{\'c}, Anita and An{\dj}el, Maja and Kereste{\v s}, Gordana and Ljube{\v s}i{\'c}, Nikola and Stanojevi{\'c}, Mateusz-Milan and Tonkovi{\'c}, Mirjana},
  year = {2018},
  month = sep,
  journal = {Suvremena lingvistika},
  volume = {44},
  number = {85},
  pages = {91--112},
  publisher = {{Hrvatsko filolo\v{s}ko dru\v{s}tvo}},
  issn = {05860296, 1847117X},
  doi = {10.22210/suvlin.2018.085.05},
  language = {hr},
  file = {/home/denis/Zotero/storage/5YEL6MZE/203943.html}
}

@book{petzPsihologijskiRjecnik2005,
  title = {Psihologijski Rje\v{c}nik},
  author = {Petz, Boris},
  year = {2005},
  publisher = {{Naklada Slap}},
  address = {{Jastrebarsko}}
}

@article{piironenComparisonBayesianPredictive2017,
  title = {Comparison of {{Bayesian}} Predictive Methods for Model Selection},
  author = {Piironen, Juho and Vehtari, Aki},
  year = {2017},
  month = may,
  journal = {Statistics and Computing},
  volume = {27},
  number = {3},
  pages = {711--735},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-016-9649-y},
  abstract = {The goal of this paper is to compare several widely used Bayesian model selection methods in practical model selection problems, highlight their differences and give recommendations about the preferred approaches. We focus on the variable subset selection for regression and classification and perform several numerical experiments using both simulated and real world data. The results show that the optimization of a utility estimate such as the cross-validation (CV) score is liable to finding overfitted models due to relatively high variance in the utility estimates when the data is scarce. This can also lead to substantial selection induced bias and optimism in the performance evaluation for the selected model. From a predictive viewpoint, best results are obtained by accounting for model uncertainty by forming the full encompassing model, such as the Bayesian model averaging solution over the candidate models. If the encompassing model is too complex, it can be robustly simplified by the projection method, in which the information of the full model is projected onto the submodels. This approach is substantially less prone to overfitting than selection based on CV-score. Overall, the projection method appears to outperform also the maximum a posteriori model and the selection of the most probable variables. The study also demonstrates that the model selection can greatly benefit from using crossvalidation outside the searching process both for guiding the model size selection and assessing the predictive performance of the finally selected model.},
  language = {en},
  keywords = {bayes,statistika}
}

@book{pituchAppliedMultivariateStatistics2016,
  title = {Applied {{Multivariate Statistics}} for the {{Social Sciences}}: {{Analyses}} with {{SAS}} and {{IBM}}'s {{SPSS}}},
  author = {Pituch, Keenan A and Stevens, James P},
  year = {2016},
  publisher = {{Routledge}},
  address = {{New York, NY}},
  keywords = {statistika}
}

@article{poldrackFutureFMRICognitive2012,
  title = {The {{Future}} of {{fMRI}} in {{Cognitive Neuroscience}}},
  author = {Poldrack, Russell A.},
  year = {2012},
  month = aug,
  journal = {NeuroImage},
  volume = {62},
  number = {2},
  pages = {1216--1220},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2011.08.007},
  abstract = {Over the last 20 years, fMRI has revolutionized cognitive neuroscience. Here I outline a vision for what the next 20 years of fMRI in cognitive neuroscience might look like. Some developments that I hope for include increased methodological rigor, an increasing focus on connectivity and pattern analysis as opposed to ``blobology'', a greater focus on selective inference powered by open databases, and increased use of ontologies and computational models to describe underlying processes.},
  language = {en},
  keywords = {fmri,metodologija}
}

@article{popovicUntanglingDirectSpecies2019,
  title = {Untangling Direct Species Associations from Indirect Mediator Species Effects with Graphical Models},
  author = {Popovic, Gordana C. and Warton, David I. and Thomson, Fiona J. and Hui, Francis K. C. and Moles, Angela T.},
  year = {2019},
  journal = {Methods in Ecology and Evolution},
  volume = {10},
  number = {9},
  pages = {1571--1583},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.13247},
  abstract = {Ecologists often investigate co-occurrence patterns in multi-species data in order to gain insight into the ecological causes of observed co-occurrences. Apart from direct associations between the two species of interest, they may co-occur because of indirect effects, where both species respond to another variable, whether environmental or biotic (e.g. a mediator species). A wide variety of methods are now available for modelling how environmental filtering drives species distributions. In contrast, methods for studying other causes of co-occurence are much more limited. ``Graphical'' methods, which can be used to study how mediator species impact co-occurrence patterns, have recently been proposed for use in ecology. However, available methods are limited to presence/absence data or methods assuming multivariate normality, which is problematic when analysing abundances. We propose Gaussian copula graphical models (GCGMs) for studying the effect of mediator species on co-occurence patterns. GCGMs are a flexible type of graphical model which naturally accommodates all data types, for example binary (presence/absence), counts, as well as ordinal data and biomass, in a unified framework. Simulations demonstrate that GCGMs can be applied to a much broader range of data types than the methods currently used in ecology, and perform as well as or better than existing methods in many settings. We apply GCGMs to counts of hunting spiders, in order to visualise associations between species. We also analyse abundance data of New Zealand native forest cover (on an ordinal scale) to show how GCGMs can be used analyse large and complex datasets. In these data, we were able to reproduce known species relationships as well as generate new ecological hypotheses about species associations.},
  copyright = {\textcopyright{} 2019 The Authors. Methods in Ecology and Evolution \textcopyright{} 2019 British Ecological Society},
  language = {en},
  keywords = {copula,statistika},
  annotation = {\_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13247},
  file = {/home/denis/Zotero/storage/P9WNUVAZ/2041-210X.html;/home/denis/Zotero/storage/Y4BZNWZS/2041-210X.html}
}

@article{prasserFlexibleDataAnonymization2020,
  title = {Flexible Data Anonymization Using {{ARX}}\textemdash{{Current}} Status and Challenges Ahead},
  author = {Prasser, Fabian and Eicher, Johanna and Spengler, Helmut and Bild, Raffael and Kuhn, Klaus A.},
  year = {2020},
  journal = {Software: Practice and Experience},
  volume = {50},
  number = {7},
  pages = {1277--1304},
  issn = {1097-024X},
  doi = {10.1002/spe.2812},
  abstract = {The race for innovation has turned into a race for data. Rapid developments of new technologies, especially in the field of artificial intelligence, are accompanied by new ways of accessing, integrating, and analyzing sensitive personal data. Examples include financial transactions, social network activities, location traces, and medical records. As a consequence, adequate and careful privacy management has become a significant challenge. New data protection regulations, for example in the EU and China, are direct responses to these developments. Data anonymization is an important building block of data protection concepts, as it allows to reduce privacy risks by altering data. The development of anonymization tools involves significant challenges, however. For instance, the effectiveness of different anonymization techniques depends on context, and thus tools need to support a large set of methods to ensure that the usefulness of data is not overly affected by risk-reducing transformations. In spite of these requirements, existing solutions typically only support a small set of methods. In this work, we describe how we have extended an open source data anonymization tool to support almost arbitrary combinations of a wide range of techniques in a scalable manner. We then review the spectrum of methods supported and discuss their compatibility within the novel framework. The results of an extensive experimental comparison show that our approach outperforms related solutions in terms of scalability and output data quality\textemdash while supporting a much broader range of techniques. Finally, we discuss practical experiences with ARX and present remaining issues and challenges ahead.},
  language = {en},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.2812},
  file = {/home/denis/Zotero/storage/CX7SZZI3/spe.html}
}

@article{preacherSPSSSASProcedures2004,
  title = {{{SPSS}} and {{SAS}} Procedures for Estimating Indirect Effects in Simple Mediation Models},
  author = {Preacher, Kristopher J. and Hayes, Andrew F.},
  year = {2004},
  journal = {Behavior research methods, instruments, \& computers},
  volume = {36},
  number = {4},
  pages = {717--731},
  keywords = {medijacija,software,statistika}
}

@article{quintanaBayesianAlternativesCommon2018,
  title = {Bayesian Alternatives for Common Null-Hypothesis Significance Tests in Psychiatry: A Non-Technical Guide Using {{JASP}}},
  author = {Quintana, Daniel S. and Williams, Donald R.},
  year = {2018},
  journal = {BMC psychiatry},
  volume = {18},
  number = {1},
  pages = {178},
  keywords = {bayes,statistika}
}

@article{raaijmakersHowDealLanguageasfixedeffect1999,
  title = {How to Deal with ``the Language-as-Fixed-Effect Fallacy'': {{Common}} Misconceptions and Alternative Solutions},
  author = {Raaijmakers, Jeroen GW and Schrijnemakers, Joseph MC and Gremmen, Frans},
  year = {1999},
  journal = {Journal of Memory and language},
  volume = {41},
  number = {3},
  pages = {416--426},
  keywords = {metodologija,psihologija-jezika,statistika}
}

@article{raglandDichotomizingContinuousOutcome1992,
  title = {Dichotomizing {{Continuous Outcome Variables}}: {{Dependence}} of the {{Magnitude}} of {{Association}} and {{Statistical Power}} on the {{Cutpoint}}},
  author = {Ragland, David R.},
  year = {1992},
  journal = {Epidemiology},
  volume = {3},
  number = {5},
  pages = {434--440},
  keywords = {statistika}
}

@incollection{rastleVisualWordRecognition2016,
  title = {Visual {{Word Recognition}}},
  booktitle = {Neurobiology of {{Language}}},
  author = {Rastle, Kathleen},
  editor = {Hickok, G and Small, Steven L.},
  year = {2016},
  pages = {255--264},
  publisher = {{Elsevier}},
  file = {/home/denis/Zotero/storage/H9EN48YR/B9780124077942000213.html}
}

@article{ratcliffDiffusionModelAccount2004,
  title = {A {{Diffusion Model Account}} of the {{Lexical Decision Task}}},
  author = {Ratcliff, Roger and Gomez, Pablo and McKoon, Gail},
  year = {2004},
  journal = {Psychological Review},
  volume = {111},
  number = {1},
  pages = {159--182},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471(Electronic),0033-295X(Print)},
  doi = {10.1037/0033-295X.111.1.159},
  abstract = {The diffusion model for 2-choice decisions (R. Ratcliff, 1978) was applied to data from lexical decision experiments in which word frequency, proportion of high- versus low-frequency words, and type of nonword were manipulated. The model gave a good account of all of the dependent variables--accuracy, correct and error response times, and their distributions--and provided a description of how the component processes involved in the lexical decision task were affected by experimental variables. All of the variables investigated affected the rate at which information was accumulated from the stimuli--called drift rate in the model. The different drift rates observed for the various classes of stimuli can all be explained by a 2-dimens;ional signal-detection representation of stimulus information. The authors discuss how this representation and the diffusion model's decision process might be integrated with current models of lexical access. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {diffusion-model,psihologija-jezika},
  file = {/home/denis/Zotero/storage/PV5MRMZB/2004-10332-010.html}
}

@article{ratcliffTheoryMemoryRetrieval1978,
  title = {A {{Theory}} of {{Memory Retrieval}}},
  author = {Ratcliff, Roger},
  year = {1978},
  journal = {Psychological Review},
  volume = {85},
  number = {2},
  pages = {59--108},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471(Electronic),0033-295X(Print)},
  doi = {10.1037/0033-295X.85.2.59},
  abstract = {Develops a theory of memory retrieval and shows that it applies over a range of experimental paradigms. Access to memory traces is viewed in terms of a resonance metaphor. The probe item evokes the search set on the basis of probe\textendash memory item relatedness, just as a ringing tuning fork evokes sympathetic vibrations in other tuning forks. Evidence is accumulated in parallel from each probe\textendash memory item comparison, and each comparison is modeled by a continuous random walk process. In item recognition, the decision process is self-terminating on matching comparisons and exhaustive on nonmatching comparisons. The mathematical model produces predictions about accuracy, mean reaction time, error latency, and reaction time distributions that are in good accord with data from 2 experiments conducted with 6 undergraduates. The theory is applied to 4 item recognition paradigms (Sternberg, prememorized list, study\textendash test, and continuous) and to speed\textendash accuracy paradigms; results are found to provide a basis for comparison of these paradigms. It is noted that neural network models can be interfaced to the retrieval theory with little difficulty and that semantic memory models may benefit from such a retrieval scheme. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {diffusion-model},
  file = {/home/denis/Zotero/storage/T3HP6KK2/1978-30970-001.html}
}

@book{raykovIntroductionAppliedMultivariate2008,
  title = {An Introduction to Applied Multivariate Analysis},
  author = {Raykov, Tenko and Marcoulides, George A.},
  year = {2008},
  publisher = {{Routledge}},
  isbn = {1-136-67600-7},
  keywords = {multivariate,statistika}
}

@incollection{raynerEyemovementControlReading2006,
  title = {Eye-Movement {{Control}} in {{Reading}}},
  booktitle = {Handbook of {{Psycholinguistics}}},
  author = {Rayner, Keith and Pollatsek, Alexander},
  editor = {Traxler, Matthew J. and Gernsbacher, Morton Ann},
  year = {2006},
  pages = {613--657},
  publisher = {{Elsevier}}
}

@article{raynerLexicalComplexityFixation1986,
  title = {Lexical {{Complexity}} and {{Fixation Times}} in {{Reading}}: {{Effects}} of {{Word Frequency}}, {{Verb Complexity}}, and {{Lexical Ambiguity}}},
  shorttitle = {Lexical Complexity and Fixation Times in Reading},
  author = {Rayner, Keith and Duffy, Susan A.},
  year = {1986},
  month = may,
  journal = {Memory \& Cognition},
  volume = {14},
  number = {3},
  pages = {191--201},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/BF03197692},
  language = {en},
  keywords = {psihologija-jezika}
}

@book{rcoreteamLanguageEnvironmentStatistical2018,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  author = {{R Core Team}},
  year = {2018},
  publisher = {{R Foundation for Statistical Computing}},
  address = {{Vienna, Austria}},
  keywords = {software}
}

@article{reberImplicitLearningArtificial1967,
  title = {Implicit Learning of Artificial Grammars},
  author = {Reber, Arthur S.},
  year = {1967},
  journal = {Journal of verbal learning and verbal behavior},
  volume = {6},
  number = {6},
  pages = {855--863}
}

@book{reComputeEsCompute2013,
  title = {Compute.Es: {{Compute Effect Sizes}}},
  author = {Re, A. C. Del},
  year = {2013}
}

@article{redickMeasuringWorkingMemory2012,
  title = {Measuring Working Memory Capacity with Automated Complex Span Tasks},
  author = {Redick, Thomas S. and Broadway, James M. and Meier, Matt E. and Kuriakose, Princy S. and Unsworth, Nash and Kane, Michael J. and Engle, Randall W.},
  year = {2012},
  journal = {European Journal of Psychological Assessment},
  volume = {28},
  pages = {164--171},
  doi = {10.1027/1015-5759/a000123},
  keywords = {complex-span-test}
}

@article{regenwetterConstructBehaviorGap2017,
  title = {The Construct\textendash Behavior Gap in Behavioral Decision Research: {{A}} Challenge beyond Replicability},
  shorttitle = {The Construct\textendash Behavior Gap in Behavioral Decision Research},
  author = {Regenwetter, Michel and Robinson, Maria M.},
  year = {2017},
  journal = {Psychological Review},
  volume = {124},
  number = {5},
  pages = {533--550},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471(Electronic),0033-295X(Print)},
  doi = {10.1037/rev0000067},
  abstract = {Behavioral decision research compares theoretical constructs like preferences to behavior such as observed choices. Three fairly common links from constructs to behavior are (1) to tally, across participants and decision problems, the number of choices consistent with one predicted pattern of pairwise preferences; (2) to compare what most people choose in each decision problem against a predicted preference pattern; or (3) to enumerate the decision problems in which two experimental conditions generate a 1-sided significant difference in choice frequency `consistent' with the theory. Although simple, these theoretical links are heuristics. They are subject to well-known reasoning fallacies, most notably the fallacy of sweeping generalization and the fallacy of composition. No amount of replication can alleviate these fallacies. On the contrary, reiterating logically inconsistent theoretical reasoning over and again across studies obfuscates science. As a case in point, we consider pairwise choices among simple lotteries and the hypotheses of overweighting or underweighting of small probabilities, as well as the description\textendash experience gap. We discuss ways to avoid reasoning fallacies in bridging the conceptual gap between hypothetical constructs, such as, for example, ``overweighting'' to observable pairwise choice data. Although replication is invaluable, successful replication of hard-to-interpret results is not. Behavioral decision research stands to gain much theoretical and empirical clarity by spelling out precise and formally explicit theories of how hypothetical constructs translate into observable behavior. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
  file = {/home/denis/Zotero/storage/HUF7A4RC/2017-21388-001.html}
}

@book{revellePsychProceduresPsychological2018,
  title = {Psych: {{Procedures}} for {{Psychological}}, {{Psychometric}}, and {{Personality Research}}},
  author = {Revelle, William},
  year = {2018},
  publisher = {{Northwestern University}},
  address = {{Evanston, Illinois}}
}

@article{richardsModelSelectionModel2011,
  title = {Model Selection and Model Averaging in Behavioural Ecology: The Utility of the {{IT}}-{{AIC}} Framework},
  shorttitle = {Model Selection and Model Averaging in Behavioural Ecology},
  author = {Richards, Shane A. and Whittingham, Mark J. and Stephens, Philip A.},
  year = {2011},
  month = jan,
  journal = {Behavioral Ecology and Sociobiology},
  volume = {65},
  number = {1},
  pages = {77--89},
  issn = {0340-5443, 1432-0762},
  doi = {10.1007/s00265-010-1035-8},
  language = {en},
  keywords = {multi-model-inference,statistika}
}

@article{rileyMinimumSampleSize2019,
  title = {Minimum {{Sample Size}} for {{Developing}} a {{Multivariable Prediction Model}}: {{Part I}} - {{Continuous Outcomes}}},
  shorttitle = {Minimum Sample Size for Developing a Multivariable Prediction Model},
  author = {Riley, Richard D. and Snell, Kym I.E. and Ensor, Joie and Burke, Danielle L. and Harrell, Frank E. and Moons, Karel G.M. and Collins, Gary S.},
  year = {2019},
  month = mar,
  journal = {Statistics in Medicine},
  volume = {38},
  number = {7},
  pages = {1262--1275},
  issn = {02776715},
  doi = {10.1002/sim.7993},
  language = {en},
  keywords = {statistika}
}

@article{rileyMinimumSampleSize2019a,
  title = {Minimum {{Sample Size}} for {{Developing}} a {{Multivariable Prediction Model}}: {{Part II}} - {{Binary}} and {{Time}}-to-{{Event Outcomes}}},
  shorttitle = {Minimum Sample Size for Developing a Multivariable Prediction Model},
  author = {Riley, Richard D and Snell, Kym IE and Ensor, Joie and Burke, Danielle L and Harrell Jr, Frank E and Moons, Karel GM and Collins, Gary S},
  year = {2019},
  month = mar,
  journal = {Statistics in Medicine},
  volume = {38},
  number = {7},
  pages = {1276--1296},
  issn = {02776715},
  doi = {10.1002/sim.7992},
  language = {en},
  keywords = {statistika}
}

@book{robertj.grissomEffectSizesResearch2005,
  title = {Effect {{Sizes}} for {{Research}}: {{A Broad Practical Approach}}},
  author = {Robert J. Grissom, John J. Kim},
  year = {2005},
  edition = {First},
  publisher = {{Routledge Academic}},
  isbn = {0-8058-5014-7 978-0-8058-5014-7},
  keywords = {effect-size,statistika}
}

@techreport{robinaughInvisibleHandsFine2020,
  type = {Preprint},
  title = {Invisible {{Hands}} and {{Fine Calipers}}: {{A Call}} to {{Use Formal Theory}} as a {{Toolkit}} for {{Theory Construction}}},
  shorttitle = {Invisible {{Hands}} and {{Fine Calipers}}},
  author = {Robinaugh, Donald and Haslbeck, Jonas M B and Ryan, Ois{\'i}n and Fried, Eiko I and Waldorp, Lourens},
  year = {2020},
  month = mar,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/ugz7y},
  abstract = {In recent years, a growing chorus of researchers have argued that psychological theory is in a state of crisis: theories are rarely developed in a way that indicates an accumulation of knowledge and they are often absent from our research entirely. More than 40 years ago, Paul Meehl raised these very concerns. Yet, in the ensuing decades, little has improved. We aim to chart a better path forward for psychological theory by revisiting Meehl's criticisms, his proposed solution, and the reasons his solution failed to meaningful change the status of psychological theory. We argue that Meehl identified serious shortcomings in our evaluation of psychological theories and that his proposed solution would substantially strengthen theory testing. However, we also argue that he failed to provide researchers a set of tools for theory construction. To advance psychological theory, we must equip researchers with tools to better generate, evaluate, and develop their theories. We argue that formal theories provide this much needed set of tools, equipping researchers with tools for thinking, evaluating explanation, informing theory development, strengthening measurement, and moving toward collaborative construction of psychological theories that allow us to explain, predict, and control psychological phenomena.},
  language = {en},
  keywords = {metodologija}
}

@techreport{roccaPuttingPsychologyTest2020,
  title = {Putting Psychology to the Test: {{Rethinking}} Model Evaluation through Benchmarking and Prediction},
  shorttitle = {Putting Psychology to the Test},
  author = {Rocca, Roberta and Yarkoni, Tal},
  year = {2020},
  month = nov,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/e437b},
  abstract = {Consensus on standards for evaluating models and theories is an integral part of every science. Nonetheless, in psychology, relatively little focus has been placed on defining reliable communal metrics to assess model performance. Evaluation practices are often idiosyncratic, and are affected by a number of shortcomings (e.g., failure to assess models' ability to generalize to unseen data) that make it difficult to discriminate between good and bad models. Drawing inspiration from fields like machine learning and statistical genetics, we argue in favor of introducing common benchmarks as a means of overcoming the lack of reliable model evaluation criteria currently observed in psychology. We discuss a number of principles benchmarks should satisfy to achieve maximal utility; identify concrete steps the community could take to promote the development of such benchmarks; and address a number of potential pitfalls and concerns that may arise in the course of implementation. We argue that reaching consensus on common evaluation benchmarks will foster cumulative progress in psychology, and encourage researchers to place heavier emphasis on the practical utility of scientific models.},
  keywords = {statistika}
}

@article{rohrerProbingBirthorderEffects2017,
  title = {Probing Birth-Order Effects on Narrow Traits Using Specification-Curve Analysis},
  author = {Rohrer, Julia M. and Egloff, Boris and Schmukle, Stefan C.},
  year = {2017},
  journal = {Psychological Science},
  volume = {28},
  number = {12},
  pages = {1821--1832},
  keywords = {metodologija,specification-curve,statistika},
  file = {/home/denis/Zotero/storage/UJJ25N7X/0956797617723726.html}
}

@article{rouderFlankerNegativeFlanker2003,
  title = {Flanker and Negative Flanker Effects in Letter Identification},
  author = {Rouder, Jeffrey N. and King, Jonathan W.},
  year = {2003},
  journal = {Perception \& Psychophysics},
  volume = {65},
  number = {2},
  pages = {287--297},
  keywords = {flanker-task}
}

@article{rouderPowerDominanceConstraint,
  title = {Power, {{Dominance}}, and {{Constraint}}: {{A Note}} on the {{Appeal}} of {{Different Design Traditions}}},
  author = {Rouder, Jeffrey N and Haaf, Julia M},
  pages = {8},
  abstract = {The recent field-wide emphasis on power has brought the number of participants used in psychological experiments into focus. Social psychology typically follows a tradition in which many participants perform a small number of trials each; in psychophysics, the tradition is to include only a few participants, who perform many trials each; and the tradition in cognitive psychology falls in between, balancing the number of participants and trials. We ask whether it is better to add trials or to add participants if one wishes to increase power. The answer is straightforward\textemdash greatest power is achieved by using more people, and the gain from adding people is greater than the gain from adding trials. In light of these results, the design parameters in the social psychology tradition seem ideal. Yet there are conditions in which one may trade people for trials with only a minor decrement in power. Under these conditions, the limiting factor is the trial-to-trial variability rather than the variability across people in the population. These conditions are highly plausible, and we present a theoretical argument as to why. We think that most cognitive effects are characterized by stochastic dominance; that is, everyone's true effect is in the same direction. For example, it is plausible that when performing the Stroop task, all people truly identify congruent colors faster than incongruent ones. When dominance holds, small mean effects imply a small degree of variability across the population. It is this degree of homogeneity, the consequence of dominance, that licenses the design parameters of the cognitive psychology and psychophysics traditions.},
  language = {en},
  keywords = {metodologija,stat-power,statistika}
}

@article{rouderPsychometricsIndividualDifferences2019,
  ids = {rouderPsychometricsIndividualDifferences2019a},
  title = {A Psychometrics of Individual Differences in Experimental Tasks},
  author = {Rouder, Jeffrey N. and Haaf, Julia M.},
  year = {2019},
  month = apr,
  journal = {Psychonomic Bulletin \& Review},
  volume = {26},
  number = {2},
  pages = {452--467},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-018-1558-y},
  abstract = {In modern individual-difference studies, researchers often correlate performance on various tasks to uncover common latent processes. Yet, in some sense, the results have been disappointing as correlations among tasks that seemingly have processes in common are often low. A pressing question then is whether these attenuated correlations reflect statistical considerations, such as a lack of individual variability on tasks, or substantive considerations, such as that inhibition in different tasks is not a unified concept. One problem in addressing this question is that researchers aggregate performance across trials to tally individual-by-task scores. It is tempting to think that aggregation is fine and that everything comes out in the wash. But as shown here, this aggregation may greatly attenuate measures of effect size and correlation. We propose an alternative analysis of task performance that is based on accounting for trial-by-trial variability along with the covariation of individuals' performance across tasks. The implementation is through common hierarchical models, and this treatment rescues classical concepts of effect size, reliability, and correlation for studying individual differences with experimental tasks. Using recent data from Hedge et al. Behavioral Research Methods, 50(3), 1166\textendash 1186, 2018 we show that there is Bayes-factor support for a lack of correlation between the Stroop and flanker task. This support for a lack of correlation indicates a psychologically relevant result\textemdash Stroop and flanker inhibition are seemingly unrelated, contradicting unified concepts of inhibition.},
  language = {en},
  keywords = {metodologija,statistika}
}

@article{rousseletReactionTimesOther2020,
  title = {Reaction {{Times}} and Other {{Skewed Distributions}}},
  shorttitle = {Reaction {{Times}} and Other {{Skewed Distributions}}},
  author = {Rousselet, Guillaume A. and Wilcox, Rand R.},
  year = {2020},
  month = may,
  journal = {Meta-Psychology},
  volume = {4},
  issn = {2003-2714},
  doi = {10.15626/MP.2019.1630},
  abstract = {To summarise skewed (asymmetric) distributions, such as reaction times, typically the mean or the median are used as measures of central tendency. Using the mean might seem surprising, given that it provides a poor measure of central tendency for skewed distributions, whereas the median provides a better indication of the location of the bulk of the observations. However, the sample median is biased: with small sample sizes, it tends to overestimate the population median. This is not the case for the mean. Based on this observation, Miller (1988) concluded that "sample medians must not be used to compare reaction times across experimental conditions when there are unequal numbers of trials in the conditions". Here we replicate and extend Miller (1988), and demonstrate that his conclusion was ill-advised for several reasons. First, the median's bias can be corrected using a percentile bootstrap bias correction. Second, a careful examination of the sampling distributions reveals that the sample median is median unbiased, whereas the mean is median biased when dealing with skewed distributions. That is, on average the sample mean estimates the population mean, but typically this is not the case. In addition, simulations of false and true positives in various situations show that no method dominates. Crucially, neither the mean nor the median are sufficient or even necessary to compare skewed distributions. Different questions require different methods and it would be unwise to use the mean or the median in all situations. Better tools are available to get a deeper understanding of how distributions differ: we illustrate the hierarchical shift function, a powerful alternative that relies on quantile estimation. All the code and data to reproduce the figures and analyses in the article are available online.},
  copyright = {Copyright (c) 2020 Guillaume A Rousselet, Rand R Wilcox},
  language = {en},
  keywords = {metodologija,statistika},
  file = {/home/denis/Zotero/storage/PH5R3WP5/1630.html}
}

@article{rubinCausalInferenceUsing2005,
  title = {Causal {{Inference Using Potential Outcomes}}: {{Design}}, {{Modeling}}, {{Decisions}}},
  shorttitle = {Causal {{Inference Using Potential Outcomes}}},
  author = {Rubin, Donald B},
  year = {2005},
  month = mar,
  journal = {Journal of the American Statistical Association},
  volume = {100},
  number = {469},
  pages = {322--331},
  issn = {0162-1459, 1537-274X},
  doi = {10.1198/016214504000001880},
  language = {en},
  keywords = {causal-inference,statistika}
}

@article{rubinPvaluesLoseTheir2017,
  title = {Do P-Values {{Lose Their Meaning}} in {{Exploratory Analyses}}? {{It Depends How You Define}} the {{Familywise Error Rate}}},
  shorttitle = {Do {\emph{p}} {{Values Lose Their Meaning}} in {{Exploratory Analyses}}?},
  author = {Rubin, Mark},
  year = {2017},
  month = sep,
  journal = {Review of General Psychology},
  volume = {21},
  number = {3},
  pages = {269--275},
  issn = {1089-2680, 1939-1552},
  doi = {10.1037/gpr0000123},
  abstract = {Several researchers have recently argued that p values lose their meaning in exploratory analyses due to an unknown inflation of the alpha level (e.g., Nosek \& Lakens, 2014; Wagenmakers, 2016). For this argument to be tenable, the familywise error rate must be defined in relation to the number of hypotheses that are tested in the same study or article. Under this conceptualization, the familywise error rate is usually unknowable in exploratory analyses because it is usually unclear how many hypotheses have been tested on a spontaneous basis and then omitted from the final research report. In the present article, I argue that it is inappropriate to conceptualize the familywise error rate in relation to the number of hypotheses that are tested. Instead, it is more appropriate to conceptualize familywise error in relation to the number of different tests that are conducted on the same null hypothesis in the same study. Under this conceptualization, alpha-level adjustments in exploratory analyses are (a) less necessary and (b) objectively verifiable. As a result, p values do not lose their meaning in exploratory analyses.},
  language = {en},
  keywords = {filozofija-znanosti,statistika}
}

@article{saffranStatisticalLanguageLearning2003,
  title = {Statistical Language Learning: {{Mechanisms}} and Constraints},
  author = {Saffran, Jenny R.},
  year = {2003},
  journal = {Current directions in psychological science},
  volume = {12},
  number = {4},
  pages = {110--114}
}

@book{salkindEncyclopediaMeasurementStatistics2007,
  title = {Encyclopedia of {{Measurement}} and {{Statistics}}},
  author = {Salkind, Neil J},
  year = {2007},
  publisher = {{Sage}},
  address = {{Thousand Oaks, CA}},
  keywords = {statistika}
}

@article{sandersEriksenFlankerEffect2002,
  title = {The {{Eriksen}} Flanker Effect Revisited},
  author = {Sanders, A. F. and Lamers, J. M.},
  year = {2002},
  journal = {Acta Psychologica},
  volume = {109},
  number = {1},
  pages = {41--56},
  keywords = {flanker-task}
}

@article{schadPrincipledBayesianWorkflow2020,
  title = {Toward a Principled {{Bayesian}} Workflow in Cognitive Science},
  author = {Schad, Daniel J. and Betancourt, Michael and Vasishth, Shravan},
  year = {2020},
  month = feb,
  journal = {arXiv:1904.12765 [stat]},
  eprint = {1904.12765},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Experiments in research on memory, language, and in other areas of cognitive science are increasingly being analyzed using Bayesian methods. This has been facilitated by the development of probabilistic programming languages such as Stan, and easily accessible front-end packages such as brms. The utility of Bayesian methods, however, ultimately depends on the relevance of the Bayesian model, in particular whether or not it accurately captures the structure of the data and the data analyst's domain expertise. Even with powerful software, the analyst is responsible for verifying the utility of their model. To demonstrate this point, we introduce a principled Bayesian workflow (Betancourt, 2018) to cognitive science. Using a concrete working example, we describe basic questions one should ask about the model: prior predictive checks, computational faithfulness, model sensitivity, and posterior predictive checks. The running example for demonstrating the workflow is data on reading times with a linguistic manipulation of object versus subject relative clause sentences. This principled Bayesian workflow also demonstrates how to use domain knowledge to inform prior distributions. It provides guidelines and checks for valid data analysis, avoiding overfitting complex models to noise, and capturing relevant data structure in a probabilistic model. Given the increasing use of Bayesian methods, we aim to discuss how these methods can be properly employed to obtain robust answers to scientific questions. All data and code accompanying this paper are available from https://osf.io/b2vx9/.},
  archiveprefix = {arXiv},
  keywords = {statistika},
  file = {/home/denis/Zotero/storage/8G3N38YV/1904.html}
}

@article{schielzethSimpleMeansImprove2010,
  title = {Simple Means to Improve the Interpretability of Regression Coefficients},
  author = {Schielzeth, Holger},
  year = {2010},
  journal = {Methods in Ecology and Evolution},
  volume = {1},
  number = {2},
  pages = {103--113},
  issn = {2041-210X},
  doi = {10.1111/j.2041-210X.2010.00012.x},
  abstract = {1. Linear regression models are an important statistical tool in evolutionary and ecological studies. Unfortunately, these models often yield some uninterpretable estimates and hypothesis tests, especially when models contain interactions or polynomial terms. Furthermore, the standard errors for treatment groups, although often of interest for including in a publication, are not directly available in a standard linear model. 2. Centring and standardization of input variables are simple means to improve the interpretability of regression coefficients. Further, refitting the model with a slightly modified model structure allows extracting the appropriate standard errors for treatment groups directly from the model. 3. Centring will make main effects biologically interpretable even when involved in interactions and thus avoids the potential misinterpretation of main effects. This also applies to the estimation of linear effects in the presence of polynomials. Categorical input variables can also be centred and this sometimes assists interpretation. 4. Standardization (z-transformation) of input variables results in the estimation of standardized slopes or standardized partial regression coefficients. Standardized slopes are comparable in magnitude within models as well as between studies. They have some advantages over partial correlation coefficients and are often the more interesting standardized effect size. 5. The thoughtful removal of intercepts or main effects allows extracting treatment means or treatment slopes and their appropriate standard errors directly from a linear model. This provides a simple alternative to the more complicated calculation of standard errors from contrasts and main effects. 6. The simple methods presented here put the focus on parameter estimation (point estimates as well as confidence intervals) rather than on significance thresholds. They allow fitting complex, but meaningful models that can be concisely presented and interpreted. The presented methods can also be applied to generalised linear models (GLM) and linear mixed models.},
  copyright = {\textcopyright{} 2010 The Author. Journal compilation \textcopyright{} 2010 British Ecological Society},
  language = {en},
  keywords = {statistika}
}

@article{schonbrodtWhatSampleSize2013,
  title = {At What Sample Size Do Correlations Stabilize?},
  author = {Sch{\"o}nbrodt, Felix D. and Perugini, Marco},
  year = {2013},
  journal = {Journal of Research in Personality},
  volume = {47},
  number = {5},
  pages = {609--612},
  keywords = {metodologija,statistika}
}

@article{schotterParafovealProcessingReading2012,
  title = {Parafoveal Processing in Reading},
  author = {Schotter, Elizabeth R. and Angele, Bernhard and Rayner, Keith},
  year = {2012},
  journal = {Attention, Perception, \& Psychophysics},
  volume = {74},
  number = {1},
  pages = {5--35}
}

@article{sellkeCalibrationValuesTesting2001,
  title = {Calibration of {$\rho$} Values for Testing Precise Null Hypotheses},
  author = {Sellke, Thomas and Bayarri, M. J. and Berger, James O.},
  year = {2001},
  journal = {The American Statistician},
  volume = {55},
  number = {1},
  pages = {62--71},
  keywords = {metodologija,p-vrijednosti,statistika}
}

@article{sennCovariateImbalanceRandom1989,
  title = {Covariate Imbalance and Random Allocation in Clinical Trials},
  author = {Senn, S. J.},
  year = {1989},
  month = apr,
  journal = {Statistics in Medicine},
  volume = {8},
  number = {4},
  pages = {467--475},
  issn = {02776715, 10970258},
  doi = {10.1002/sim.4780080410},
  abstract = {A model is developed to estimate the effect of covariateimbalance on the size of a test of treatment efficacy in randomized clinical trials comparing two treatments when dispersion parameters are known. It is concluded that tests of homogeneityon the covariates shouldnot be performed,that covariate imbalance isjust as much a problem for large studies as for small ones in terms of effect on size, and that the effect of correlation between covariatesand measures of efficacy is more complex than has previously been sugested. The best way to adjust for covariate imbalance is by an analysis of covariance.},
  language = {en},
  keywords = {metodologija,statistika}
}

@article{sennSevenMythsRandomisation2013,
  title = {Seven Myths of Randomisation in Clinical Trials},
  author = {Senn, Stephen},
  year = {2013},
  month = apr,
  journal = {Statistics in Medicine},
  volume = {32},
  number = {9},
  pages = {1439--1450},
  issn = {02776715},
  doi = {10.1002/sim.5713},
  language = {en},
  keywords = {metodologija,statistika}
}

@incollection{shanksdavidr.ImplicitLearning2005,
  title = {Implicit {{Learning}}},
  booktitle = {Handbook of {{Cognition}}},
  author = {Shanks, David R.},
  editor = {Lamberts, K. and Goldstone, R.},
  year = {2005},
  pages = {202--220},
  publisher = {{SAGE Publications}},
  address = {{Tho}},
  isbn = {978-1-84787-136-7}
}

@article{shipleyGeneralizedAICChi2020,
  title = {Generalized {{AIC}} and {{Chi}}-squared {{Statistics}} for {{Path Models Consistent With Directed Acyclic Graphs}}},
  author = {Shipley, Bill and Douma, Jacob C.},
  year = {2020},
  month = mar,
  journal = {Ecology},
  volume = {101},
  number = {3},
  issn = {0012-9658, 1939-9170},
  doi = {10.1002/ecy.2960},
  abstract = {We explain how to obtain a generalized maximum-likelihood chi-square statistic,XM2 L, and a full-model Akaike Information Criterion (AIC) statistic for piecewise structural equation modeling (SEM); that is, structural equations without latent variables whose causal topology can be represented as a directed acyclic graph (DAG). The full piecewise SEM is decomposed into submodels as a Markov network, each of which can have different distributional assumptions or functional links and that can be modeled by any method that produces maximum-likelihood parameter estimates. The generalized XM2 L is a function of the difference in the maximum likelihoods of the model and its saturated equivalent and the full-model AIC is calculated by summing the AIC statistics of each of the submodels.},
  language = {en},
  keywords = {sem,statistika}
}

@article{silberzahnManyAnalystsOne2018,
  title = {Many {{Analysts}}, {{One Data Set}}: {{Making Transparent How Variations}} in {{Analytic Choices Affect Results}}},
  shorttitle = {Many {{Analysts}}, {{One Data Set}}},
  author = {Silberzahn, R. and Uhlmann, E. L. and Martin, D. P. and Anselmi, P. and Aust, F. and Awtrey, E. and Bahn{\'i}k, {\v S}. and Bai, F. and Bannard, C. and Bonnier, E. and Carlsson, R. and Cheung, F. and Christensen, G. and Clay, R. and Craig, M. A. and Dalla Rosa, A. and Dam, L. and Evans, M. H. and Flores Cervantes, I. and Fong, N. and {Gamez-Djokic}, M. and Glenz, A. and {Gordon-McKeon}, S. and Heaton, T. J. and Hederos, K. and Heene, M. and Hofelich Mohr, A. J. and H{\"o}gden, F. and Hui, K. and Johannesson, M. and Kalodimos, J. and Kaszubowski, E. and Kennedy, D. M. and Lei, R. and Lindsay, T. A. and Liverani, S. and Madan, C. R. and Molden, D. and Molleman, E. and Morey, R. D. and Mulder, L. B. and Nijstad, B. R. and Pope, N. G. and Pope, B. and Prenoveau, J. M. and Rink, F. and Robusto, E. and Roderique, H. and Sandberg, A. and Schl{\"u}ter, E. and Sch{\"o}nbrodt, F. D. and Sherman, M. F. and Sommer, S. A. and Sotak, K. and Spain, S. and Sp{\"o}rlein, C. and Stafford, T. and Stefanutti, L. and Tauber, S. and Ullrich, J. and Vianello, M. and Wagenmakers, E.-J. and Witkowiak, M. and Yoon, S. and Nosek, B. A.},
  year = {2018},
  month = sep,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {1},
  number = {3},
  pages = {337--356},
  issn = {2515-2459, 2515-2467},
  doi = {10.1177/2515245917747646},
  abstract = {Twenty-nine teams involving 61 analysts used the same data set to address the same research question: whether soccer referees are more likely to give red cards to dark-skin-toned players than to light-skin-toned players. Analytic approaches varied widely across the teams, and the estimated effect sizes ranged from 0.89 to 2.93 (Mdn = 1.31) in odds-ratio units. Twenty teams (69\%) found a statistically significant positive effect, and 9 teams (31\%) did not observe a significant relationship. Overall, the 29 different analyses used 21 unique combinations of covariates. Neither analysts' prior beliefs about the effect of interest nor their level of expertise readily explained the variation in the outcomes of the analyses. Peer ratings of the quality of the analyses also did not account for the variability. These findings suggest that significant variation in the results of analyses of complex data may be difficult to avoid, even by experts with honest intentions. Crowdsourcing data analysis, a strategy in which numerous research teams are recruited to simultaneously investigate the same research question, makes transparent how defensible, yet subjective, analytic choices influence research results.},
  language = {en}
}

@article{simmonsPowerPosingPcurving2017,
  title = {Power Posing: {{P}}-Curving the Evidence},
  author = {Simmons, Joseph P. and Simonsohn, Uri},
  year = {2017},
  journal = {Psychological science},
  volume = {28},
  number = {5},
  pages = {687--693},
  keywords = {metodologija}
}

@article{simonsohnBetterPcurvesMaking2015,
  title = {Better {{P}}-Curves: {{Making P}}-Curve Analysis More Robust to Errors, Fraud, and Ambitious {{P}}-Hacking, a {{Reply}} to {{Ulrich}} and {{Miller}} (2015).},
  author = {Simonsohn, Uri and Simmons, Joseph P. and Nelson, Leif D.},
  year = {2015},
  keywords = {meta-analiza,metodologija,statistika}
}

@article{simonsohnPcurveEffectSize2014,
  title = {P-Curve and Effect Size: {{Correcting}} for Publication Bias Using Only Significant Results},
  author = {Simonsohn, Uri and Nelson, Leif D. and Simmons, Joseph P.},
  year = {2014},
  journal = {Perspectives on Psychological Science},
  volume = {9},
  number = {6},
  pages = {666--681},
  keywords = {meta-analiza,metodologija,statistika}
}

@article{simonsohnPcurveKeyFiledrawer2014,
  title = {P-Curve: A Key to the File-Drawer.},
  author = {Simonsohn, Uri and Nelson, Leif D. and Simmons, Joseph P.},
  year = {2014},
  journal = {Journal of Experimental Psychology: General},
  volume = {143},
  number = {2},
  pages = {534--547},
  keywords = {meta-analiza,metodologija,statistika}
}

@article{simonsohnSpecificationCurveDescriptive2015,
  title = {Specification Curve: {{Descriptive}} and Inferential Statistics on All Reasonable Specifications},
  shorttitle = {Specification Curve},
  author = {Simonsohn, Uri and Simmons, Joseph P. and Nelson, Leif D.},
  year = {2015},
  journal = {Available at SSRN 2694998},
  keywords = {metodologija,specification-curve,statistika},
  file = {/home/denis/Zotero/storage/78RX64AY/papers.html}
}

@book{slowikowskiGgrepelAutomaticallyPosition2018,
  title = {Ggrepel: {{Automatically Position Non}}-{{Overlapping Text Labels}} with 'Ggplot2'},
  author = {Slowikowski, Kamil},
  year = {2018}
}

@article{smaldinoHowTranslateVerbal,
  title = {How to {{Translate}} a {{Verbal Theory}} into a {{Formal Model}}},
  author = {Smaldino, Paul E},
  pages = {19},
  abstract = {Turning verbal theories into formal models is an essential business of a mature science. Here I elaborate on taxonomies of models, provide ten lessons for translating a verbal 3 theory into a formal model, and discuss the specific challenges involved in collaborations between modelers and non-modelers. It's a start.},
  language = {en},
  keywords = {metodologija}
}

@article{smaleReviewHistoryAdvocacy1970,
  title = {A {{Review}} of the {{History}}, {{Advocacy}} and {{Efficacy}} of {{Data Management Plans}}},
  author = {Smale, Nicholas Andrew and Unsworth, Kathryn and Denyer, Gareth and Magatova, Elise and Barr, Daniel},
  year = {1970},
  month = jan,
  journal = {International Journal of Digital Curation},
  volume = {15},
  number = {1},
  pages = {30},
  issn = {1746-8256},
  doi = {10.2218/ijdc.v15i1.525},
  abstract = {Data management plans (DMPs) have increasingly been encouraged as a key component of institutional and funding body policy. Although DMPs necessarily place administrative burden on researchers, proponents claim that DMPs have myriad benefits, including enhanced research data quality, increased rates of data sharing, and institutional planning and compliance benefits. In this article, we explore the international history of DMPs and describe institutional and funding body DMP policy. We find that economic and societal benefits from presumed increased rates of data sharing was the original driver of mandating DMPs by funding bodies. Today, 86\% of UK Research Councils and 63\% of US funding bodies require submission of a DMP with funding applications. Given that no major Australian funding bodies require DMP submission, it is of note that 37\% of Australian universities have taken the initiative to internally mandate DMPs. Institutions both within Australia and internationally frequently promote the professional benefits of DMP use, and endorse DMPs as `best practice'. We analyse one such typical DMP implementation at a major Australian institution, finding that DMPs have low levels of apparent translational value. Indeed, an extensive literature review suggests there is very limited published systematic evidence that DMP use has any tangible benefit for researchers, institutions or funding bodies. We are therefore led to question why DMPs have become the go-to tool for research data professionals and advocates of good data practice. By delineating multiple use-cases and highlighting the need for DMPs to be fit for intended purpose, we question the view that a good DMP is necessarily that which encompasses the entire data lifecycle of a project. Finally, we summarise recent developments in the DMP landscape, and note a positive shift towards evidence-based research management through more researcher-centric, educative, and integrated DMP services.},
  copyright = {Copyright (c) 2020 International Journal of Digital Curation},
  language = {en},
  keywords = {meta-science},
  file = {/home/denis/Zotero/storage/3F62CJJH/525.html}
}

@article{smithsonCorrectConfidenceIntervals2001,
  title = {Correct Confidence Intervals for Various Regression Effect Sizes and Parameters: {{The}} Importance of Noncentral Distributions in Computing Intervals},
  author = {Smithson, Michael},
  year = {2001},
  journal = {Educational and psychological measurement},
  volume = {61},
  number = {4},
  pages = {605--632},
  keywords = {effect-size,statistika}
}

@article{snellIntegrationParafovealOrthographic2017,
  title = {Integration of Parafoveal Orthographic Information during Foveal Word Reading: Beyond the Sub-Lexical Level?},
  author = {Snell, Joshua and Vitu, Fran{\c c}oise and Grainger, Jonathan},
  year = {2017},
  journal = {The Quarterly Journal of Experimental Psychology},
  volume = {70},
  number = {10},
  pages = {1984--1996},
  keywords = {flanker-task}
}

@article{snellParallelWordProcessing2018,
  title = {Parallel Word Processing in the Flanker Paradigm Has a Rightward Bias},
  author = {Snell, Joshua and Grainger, Jonathan},
  year = {2018},
  journal = {Attention, Perception, \& Psychophysics},
  pages = {1--8},
  keywords = {flanker-task}
}

@article{sobczak2019implicit,
  title = {Implicit versus Explicit Mechanisms of Vocabulary Learning and Consolidation},
  author = {Sobczak, Justyna M and Gaskell, M Gareth},
  year = {2019},
  journal = {Journal of Memory and Language},
  volume = {106},
  pages = {1--17},
  publisher = {{Elsevier}},
  keywords = {psihologija-jezika,word-exposure}
}

@article{spiegelhalterBayesianApproachesRandomized1994,
  title = {Bayesian {{Approaches}} to {{Randomized Trials}}},
  author = {Spiegelhalter, David J. and Freedman, Laurence S. and Parmar, Mahesh K. B.},
  year = {1994},
  journal = {Journal of the Royal Statistical Society. Series A (Statistics in Society)},
  volume = {157},
  number = {3},
  pages = {357},
  issn = {09641998},
  doi = {10.2307/2983527},
  abstract = {Statistical issues in conducting randomized trials include the choice of a sample size, whether to stop a trial early and the appropriate analysis and interpretation of the trial results. At each of these stages, evidence external to the trial is useful, but generally such evidence is introduced in an unstructured and informal manner. We argue that a Bayesian approach allows a formal basis for using external evidence and in addition provides a rational way for dealing with issues such as the ethics of randomization, trials to show treatment equivalence, the monitoring of accumulating data and the prediction of the consequences of continuing a study. The motivation for using this methodology is practical rather than ideological.},
  language = {en},
  keywords = {bayes,metodologija,statistika}
}

@book{spiveyCambridgeHandbookPsycholinguistics2012,
  title = {The {{Cambridge}} Handbook of Psycholinguistics},
  author = {Spivey, Michael and Joanisse, Marc and McRae, Ken},
  year = {2012},
  publisher = {{Cambridge University Press}},
  isbn = {0-521-67792-0}
}

@article{standevelopmentteamRStanInterfaceStan2019,
  title = {{{RStan}}: The {{R Interface}} to {{Stan}}},
  author = {{Stan Development Team}},
  year = {2019},
  keywords = {software}
}

@article{steacy2019examining,
  title = {Examining the Role of Imageability and Regularity in Word Reading Accuracy and Learning Efficiency among First and Second Graders at Risk for Reading Disabilities},
  author = {Steacy, Laura M and Compton, Donald L},
  year = {2019},
  journal = {Journal of experimental child psychology},
  volume = {178},
  pages = {226--250},
  publisher = {{Elsevier}},
  keywords = {psihologija-jezika,word-exposure}
}

@article{steegenIncreasingTransparencyMultiverse2016,
  title = {Increasing {{Transparency Through}} a {{Multiverse Analysis}}},
  author = {Steegen, Sara and Tuerlinckx, Francis and Gelman, Andrew and Vanpaemel, Wolf},
  year = {2016},
  month = sep,
  journal = {Perspectives on Psychological Science},
  volume = {11},
  number = {5},
  pages = {702--712},
  issn = {1745-6916, 1745-6924},
  doi = {10.1177/1745691616658637},
  abstract = {Empirical research inevitably includes constructing a data set by processing raw data into a form ready for statistical analysis. Data processing often involves choices among several reasonable options for excluding, transforming, and coding data. We suggest that instead of performing only one analysis, researchers could perform a multiverse analysis, which involves performing all analyses across the whole set of alternatively processed data sets corresponding to a large set of reasonable scenarios. Using an example focusing on the effect of fertility on religiosity and political attitudes, we show that analyzing a single data set can be misleading and propose a multiverse analysis as an alternative practice. A multiverse analysis offers an idea of how much the conclusions change because of arbitrary choices in data construction and gives pointers as to which choices are most consequential in the fragility of the result.},
  language = {en},
  keywords = {metodologija,statistika}
}

@article{steenMedflexPackageFlexible2017,
  title = {Medflex : {{An R Package}} for {{Flexible Mediation Analysis}} Using {{Natural Effect Models}}},
  shorttitle = {{\textbf{Medflex}}},
  author = {Steen, Johan and Loeys, Tom and Moerkerke, Beatrijs and Vansteelandt, Stijn},
  year = {2017},
  journal = {Journal of Statistical Software},
  volume = {76},
  number = {11},
  issn = {1548-7660},
  doi = {10.18637/jss.v076.i11},
  abstract = {Mediation analysis is routinely adopted by researchers from a wide range of applied disciplines as a statistical tool to disentangle the causal pathways by which an exposure or treatment affects an outcome. The counterfactual framework provides a language for clearly defining path-specific effects of interest and has fostered a principled extension of mediation analysis beyond the context of linear models. This paper describes medflex, an R package that implements some recent developments in mediation analysis embedded within the counterfactual framework. The medflex package offers a set of ready-made functions for fitting natural effect models, a novel class of causal models which directly parameterize the path-specific effects of interest, thereby adding flexibility to existing software packages for mediation analysis, in particular with respect to hypothesis testing and parsimony. In this paper, we give a comprehensive overview of the functionalities of the medflex package.},
  language = {en},
  keywords = {causal-inference,software,statistika}
}

@article{steynjrEstimatingEffectSize2009,
  title = {Estimating an Effect Size in One-Way Multivariate Analysis of Variance ({{MANOVA}})},
  author = {Steyn Jr, H. S. and Ellis, S. M.},
  year = {2009},
  journal = {Multivariate Behavioral Research},
  volume = {44},
  number = {1},
  pages = {106--129},
  keywords = {effect-size,multivariate,statistika},
  file = {/home/denis/Zotero/storage/TTH7EM7B/00273170802620238.html}
}

@article{stuartMatchingMethodsCausal2010,
  title = {Matching {{Methods}} for {{Causal Inference}}: {{A Review}} and a {{Look Forward}}},
  shorttitle = {Matching {{Methods}} for {{Causal Inference}}},
  author = {Stuart, Elizabeth A.},
  year = {2010},
  month = feb,
  journal = {Statistical Science},
  volume = {25},
  number = {1},
  pages = {1--21},
  issn = {0883-4237},
  doi = {10.1214/09-STS313},
  abstract = {When estimating causal effects using observational data, it is desirable to replicate a randomized experiment as closely as possible by obtaining treated and control groups with similar covariate distributions. This goal can often be achieved by choosing well-matched samples of the original treated and control groups, thereby reducing bias due to the covariates. Since the 1970s, work on matching methods has examined how to best choose treated and control subjects for comparison. Matching methods are gaining popularity in fields such as economics, epidemiology, medicine and political science. However, until now the literature and related advice has been scattered across disciplines. Researchers who are interested in using matching methods\textemdash or developing methods related to matching\textemdash do not have a single place to turn to learn about past and current research. This paper provides a structure for thinking about matching methods and guidance on their use, coalescing the existing research (both old and new) and providing a summary of where the literature on matching methods is now and where it should be headed.},
  language = {en},
  keywords = {causal-inference,statistika}
}

@article{suMultipleImputationDiagnostics2011,
  title = {Multiple {{Imputation}} with {{Diagnostics}} (Mi) in {{R}}: {{Opening Windows}} into the {{Black Box}}},
  shorttitle = {Multiple {{Imputation}} with {{Diagnostics}} (Mi) in {{R}}},
  author = {Su, Yu-Sung and Gelman, Andrew and Hill, Jennifer and Yajima, Masanao},
  year = {2011},
  month = dec,
  journal = {Journal of Statistical Software},
  volume = {45},
  number = {1},
  pages = {1--31},
  issn = {1548-7660},
  doi = {10.18637/jss.v045.i02},
  copyright = {Copyright (c) 2009 Yu-Sung Su, Andrew Gelman, Jennifer Hill, Masanao Yajima},
  language = {en},
  keywords = {missing-data,multiple-imputation,software,statistika},
  file = {/home/denis/Zotero/storage/5VL24X54/v045i02.html}
}

@book{surowieckiWisdomCrowds2005,
  title = {The {{Wisdom Of Crowds}}},
  author = {Surowiecki, James},
  year = {2005},
  publisher = {{Anchor Books}},
  address = {{New York, NY}}
}

@article{symonds2011brief,
  title = {A Brief Guide to Model Selection, Multimodel Inference and Model Averaging in Behavioural Ecology Using {{Akaike}}'s Information Criterion},
  author = {Symonds, Matthew RE and Moussalli, Adnan},
  year = {2011},
  journal = {Behavioral Ecology and Sociobiology},
  volume = {65},
  number = {1},
  pages = {13--21},
  publisher = {{Springer}},
  keywords = {information-theory,multi-model-inference,statistika}
}

@article{szeChineseLexiconProject2014,
  title = {The {{Chinese Lexicon Project}}: {{A Repository}} of {{Lexical Decision Behavioral Responses}} for 2,500 {{Chinese Characters}}},
  shorttitle = {The {{Chinese Lexicon Project}}},
  author = {Sze, Wei Ping and Rickard Liow, Susan J. and Yap, Melvin J.},
  year = {2014},
  month = mar,
  journal = {Behavior Research Methods},
  volume = {46},
  number = {1},
  pages = {263--273},
  issn = {1554-3528},
  doi = {10.3758/s13428-013-0355-9},
  abstract = {The Chinese language has more native speakers than any other language, but research on the reading of Chinese characters is still not as well-developed as it is for the reading of words in alphabetic languages. Two areas notably lacking are the paucity of megastudies in Chinese and the relatively infrequent use of the lexical decision paradigm to investigate single-character recognition. The Chinese Lexicon Project, described in this article, is a database of lexical decision latencies for 2,500 Chinese single characters in simplified script, collected from a sample of native mainland Chinese (Mandarin) speakers (N = 35). This resource will provide a valuable adjunct to influential mega-databases, such as the English, French, and Dutch Lexicon Projects. Using two separate analyses, some advantages associated with megastudies are exemplified. These include the selection of the strongest measure to represent Chinese character frequency (Cai \& Brysbaert's (PLoS ONE 5(6): e10729, 2010) subtitle contextual diversity frequency count), and the conducting of virtual studies to replicate and clarify existing findings. The unique morpho-syllabic nature of the Chinese writing system makes it a valuable case study for functional language contrasts. Moreover, this is the first publicly available large-scale repository of behavioral responses pertaining to Chinese language processing (the behavioral dataset is attached to this article, as a supplemental file available for download). For these reasons, the data should be of substantial interest to psychologists, linguists, and other researchers.},
  language = {en}
}

@misc{szollosiArrestedTheoryDevelopment2019,
  title = {Arrested Theory Development: {{The}} Misguided Distinction between Exploratory and Confirmatory Research},
  shorttitle = {Arrested Theory Development},
  author = {Szollosi, Aba and Donkin, Chris},
  year = {2019},
  month = sep,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/suzej},
  abstract = {Science progresses by finding and correcting problems in theories. Good theories are those that help facilitate this process by being hard-to-vary: they explain what they are supposed to explain, they are consistent with other good theories, and they are not easily adaptable to explain anything. Here we argue that, rather than a lack of distinction between exploratory and confirmatory research, an abundance of flexible theories is a better explanation for current replicability problems of psychology. We also explain why popular methods-oriented solutions fail to address the real problem of flexibility. Instead, we propose that a greater emphasis on theory criticism by argument would improve replicability.},
  keywords = {filozofija-znanosti}
}

@article{szollosiPreregistrationWorthwhile2020,
  title = {Is {{Preregistration Worthwhile}}?},
  author = {Szollosi, Aba and Kellen, David and Navarro, Danielle J. and Shiffrin, Richard and van Rooij, Iris and Zandt, Trisha Van and Donkin, Chris},
  year = {2020},
  month = feb,
  journal = {Trends in Cognitive Sciences},
  volume = {24},
  number = {2},
  pages = {94--95},
  publisher = {{Elsevier}},
  issn = {1364-6613, 1879-307X},
  doi = {10.1016/j.tics.2019.11.009},
  language = {English},
  pmid = {31892461},
  keywords = {filozofija-znanosti,meta-science},
  file = {/home/denis/Zotero/storage/UIJK9YMJ/S1364-6613(19)30285-2.html}
}

@article{szpunarInterpolatedMemoryTests2013,
  title = {Interpolated Memory Tests Reduce Mind Wandering and Improve Learning of Online Lectures},
  author = {Szpunar, Karl K. and Khan, Novall Y. and Schacter, Daniel L.},
  year = {2013},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {110},
  number = {16},
  pages = {6313--6317},
  keywords = {interpolated-testing}
}

@article{szpunarMindWanderingEducation2013,
  title = {Mind Wandering and Education: From the Classroom to Online Learning},
  author = {Szpunar, Karl K. and Moulton, Samuel Taylor and Schacter, Daniel L.},
  year = {2013},
  journal = {Frontiers in psychology},
  volume = {4},
  pages = {495},
  keywords = {interpolated-testing}
}

@article{szpunarOvercomingOverconfidenceLearning2014,
  title = {Overcoming Overconfidence in Learning from Video-Recorded Lectures: {{Implications}} of Interpolated Testing for Online Education},
  author = {Szpunar, Karl K. and Jing, Helen G. and Schacter, Daniel L.},
  year = {2014},
  journal = {Journal of Applied Research in Memory and Cognition},
  volume = {3},
  number = {3},
  pages = {161--164},
  keywords = {interpolated-testing}
}

@book{tabachnickUsingMultivariateStatistics2012,
  title = {Using {{Multivariate Statistics}}},
  author = {Tabachnick, Barbara G and Fidell, Linda S},
  year = {2012},
  publisher = {{Pearson}},
  address = {{London, UK}}
}

@article{thoemmesGraphicalRepresentationMissing2015,
  title = {Graphical {{Representation}} of {{Missing Data Problems}}},
  author = {Thoemmes, Felix and Mohan, Karthika},
  year = {2015},
  month = oct,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {22},
  number = {4},
  pages = {631--642},
  issn = {1070-5511, 1532-8007},
  doi = {10.1080/10705511.2014.937378},
  abstract = {Rubin's classic missingness mechanisms are central to handling missing data and minimizing biases that can arise due to missingness. However, the formulaic expressions that posit certain independencies among missing and observed data are difficult to grasp. As a result, applied researchers often rely on informal translations of these assumptions. We present a graphical representation of missing data mechanism, formalized in Mohan, Pearl, and Tian (2013). We show that graphical models provide a tool for comprehending, encoding, and communicating assumptions about the missingness process. Furthermore, we demonstrate on several examples how graph-theoretical criteria can determine if biases due to missing data might emerge in some estimates of interests and which auxiliary variables are needed to control for such biases, given assumptions about the missingness process.},
  language = {en},
  keywords = {causal-inference,missing-data,statistika}
}

@article{thompsonEffectSizesConfidence2007,
  title = {Effect Sizes, Confidence Intervals, and Confidence Intervals for Effect Sizes},
  author = {Thompson, Bruce},
  year = {2007},
  journal = {Psychology in the Schools},
  volume = {44},
  number = {5},
  pages = {423--432},
  keywords = {effect-size,statistika}
}

@article{tingleyMediationPackageCausal2014,
  title = {Mediation: {{R}} Package for Causal Mediation Analysis},
  shorttitle = {Mediation},
  author = {Tingley, Dustin and Yamamoto, Teppei and Hirose, Kentaro and Keele, Luke and Imai, Kosuke},
  year = {2014},
  keywords = {medijacija,software,statistika}
}

@article{tseChineseLexiconProject2017,
  title = {The {{Chinese Lexicon Project}}: {{A Megastudy}} of {{Lexical Decision Performance}} for 25,000+ {{Traditional Chinese Two}}-Character {{Compound Words}}},
  shorttitle = {The {{Chinese Lexicon Project}}},
  author = {Tse, Chi-Shing and Yap, Melvin J. and Chan, Yuen-Lai and Sze, Wei Ping and Shaoul, Cyrus and Lin, Dan},
  year = {2017},
  month = aug,
  journal = {Behavior Research Methods},
  volume = {49},
  number = {4},
  pages = {1503--1519},
  issn = {1554-3528},
  doi = {10.3758/s13428-016-0810-5},
  language = {en}
}

@article{tuckerMassiveAuditoryLexical2019,
  title = {The {{Massive Auditory Lexical Decision}} ({{MALD}}) {{Database}}},
  author = {Tucker, Benjamin V. and Brenner, Daniel and Danielson, D. Kyle and Kelley, Matthew C. and Nenadi{\'c}, Filip and Sims, Michelle},
  year = {2019},
  month = jun,
  journal = {Behavior Research Methods},
  volume = {51},
  number = {3},
  pages = {1187--1204},
  issn = {1554-3528},
  doi = {10.3758/s13428-018-1056-1},
  abstract = {The Massive Auditory Lexical Decision (MALD) database is an end-to-end, freely available auditory and production data set for speech and psycholinguistic research, providing time-aligned stimulus recordings for 26,793 words and 9592 pseudowords, and response data for 227,179 auditory lexical decisions from 231 unique monolingual English listeners. In addition to the experimental data, we provide many precompiled listener- and item-level descriptor variables. This data set makes it easy to explore responses, build and test theories, and compare a wide range of models. We present summary statistics and analyses.},
  language = {en},
  keywords = {megastudy,psihologija-jezika}
}

@article{tzelgovSuppressionSituationsPsychological1991,
  title = {Suppression Situations in Psychological Research: {{Definitions}}, Implications, and Applications.},
  shorttitle = {Suppression Situations in Psychological Research},
  author = {Tzelgov, Joseph and Henik, Avishai},
  year = {1991},
  journal = {Psychological Bulletin},
  volume = {109},
  number = {3},
  pages = {524},
  keywords = {statistika,suppressor},
  file = {/home/denis/Zotero/storage/8HAQJATN/1991-20289-001.html}
}

@incollection{ullmanStructuralEquationModeling2012,
  title = {Structural {{Equation Modeling}}},
  booktitle = {Using {{Multivariate Statistics}}},
  author = {Ullman, Jodie B},
  editor = {Tabachnick, Barbara G and Fidell, Linda S},
  year = {2012},
  pages = {681--785},
  publisher = {{Pearson}},
  address = {{London, UK}},
  keywords = {sem,statistika}
}

@article{unsworthAutomatedVersionOperation2005,
  title = {An Automated Version of the Operation Span Task},
  author = {Unsworth, Nash and Heitz, Richard P. and Schrock, Josef C. and Engle, Randall W.},
  year = {2005},
  journal = {Behavior research methods},
  volume = {37},
  number = {3},
  pages = {498--505},
  keywords = {complex-span-test}
}

@article{unsworthComplexWorkingMemory2009,
  title = {Complex Working Memory Span Tasks and Higher-Order Cognition: {{A}} Latent-Variable Analysis of the Relationship between Processing and Storage},
  author = {Unsworth, Nash and Redick, Thomas S. and Heitz, Richard P. and Broadway, James M. and Engle, Randall W.},
  year = {2009},
  journal = {Memory},
  volume = {17},
  number = {6},
  pages = {635--654}
}

@article{valliantComparingAlternativesEstimation2020,
  title = {Comparing Alternatives for Estimation from Nonprobability Samples},
  author = {Valliant, Richard},
  year = {2020},
  journal = {Journal of Survey Statistics and Methodology},
  volume = {8},
  number = {2},
  pages = {231--263},
  publisher = {{Oxford University Press}},
  file = {/home/denis/Zotero/storage/RJDFNKHQ/5438286.html;/home/denis/Zotero/storage/Z7WGTD2X/5438286.html}
}

@article{vanaertConductingMetaanalysesBased2016,
  title = {Conducting Meta-Analyses Based on p Values: {{Reservations}} and Recommendations for Applying p-Uniform and p-Curve},
  author = {{van Aert}, Robbie CM and Wicherts, Jelte M. and {van Assen}, Marcel ALM},
  year = {2016},
  journal = {Perspectives on Psychological Science},
  volume = {11},
  number = {5},
  pages = {713--729},
  keywords = {metodologija,statistika}
}

@book{vanbuurenFlexibleImputationMissing2018,
  title = {Flexible Imputation of Missing Data},
  author = {Van Buuren, Stef},
  year = {2018},
  publisher = {{Chapman and Hall/CRC}},
  keywords = {missing-data,multiple-imputation,statistika},
  file = {/home/denis/Zotero/storage/B8J9FJWL/9780429492259.html;/home/denis/Zotero/storage/E6DJTMN5/R-publications_bib.html}
}

@article{vancalsterRegressionShrinkageMethods2020,
  title = {Regression Shrinkage Methods for Clinical Prediction Models Do Not Guarantee Improved Performance: {{Simulation}} Study},
  shorttitle = {Regression Shrinkage Methods for Clinical Prediction Models Do Not Guarantee Improved Performance},
  author = {Van Calster, Ben and {van Smeden}, Maarten and De Cock, Bavo and Steyerberg, Ewout W},
  year = {2020},
  month = nov,
  journal = {Statistical Methods in Medical Research},
  volume = {29},
  number = {11},
  pages = {3166--3178},
  publisher = {{SAGE Publications Ltd STM}},
  issn = {0962-2802},
  doi = {10.1177/0962280220921415},
  abstract = {When developing risk prediction models on datasets with limited sample size, shrinkage methods are recommended. Earlier studies showed that shrinkage results in better predictive performance on average. This simulation study aimed to investigate the variability of regression shrinkage on predictive performance for a binary outcome. We compared standard maximum likelihood with the following shrinkage methods: uniform shrinkage (likelihood-based and bootstrap-based), penalized maximum likelihood (ridge) methods, LASSO logistic regression, adaptive LASSO, and Firth's correction. In the simulation study, we varied the number of predictors and their strength, the correlation between predictors, the event rate of the outcome, and the events per variable. In terms of results, we focused on the calibration slope. The slope indicates whether risk predictions are too extreme (slope\,{$<$}\,1) or not extreme enough (slope\,{$>$}\,1). The results can be summarized into three main findings. First, shrinkage improved calibration slopes on average. Second, the between-sample variability of calibration slopes was often increased relative to maximum likelihood. In contrast to other shrinkage approaches, Firth's correction had a small shrinkage effect but showed low variability. Third, the correlation between the estimated shrinkage and the optimal shrinkage to remove overfitting was typically negative, with Firth's correction as the exception. We conclude that, despite improved performance on average, shrinkage often worked poorly in individual datasets, in particular when it was most needed. The results imply that shrinkage methods do not solve problems associated with small sample size or low number of events per variable.},
  language = {en},
  keywords = {statistika}
}

@article{vanderweeleConceptualIssuesConcerning2009,
  title = {Conceptual {{Issues Concerning Mediation}}, {{Interventions}} and {{Composition}}},
  author = {Vanderweele, Tyler J. and Vansteelandt, Stijn},
  year = {2009},
  journal = {Statistics and Its Interface},
  volume = {2},
  number = {4},
  pages = {457--468},
  issn = {19387989, 19387997},
  doi = {10.4310/SII.2009.v2.n4.a7},
  abstract = {Concepts concerning mediation in the causal inference literature are reviewed. Notions of direct and indirect effects from a counterfactual approach to mediation are compared with those arising from the standard regression approach to mediation of Baron and Kenny (1986), commonly utilized in the social science literature. It is shown that concepts of direct and indirect effect from causal inference generalize those described by Baron and Kenny and that under appropriate identification assumptions these more general direct and indirect effects from causal inference can be estimated using regression even when there are interactions between the primary exposure of interest and the mediator. A number of conceptual issues are discussed concerning the interpretation of identification conditions for mediation, the notion of counterfactuals based on hypothetical interventions and the so called consistency and composition assumptions.},
  language = {en},
  keywords = {causal-inference,medijacija,statistika}
}

@article{vanderweeleDistinctionInteractionEffect2009,
  title = {On the {{Distinction Between Interaction}} and {{Effect Modification}}:},
  shorttitle = {On the {{Distinction Between Interaction}} and {{Effect Modification}}},
  author = {VanderWeele, Tyler J.},
  year = {2009},
  month = nov,
  journal = {Epidemiology},
  volume = {20},
  number = {6},
  pages = {863--871},
  issn = {1044-3983},
  doi = {10.1097/EDE.0b013e3181ba333c},
  abstract = {This paper contrasts the concepts of interaction and effect modification using a series of examples. Interaction and effect modification are formally defined within the counterfactual framework. Interaction is defined in terms of the effects of 2 interventions whereas effect modification is defined in terms of the effect of one intervention varying across strata of a second variable. Effect modification can be present with no interaction; interaction can be present with no effect modification. There are settings in which it is possible to assess effect modification but not interaction, or to assess interaction but not effect modification. The analytic procedures for obtaining estimates of effect modification parameters and interaction parameters using marginal structural models are compared and contrasted. A characterization is given of the settings in which interaction and effect modification coincide.},
  language = {en},
  keywords = {causal-inference,statistika}
}

@book{vanderweeleExplanationCausalInference2015,
  ids = {vanderweeleExplanationCausalInference2015a},
  title = {Explanation in {{Causal Inference}}: {{Methods}} for {{Mediation}} and {{Interaction}}},
  author = {VanderWeele, Tyler},
  year = {2015},
  publisher = {{Oxford University Press}},
  isbn = {0-19-932588-X},
  keywords = {causal-inference,statistika}
}

@article{vanderweelePrinciplesConfounderSelection2019,
  title = {Principles of Confounder Selection},
  author = {VanderWeele, Tyler J.},
  year = {2019},
  month = mar,
  journal = {European Journal of Epidemiology},
  volume = {34},
  number = {3},
  pages = {211--219},
  issn = {0393-2990, 1573-7284},
  doi = {10.1007/s10654-019-00494-6},
  abstract = {Selecting an appropriate set of confounders for which to control is critical for reliable causal inference. Recent theoretical and methodological developments have helped clarify a number of principles of confounder selection. When complete knowledge of a causal diagram relating all covariates to each other is available, graphical rules can be used to make decisions about covariate control. Unfortunately, such complete knowledge is often unavailable. This paper puts forward a practical approach to confounder selection decisions when the somewhat less stringent assumption is made that knowledge is available for each covariate whether it is a cause of the exposure, and whether it is a cause of the outcome. Based on recent theoretically justified developments in the causal inference literature, the following proposal is made for covariate control decisions: control for each covariate that is a cause of the exposure, or of the outcome, or of both; exclude from this set any variable known to be an instrumental variable; and include as a covariate any proxy for an unmeasured variable that is a common cause of both the exposure and the outcome. Various principles of confounder selection are then further related to statistical covariate selection methods.},
  language = {en},
  keywords = {causal-inference,statistika}
}

@article{vandierendonckTaskSwitchingInterplay2010,
  title = {Task Switching: Interplay of Reconfiguration and Interference Control.},
  author = {Vandierendonck, Andr{\'e} and Liefooghe, Baptist and Verbruggen, Frederick},
  year = {2010},
  journal = {Psychological bulletin},
  volume = {136},
  number = {4},
  pages = {601}
}

@techreport{vanrooijFormalizingVerbalTheories2020,
  type = {Preprint},
  title = {Formalizing Verbal Theories: {{A}} Tutorial by Dialogue},
  shorttitle = {Formalizing Verbal Theories},
  author = {{van Rooij}, Iris and Blokpoel, Mark},
  year = {2020},
  month = jul,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/r2zqy},
  abstract = {We present a tutorial for formalizing verbal theories of psychological phenomena\textemdash social or otherwise. The approach builds on concepts and tools from the mathematics of computation. We use intuitive examples and illustrate the intrinsic dialectical nature of the formalization process by presenting dialogues between two fictive characters, called Verbal and Formal. These characters' conversations and thought experiments serve to highlight important lessons in theoretical modeling.}
}

@techreport{vanrooijTheoryTestHow2020,
  type = {Preprint},
  title = {Theory before the Test: {{How}} to Build High-Verisimilitude Explanatory Theories in Psychological Science},
  shorttitle = {Theory before the Test},
  author = {{van Rooij}, Iris and Baggio, Giosu{\`e}},
  year = {2020},
  month = feb,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/7qbpr},
  abstract = {Drawing on the philosophy of psychological explanation (Cummins, 1983; 2000), we suggest that psychological science, by focusing on effects, may lose sight of its primary explananda: psychological capacities. We revisit Marr's (1982) levels-of-analysis framework, which has been remarkably productive and useful for cognitive psychological explanation. We discuss ways in which Marr's framework may be extended to other areas of psychology, such as social, developmental, and evolutionary psychology, bringing new benefits to these fields. Next, we show how theoretical analyses can endow a theory with minimal plausibility even prior to contact with empirical data: we call this the theoretical cycle. Finally, we explain how our proposal may contribute to addressing critical issues in psychological science, including how to leverage effects to understand capacities better.},
  language = {en},
  keywords = {metodologija}
}

@article{vansteelandtNaturalDirectIndirect2012,
  title = {Natural {{Direct}} and {{Indirect Effects}} on the {{Exposed}}: {{Effect Decomposition}} under {{Weaker Assumptions}}},
  shorttitle = {Natural {{Direct}} and {{Indirect Effects}} on the {{Exposed}}},
  author = {Vansteelandt, Stijn and VanderWeele, Tyler J.},
  year = {2012},
  month = dec,
  journal = {Biometrics},
  volume = {68},
  number = {4},
  pages = {1019--1027},
  issn = {0006341X},
  doi = {10.1111/j.1541-0420.2012.01777.x},
  abstract = {We define natural direct and indirect effects on the exposed. We show that these allow for effect decomposition under weaker identification conditions than population natural direct and indirect effects. When no confounders of the mediator-outcome association are affected by the exposure, identification is possible under essentially the same conditions as for controlled direct effects. Otherwise, identification is still possible with additional knowledge on a nonidentifiable selectionbias function which measures the dependence of the mediator effect on the observed exposure within confounder levels, and which evaluates to zero in a large class of realistic data-generating mechanisms. We argue that natural direct and indirect effects on the exposed are of intrinsic interest in various applications. We moreover show that they coincide with the corresponding population natural direct and indirect effects when the exposure is randomly assigned. In such settings, our results are thus also of relevance for assessing population natural direct and indirect effects in the presence of exposure-induced mediator-outcome confounding, which existing methodology has not been able to address.},
  language = {en},
  keywords = {causal-inference,medijacija,statistika}
}

@article{vantveerPreregistrationSocialPsychology2016,
  title = {Pre-Registration in Social Psychology\textemdash{{A}} Discussion and Suggested Template},
  author = {{van't Veer}, Anna Elisabeth and {Giner-Sorolla}, Roger},
  year = {2016},
  journal = {Journal of Experimental Social Psychology},
  volume = {67},
  pages = {2--12},
  keywords = {metodologija}
}

@article{vehtariPracticalBayesianModel2017,
  ids = {vehtariPracticalBayesianModel2017a},
  title = {Practical {{Bayesian Model Evaluation Using}} Leave-One-out {{Cross}}-Validation and {{WAIC}}},
  author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  year = {2017},
  month = sep,
  journal = {Statistics and Computing},
  volume = {27},
  number = {5},
  pages = {1413--1432},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-016-9696-4},
  abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparing of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
  language = {en},
  keywords = {bayes,cross-validation,statistika},
  file = {/home/denis/Zotero/storage/ZFBSJXVZ/Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf}
}

@article{vehtariSurveyBayesianPredictive2012,
  title = {A Survey of {{Bayesian}} Predictive Methods for Model Assessment, Selection and Comparison},
  author = {Vehtari, Aki and Ojanen, Janne},
  year = {2012},
  journal = {Statistics Surveys},
  volume = {6},
  pages = {142--228},
  publisher = {{The author, under a Creative Commons Attribution License}},
  file = {/home/denis/Zotero/storage/48WXVNYK/1356628931.html}
}

@book{venablesModernAppliedStatistics2002,
  title = {Modern {{Applied Statistics}} with {{S}}},
  author = {Venables, W. N. and Ripley, B. D.},
  year = {2002},
  edition = {Fourth},
  publisher = {{Springer}},
  address = {{New York}}
}

@article{wagenmakersDiffusionModelAccount2008,
  title = {A {{Diffusion Model Account}} of {{Criterion Shifts}} in the {{Lexical Decision Task}}},
  author = {Wagenmakers, Eric-Jan and Ratcliff, Roger and Gomez, Pablo and McKoon, Gail},
  year = {2008},
  month = jan,
  journal = {Journal of Memory and Language},
  volume = {58},
  number = {1},
  pages = {140--159},
  issn = {0749-596X},
  doi = {10.1016/j.jml.2007.04.006},
  abstract = {Performance in the lexical decision task is highly dependent on decision criteria. These criteria can be influenced by speed versus accuracy instructions and word/nonword proportions. Experiment 1 showed that error responses speed up relative to correct responses under instructions to respond quickly. Experiment 2 showed that responses to less probable stimuli are slower and less accurate than responses to more probable stimuli. The data from both experiments support the diffusion model for lexical decision [Ratcliff, R., Gomez, P., \& McKoon, G. (2004a). A diffusion model account of the lexical decision task. Psychological Review, 111, 159\textendash 182]. At the same time, the data provide evidence against the popular deadline model for lexical decision. The deadline model assumes that ``nonword'' responses are given only after the ``word'' response has timed out\textemdash consequently, the deadline model cannot account for the data from experimental conditions in which ``nonword'' responses are systematically faster than ``word'' responses.},
  language = {en},
  keywords = {diffusion-model,psihologija-jezika},
  file = {/home/denis/Zotero/storage/GQG2GSA8/S0749596X07000496.html}
}

@article{wagenmakersInterpretationRemovableInteractions2012,
  title = {On the Interpretation of Removable Interactions: {{A}} Survey of the Field 33 Years after {{Loftus}}},
  author = {Wagenmakers, Eric-Jan and Krypotos, Angelos-Miltiadis and Criss, Amy H. and Iverson, Geoff},
  year = {2012},
  journal = {Memory \& cognition},
  volume = {40},
  number = {2},
  pages = {145--160},
  keywords = {metodologija,statistika}
}

@article{wagenmakersMethodologicalEmpiricalDevelopments2009,
  title = {Methodological and Empirical Developments for the {{Ratcliff}} Diffusion Model of Response Times and Accuracy},
  author = {Wagenmakers, Eric-Jan},
  year = {2009},
  month = aug,
  journal = {European Journal of Cognitive Psychology},
  volume = {21},
  number = {5},
  pages = {641--671},
  publisher = {{Routledge}},
  issn = {0954-1446},
  doi = {10.1080/09541440802205067},
  abstract = {The Ratcliff diffusion model for simple two-choice decisions (e.g., Ratcliff, 1978; Ratcliff \& McKoon, 2008) has two outstanding advantages. First, the model generally provides an excellent fit to the observed data (i.e., response accuracy and the shape of RT distributions, both for correct and error responses). Second, the parameters of the model can be mapped on to latent psychological processes such as the speed of information accumulation, response caution, and a priori bias. In recent years, the advantages of the Ratcliff diffusion model have become increasingly clear. Current advances in methodology allow all researchers to fit the diffusion model to data easily. Recent applications to ageing, lexical decision, IQ, practice, the implicit association test, and the accessory stimulus effect serve to highlight the added value of a diffusion model perspective on simple decision making.},
  keywords = {diffusion-model,psihologija-jezika},
  annotation = {\_eprint: https://doi.org/10.1080/09541440802205067}
}

@article{walterCodingOrdinalIndependent1987,
  title = {Coding Ordinal Independent Variables in Multiple Regression Analyses},
  author = {Walter, Stephen D. and Feinstein, Alvan R. and Wells, Carolyn K.},
  year = {1987},
  journal = {American Journal of Epidemiology},
  volume = {125},
  number = {2},
  pages = {319--323},
  keywords = {regresija,statistika},
  file = {/home/denis/Zotero/storage/FFWU572I/109714.html}
}

@article{wangBlessingsMultipleCauses2019,
  title = {The {{Blessings}} of {{Multiple Causes}}},
  author = {Wang, Yixin and Blei, David M.},
  year = {2019},
  month = oct,
  journal = {Journal of the American Statistical Association},
  volume = {114},
  number = {528},
  pages = {1574--1596},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.2019.1686987},
  abstract = {Causal inference from observational data is a vital problem, but it comes with strong assumptions. Most methods assume that we observe all confounders, variables that affect both the causal variables and the outcome variables. This assumption is standard but it is also untestable. In this article, we develop the deconfounder, a way to do causal inference with weaker assumptions than the traditional methods require. The deconfounder is designed for problems of multiple causal inference: scientific studies that involve multiple causes whose effects are simultaneously of interest. Specifically, the deconfounder combines unsupervised machine learning and predictive model checking to use the dependencies among multiple causes as indirect evidence for some of the unobserved confounders. We develop the deconfounder algorithm, prove that it is unbiased, and show that it requires weaker assumptions than traditional causal inference. We analyze its performance in three types of studies: semi-simulated data around smoking and lung cancer, semi-simulated data around genome-wide association studies, and a real dataset about actors and movie revenue. The deconfounder is an effective approach to estimating causal effects in problems of multiple causal inference. Supplementary materials for this article are available online.},
  file = {/home/denis/Zotero/storage/67QR5Z4B/01621459.2019.html}
}

@book{weaverLadyLuckTheory1963,
  title = {Lady {{Luck}}: {{The Theory}} of {{Probability}}},
  author = {Weaver, Warren},
  year = {1963},
  publisher = {{Dover Publications, Inc.}},
  isbn = {0-486-15091-7},
  keywords = {statistika,vjerojatnost}
}

@article{weisbergWhoModeler2007,
  title = {Who Is a {{Modeler}}?},
  author = {Weisberg, Michael},
  year = {2007},
  journal = {The British journal for the philosophy of science},
  volume = {58},
  number = {2},
  pages = {207--233},
  publisher = {{Oxford University Press}},
  file = {/home/denis/Zotero/storage/8NRTQTJ7/1545300.html}
}

@article{westfallStatisticallyControllingConfounding2016,
  title = {Statistically {{Controlling}} for {{Confounding Constructs Is Harder}} than {{You Think}}},
  author = {Westfall, Jacob and Yarkoni, Tal},
  year = {2016},
  month = mar,
  journal = {PLOS ONE},
  volume = {11},
  number = {3},
  pages = {e0152719},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0152719},
  abstract = {Social scientists often seek to demonstrate that a construct has incremental validity over and above other related constructs. However, these claims are typically supported by measurement-level models that fail to consider the effects of measurement (un)reliability. We use intuitive examples, Monte Carlo simulations, and a novel analytical framework to demonstrate that common strategies for establishing incremental construct validity using multiple regression analysis exhibit extremely high Type I error rates under parameter regimes common in many psychological domains. Counterintuitively, we find that error rates are highest\textemdash in some cases approaching 100\%\textemdash when sample sizes are large and reliability is moderate. Our findings suggest that a potentially large proportion of incremental validity claims made in the literature are spurious. We present a web application (http://jakewestfall.org/ivy/) that readers can use to explore the statistical properties of these and other incremental validity arguments. We conclude by reviewing SEM-based statistical approaches that appropriately control the Type I error rate when attempting to establish incremental validity.},
  language = {en},
  file = {/home/denis/Zotero/storage/23JQST6M/article.html}
}

@article{westfallStatisticalPowerOptimal2014,
  title = {Statistical {{Power}} and {{Optimal Design}} in {{Experiments}} in {{Which Samples}} of {{Participants Respond}} to {{Samples}} of {{Stimuli}}},
  author = {Westfall, Jacob and Kenny, David A. and Judd, Charles M.},
  year = {2014},
  journal = {Journal of Experimental Psychology: General},
  volume = {143},
  number = {5},
  pages = {2020--2045},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/xge0000014},
  abstract = {Researchers designing experiments in which a sample of participants responds to a sample of stimuli are faced with difficult questions about optimal study design. The conventional procedures of statistical power analysis fail to provide appropriate answers to these questions because they are based on statistical models in which stimuli are not assumed to be a source of random variation in the data, models that are inappropriate for experiments involving crossed random factors of participants and stimuli. In this article, we present new methods of power analysis for designs with crossed random factors, and we give detailed, practical guidance to psychology researchers planning experiments in which a sample of participants responds to a sample of stimuli. We extensively examine 5 commonly used experimental designs, describe how to estimate statistical power in each, and provide power analysis results based on a reasonable set of default parameter values. We then develop general conclusions and formulate rules of thumb concerning the optimal design of experiments in which a sample of participants responds to a sample of stimuli. We show that in crossed designs, statistical power typically does not approach unity as the number of participants goes to infinity but instead approaches a maximum attainable power value that is possibly small, depending on the stimulus sample. We also consider the statistical merits of designs involving multiple stimulus blocks. Finally, we provide a simple and flexible Web-based power application to aid researchers in planning studies with samples of stimuli.},
  language = {en},
  keywords = {effect-size,multilevel,stat-power,statistika}
}

@book{westLinearMixedModels2014,
  title = {Linear Mixed Models: A Practical Guide Using Statistical Software},
  author = {West, Brady T. and Welch, Kathleen B. and Galecki, Andrzej T.},
  year = {2014},
  publisher = {{Chapman and Hall/CRC}},
  isbn = {1-4665-6102-5},
  keywords = {multilevel,statistika}
}

@article{westreichTableFallacyPresenting2013,
  title = {The {{Table}} 2 {{Fallacy}}: {{Presenting}} and {{Interpreting Confounder}} and {{Modifier Coefficients}}},
  shorttitle = {The {{Table}} 2 {{Fallacy}}},
  author = {Westreich, D. and Greenland, S.},
  year = {2013},
  month = feb,
  journal = {American Journal of Epidemiology},
  volume = {177},
  number = {4},
  pages = {292--298},
  issn = {0002-9262, 1476-6256},
  doi = {10.1093/aje/kws412},
  language = {en},
  keywords = {causal-inference,statistika}
}

@incollection{whittakerStructuralEquationModeling2016,
  title = {Structural {{Equation Modeling}}},
  booktitle = {Applied {{Multivariate Statistics}} for the {{Social Sciences}}: {{Analyses}} with {{SAS}} and {{IBM}}'s {{SPSS}}},
  author = {Whittaker, Tiffany A.},
  editor = {Pituch, Keenan A and Stevens, James P},
  year = {2016},
  pages = {639--746},
  publisher = {{Routledge}},
  address = {{New York, NY}},
  keywords = {sem,statistika}
}

@book{wickhamConflictedAlternativeConflict2018,
  title = {Conflicted: {{An Alternative Conflict Resolution Strategy}}},
  author = {Wickham, Hadley},
  year = {2018}
}

@book{wickhamGgplot2ElegantGraphics2016,
  title = {Ggplot2: {{Elegant Graphics}} for {{Data Analysis}}},
  author = {Wickham, Hadley},
  year = {2016},
  publisher = {{Springer-Verlag New York}},
  isbn = {978-3-319-24277-4},
  keywords = {visualization}
}

@book{wickhamTidyverseEasilyInstall2017,
  title = {Tidyverse: {{Easily Install}} and {{Load}} the '{{Tidyverse}}'},
  author = {Wickham, Hadley},
  year = {2017}
}

@article{wickhamWelcomeTidyverse2019,
  title = {Welcome to the Tidyverse},
  author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and Fran{\c c}ois, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and M{\"u}ller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
  year = {2019},
  journal = {Journal of Open Source Software},
  volume = {4},
  number = {43},
  pages = {1686},
  doi = {10.21105/joss.01686},
  keywords = {software}
}

@article{williamsBayesianNonlinearMixedeffects2019,
  title = {A {{Bayesian}} Nonlinear Mixed-Effects Location Scale Model for Learning},
  author = {Williams, Donald R. and Zimprich, Daniel R. and Rast, Philippe},
  year = {2019},
  month = oct,
  journal = {Behavior Research Methods},
  volume = {51},
  number = {5},
  pages = {1968--1986},
  issn = {1554-3528},
  doi = {10.3758/s13428-019-01255-9},
  abstract = {We present a Bayesian nonlinear mixed-effects location scale model (NL-MELSM). The NL-MELSM allows for fitting nonlinear functions to the location, or individual means, and the scale, or within-person variance. Specifically, in the context of learning, this model allows the within-person variance to follow a nonlinear trajectory, where it can be determined whether variability reduces during learning. It incorporates a sub-model that can predict nonlinear parameters for both the location and scale. This specification estimates random effects for all nonlinear location and scale parameters that are drawn from a common multivariate distribution. This allows estimation of covariances among the random effects, within and across the location and the scale. These covariances offer new insights into the interplay between individual mean structures and intraindividual variability in nonlinear parameters. We take a fully Bayesian approach, not only for ease of estimation but also for inference because it provides the necessary and consistent information for use in psychological applications, such as model selection and hypothesis testing. To illustrate the model, we use data from 333 individuals, consisting of three age groups, who participated in five learning trials that assessed verbal memory. In an exploratory context, we demonstrate that fitting a nonlinear function to the within-person variance, and allowing for individual variation therein, improves predictive accuracy compared to customary modeling techniques (e.g., assuming constant variance). We conclude by discussing the usefulness, limitations, and future directions of the NL-MELSM.},
  language = {en},
  keywords = {bayes,statistika}
}

@article{wilsonBestPracticesScientific2014,
  title = {Best {{Practices}} for {{Scientific Computing}}},
  author = {Wilson, Greg and Aruliah, D. A. and Brown, C. Titus and Hong, Neil P. Chue and Davis, Matt and Guy, Richard T. and Haddock, Steven H. D. and Huff, Kathryn D. and Mitchell, Ian M. and Plumbley, Mark D. and Waugh, Ben and White, Ethan P. and Wilson, Paul},
  year = {2014},
  month = jan,
  journal = {PLOS Biology},
  volume = {12},
  number = {1},
  pages = {e1001745},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.1001745},
  abstract = {We describe a set of best practices for scientific software development, based on research and experience, that will improve scientists' productivity and the reliability of their software.},
  language = {en},
  keywords = {software,stat-project-management},
  file = {/home/denis/Zotero/storage/5LS6BM5Y/article.html}
}

@article{wilsonGoodEnoughPractices2017,
  title = {Good Enough Practices in Scientific Computing},
  author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K.},
  year = {2017},
  month = jun,
  journal = {PLOS Computational Biology},
  volume = {13},
  number = {6},
  pages = {e1005510},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005510},
  abstract = {Author summary Computers are now essential in all branches of science, but most researchers are never taught the equivalent of basic lab skills for research computing. As a result, data can get lost, analyses can take much longer than necessary, and researchers are limited in how effectively they can work with software and data. Computing workflows need to follow the same practices as lab projects and notebooks, with organized data, documented steps, and the project structured for reproducibility, but researchers new to computing often don't know where to start. This paper presents a set of good computing practices that every researcher can adopt, regardless of their current level of computational skill. These practices, which encompass data management, programming, collaborating with colleagues, organizing projects, tracking work, and writing manuscripts, are drawn from a wide variety of published sources from our daily lives and from our work with volunteer organizations that have delivered workshops to over 11,000 people since 2010.},
  language = {en},
  keywords = {software,stat-project-management},
  file = {/home/denis/Zotero/storage/W4I3Q2UL/article.html}
}

@article{wilsonTenSimpleRules2019,
  title = {Ten {{Simple Rules}} for the {{Computational Modeling}} of {{Behavioral Data}}},
  author = {Wilson, Robert C and Collins, Anne GE},
  year = {2019},
  month = nov,
  journal = {eLife},
  volume = {8},
  pages = {e49547},
  issn = {2050-084X},
  doi = {10.7554/eLife.49547},
  abstract = {Computational modeling of behavior has revolutionized psychology and neuroscience. By fitting models to experimental data we can probe the algorithms underlying behavior, find neural correlates of computational variables and better understand the effects of drugs, illness and interventions. But with great power comes great responsibility. Here, we offer ten simple rules to ensure that computational modeling is used with care and yields meaningful insights. In particular, we present a beginner-friendly, pragmatic and details-oriented introduction on how to relate models to data. What, exactly, can a model tell us about the mind? To answer this, we apply our rules to the simplest modeling techniques most accessible to beginning modelers and illustrate them with examples and code available online. However, most rules apply to more advanced techniques. Our hope is that by following our guidelines, researchers will avoid many pitfalls and unleash the power of computational modeling on their own data.},
  language = {en},
  keywords = {metodologija,modelling,statistika}
}

@article{wissmanInterimTestEffect2011,
  title = {The Interim Test Effect: {{Testing}} Prior Material Can Facilitate the Learning of New Material},
  author = {Wissman, Kathryn T. and Rawson, Katherine A. and Pyc, Mary A.},
  year = {2011},
  journal = {Psychonomic Bulletin \& Review},
  volume = {18},
  number = {6},
  pages = {1140--1147},
  keywords = {interpolated-testing}
}

@incollection{wolfeVisualAttention2000,
  title = {Visual Attention},
  booktitle = {Seeing},
  author = {Wolfe, Jeremy M.},
  editor = {De Valois, Karen K.},
  year = {2000},
  pages = {335--386},
  publisher = {{Elsevier}},
  address = {{San Diego, CA}},
  keywords = {flanker-task}
}

@book{xieKnitrGeneralPurposePackage2019,
  title = {Knitr: {{A General}}-{{Purpose Package}} for {{Dynamic Report Generation}} in {{R}}},
  author = {Xie, Yihui},
  year = {2019}
}

@book{xieMarkdownDefinitiveGuide2018,
  title = {R Markdown: {{The Definitive Guide}}},
  author = {Xie, Yihui and Allaire, J.J. and Grolemund, Garrett},
  year = {2018},
  publisher = {{Chapman and Hall/CRC}},
  address = {{Boca Raton, Florida}},
  keywords = {software}
}

@incollection{yapVisualWordRecognition2015,
  title = {Visual {{Word Recognition}}},
  booktitle = {The {{Oxford Handbook}} of {{Reading}}},
  author = {Yap, Melvin J. and Balota, David A.},
  editor = {Pollatsek, Alexander and Treiman, Rebecca},
  year = {2015},
  pages = {26--43},
  publisher = {{Oxford University Press}}
}

@article{yarkoniChoosingPredictionExplanation2017,
  title = {Choosing Prediction over Explanation in Psychology: {{Lessons}} from Machine Learning},
  author = {Yarkoni, Tal and Westfall, Jacob},
  year = {2017},
  journal = {Perspectives on Psychological Science},
  volume = {12},
  number = {6},
  pages = {1100--1122},
  keywords = {metodologija}
}

@techreport{yarkoniGeneralizabilityCrisis2019,
  type = {Preprint},
  title = {The {{Generalizability Crisis}}},
  author = {Yarkoni, Tal},
  year = {2019},
  month = nov,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/jqw35},
  abstract = {Most theories and hypotheses in psychology are verbal in nature, yet their evaluation overwhelmingly relies on inferential statistical procedures. The validity of the move from qualitative to quantitative analysis depends on the verbal and statistical expressions of a hypothesis being closely aligned\textemdash that is, that the two must refer to roughly the same set of hypothetical observations. Here I argue that most inferential statistical tests in psychology fail to meet this basic condition. I demonstrate how foundational assumptions of the "random effects" model used pervasively in psychology impose far stronger constraints on the generalizability of results than most researchers appreciate. Ignoring these constraints dramatically inflates false positive rates and routinely leads researchers to draw sweeping verbal generalizations that lack any meaningful connection to the statistical quantities they are putatively based on. I argue that the routine failure to consider the generalizability of one's conclusions from a statistical perspective lies at the root of many of psychology's ongoing problems (e.g., the replication crisis), and conclude with a discussion of several potential avenues for improvement.},
  language = {en},
  keywords = {metodologija}
}

@article{yarkoniMovingColtheartNew2008,
  title = {Moving {{Beyond Coltheart}}'s {{N}}: {{A New Measure}} of {{Orthographic Similarity}}},
  author = {Yarkoni, Tal and Balota, David and Yap, Melvin},
  year = {2008},
  journal = {Psychonomic Bulletin \& Review},
  volume = {15},
  number = {5},
  pages = {971--979},
  keywords = {orthographic-neighborhood,psihologija-jezika}
}

@article{zhangCrossvalidationSelectingModel2015,
  title = {Cross-Validation for Selecting a Model Selection Procedure},
  author = {Zhang, Yongli and Yang, Yuhong},
  year = {2015},
  journal = {Journal of Econometrics},
  pages = {18},
  abstract = {While there are various model selection methods, an unanswered but important question is how to select one of them for data at hand. The difficulty is due to that the targeted behaviors of the model selection procedures depend heavily on uncheckable or difficult-to-check assumptions on the data generating process. Fortunately, cross-validation (CV) provides a general tool to solve this problem. In this work, results are provided on how to apply CV to consistently choose the best method, yielding new insights and guidance for potentially vast amount of application. In addition, we address several seemingly widely spread misconceptions on CV.},
  language = {en},
  keywords = {cross-validation,statistika}
}

@article{zhaoReconsideringBaronKenny2010,
  title = {Reconsidering {{Baron}} and {{Kenny}}: {{Myths}} and Truths about Mediation Analysis},
  shorttitle = {Reconsidering {{Baron}} and {{Kenny}}},
  author = {Zhao, Xinshu and Lynch Jr, John G. and Chen, Qimei},
  year = {2010},
  journal = {Journal of consumer research},
  volume = {37},
  number = {2},
  pages = {197--206},
  keywords = {medijacija,statistika}
}

@article{zhouSequentialRerandomization2018,
  title = {Sequential Rerandomization},
  author = {Zhou, Quan and Ernst, Philip A. and Morgan, Kari Lock and Rubin, Donald B. and Zhang, Anru},
  year = {2018},
  month = sep,
  journal = {Biometrika},
  volume = {105},
  number = {3},
  pages = {745--752},
  issn = {0006-3444},
  doi = {10.1093/biomet/asy031},
  abstract = {Summary.  The seminal work of Morgan \&amp; Rubin (2012) considers rerandomization for all the units at one time.In practice, however, experimenters may have to},
  language = {en},
  keywords = {metodologija,rerandomization,statistika},
  file = {/home/denis/Zotero/storage/DY5KDCKP/5043453.html}
}

@book{zhuKableExtraConstructComplex2019,
  title = {{{kableExtra}}: {{Construct Complex Table}} with 'kable' and {{Pipe Syntax}}},
  author = {Zhu, Hao},
  year = {2019}
}

@article{zuur2010protocol,
  title = {A Protocol for Data Exploration to Avoid Common Statistical Problems},
  author = {Zuur, Alain F and Ieno, Elena N and Elphick, Chris S},
  year = {2010},
  journal = {Methods in ecology and evolution},
  volume = {1},
  number = {1},
  pages = {3--14},
  publisher = {{Wiley Online Library}},
  keywords = {metodologija,multilevel,statistika}
}

@article{zuur2016protocol,
  title = {A Protocol for Conducting and Presenting Results of Regression-Type Analyses},
  author = {Zuur, Alain F and Ieno, Elena N},
  year = {2016},
  journal = {Methods in Ecology and Evolution},
  volume = {7},
  number = {6},
  pages = {636--645},
  publisher = {{Wiley Online Library}},
  keywords = {metodologija,regresija,statistika}
}


